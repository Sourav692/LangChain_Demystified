{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1kiH8lf1y4sD"
      },
      "source": [
        "# Build a Multi-User Conversational Tool-Calling Agentic AI Research Assistant with LangChain"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NYBpZTjLnEXb"
      },
      "source": [
        "This demo will cover building AI Agents with the legacy LangChain `AgentExecutor`. These are fine for getting started, but for working with more advanced agents, LangChain recommends to use LangGraph, which we will cover in the future demos.\n",
        "\n",
        "Agents are systems that use an LLM as a reasoning engine to determine which actions to take and what the inputs to those actions should be. The results of those actions can then be fed back into the agent and it determines whether more actions are needed, or whether it is okay to stop.\n",
        "\n",
        "Here we will build a multi-user Conversational Agent which can refer to previous conversations and give more contextual answers by storing agent messages to a SQL database\n",
        "\n",
        "![](https://i.imgur.com/lHWqaT9.png)\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "L1KvMtf54l0d"
      },
      "source": [
        "## Install OpenAI, and LangChain dependencies"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2evPp14fy258",
        "outputId": "8f7fcca6-1101-4488-c0c7-0ffe0307cf69"
      },
      "outputs": [],
      "source": [
        "# !pip install langchain==0.3.14\n",
        "# !pip install langchain-openai==0.3.0\n",
        "# !pip install langchain-community==0.3.14"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AakmY6B_zYte",
        "outputId": "4be48016-fc58-4992-9b93-a13f4c358026"
      },
      "outputs": [],
      "source": [
        "# !pip install markitdown"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "H9c37cLnSrbg"
      },
      "source": [
        "## Enter Open AI API Key"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cv3JzCEx_PAd",
        "outputId": "f9111545-cbad-4b45-c073-d2fe2b35fe70"
      },
      "outputs": [],
      "source": [
        "# from getpass import getpass\n",
        "\n",
        "# OPENAI_KEY = getpass('Enter Open AI API Key: ')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ucWRRI3QztL2"
      },
      "source": [
        "## Enter Tavily Search API Key\n",
        "\n",
        "Get a free API key from [here](https://tavily.com/#api)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mK-1WLzOrJdb",
        "outputId": "06b5df28-b09c-449e-d2b3-b0630c7efa60"
      },
      "outputs": [],
      "source": [
        "# TAVILY_API_KEY = getpass('Enter Tavily Search API Key: ')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ce5arICZEEov"
      },
      "source": [
        "## Enter WeatherAPI API Key\n",
        "\n",
        "Get a free API key from [here](https://www.weatherapi.com/signup.aspx)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XpAMz1XgEEov",
        "outputId": "78e31000-cb94-4b68-cd9f-e360d2cd7480"
      },
      "outputs": [],
      "source": [
        "# WEATHER_API_KEY = getpass('Enter WeatherAPI API Key: ')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1T0s0um5Svfa"
      },
      "source": [
        "## Setup Environment Variables"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "x1YSuHNF_lbh"
      },
      "outputs": [],
      "source": [
        "# import os\n",
        "\n",
        "# os.environ['OPENAI_API_KEY'] = OPENAI_KEY\n",
        "# os.environ['TAVILY_API_KEY'] = TAVILY_API_KEY"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "execution_count": 7,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# =============================================================================\n",
        "# LOAD ENVIRONMENT VARIABLES\n",
        "# =============================================================================\n",
        "# This loads API keys from a .env file in the project directory.\n",
        "# Your .env file should contain:\n",
        "#   OPENAI_API_KEY=your_openai_key\n",
        "#   TAVILY_API_KEY=your_tavily_key  \n",
        "#   WEATHER_API_KEY=your_openweathermap_key\n",
        "# =============================================================================\n",
        "\n",
        "from dotenv import load_dotenv, find_dotenv\n",
        "\n",
        "# find_dotenv() searches for .env file in current and parent directories\n",
        "load_dotenv(find_dotenv())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "howf-v0ARWbv"
      },
      "source": [
        "## Create Tools\n",
        "\n",
        "Here we create two custom tools which are wrappers on top of the [Tavily API](https://tavily.com/#api) and [WeatherAPI](https://www.weatherapi.com/)\n",
        "\n",
        "- Web Search tool with information extraction\n",
        "- Weather tool\n",
        "\n",
        "![](https://i.imgur.com/TyPAYXE.png)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ue8xgu9WpuPi",
        "outputId": "fc5f62c8-d5a1-4e33-846f-9cf4bb8eccea"
      },
      "outputs": [],
      "source": [
        "from langchain_core.tools import tool\n",
        "from markitdown import MarkItDown\n",
        "from langchain_community.tools.tavily_search import TavilySearchResults\n",
        "from tqdm import tqdm\n",
        "from concurrent.futures import ThreadPoolExecutor, TimeoutError\n",
        "import requests\n",
        "import json\n",
        "from warnings import filterwarnings\n",
        "from IPython.display import display, Markdown\n",
        "\n",
        "filterwarnings('ignore')\n",
        "\n",
        "tavily_tool = TavilySearchResults(max_results=5,\n",
        "                                  search_depth='advanced',\n",
        "                                  include_answer=False,\n",
        "                                  include_raw_content=True)\n",
        "session = requests.Session()\n",
        "session.headers.update({\n",
        "    \"User-Agent\": \"Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/112.0.0.0 Safari/537.36\",\n",
        "    \"Accept-Language\": \"en-US,en;q=0.9\",\n",
        "    \"Accept-Encoding\": \"gzip, deflate, br\"\n",
        "})\n",
        "md = MarkItDown(requests_session=session)\n",
        "\n",
        "@tool\n",
        "def search_web_extract_info(query: str) -> list:\n",
        "    \"\"\"Search the web for a query and extracts useful information from the search links.\"\"\"\n",
        "    print('Calling web search tool')\n",
        "    results = tavily_tool.invoke(query)\n",
        "    docs = []\n",
        "\n",
        "    def extract_content(url):\n",
        "        \"\"\"Helper function to extract content from a URL.\"\"\"\n",
        "        extracted_info = md.convert(url)\n",
        "        text_title = extracted_info.title.strip()\n",
        "        text_content = extracted_info.text_content.strip()\n",
        "        return text_title + '\\n' + text_content\n",
        "\n",
        "    with ThreadPoolExecutor() as executor:\n",
        "        for result in tqdm(results):\n",
        "            try:\n",
        "                future = executor.submit(extract_content, result['url'])\n",
        "                # Wait for up to 60 seconds for the task to complete\n",
        "                content = future.result(timeout=60)\n",
        "                docs.append(content)\n",
        "            except TimeoutError:\n",
        "                print(f\"Extraction timed out for url: {result['url']}\")\n",
        "            except Exception as e:\n",
        "                print(f\"Error extracting from url: {result['url']} - {e}\")\n",
        "\n",
        "    return docs\n",
        "\n",
        "\n",
        "# =============================================================================\n",
        "# TOOL 2: Weather Information Tool  \n",
        "# =============================================================================\n",
        "# This tool fetches real-time weather data using OpenWeatherMap API\n",
        "\n",
        "@tool\n",
        "def get_weather(query: str) -> dict:\n",
        "    \"\"\"\n",
        "    Fetch current weather data for a specified location using OpenWeatherMap API.\n",
        "    \n",
        "    Args:\n",
        "        query (str): The city name to get weather information for\n",
        "        \n",
        "    Returns:\n",
        "        dict: Weather data including temperature, humidity, wind speed, etc.\n",
        "              Returns \"Weather Data Not Found\" if the location is invalid\n",
        "    \"\"\"\n",
        "    # Construct API URL with city name and API key\n",
        "    # Note: The ',IN' suffix restricts search to India - modify as needed\n",
        "    url = f\"https://api.openweathermap.org/data/2.5/weather?q={query},IN&appid={os.getenv('WEATHER_API_KEY')}&units=metric\"\n",
        "\n",
        "    response = requests.get(url)\n",
        "    data = response.json()\n",
        "    \n",
        "    # Validate response by checking if 'name' field exists\n",
        "    if data.get(\"name\"):\n",
        "        return data\n",
        "    else:\n",
        "        return \"Weather Data Not Found\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "c7kvwG3SmREW"
      },
      "source": [
        "## Build and Test AI Agent\n",
        "\n",
        "Now that we have defined the tools and the LLM, we can create the agent. We will be using a tool calling agent to bind the tools to the agent with a prompt. We will also add in the capability to store historical conversations as memory"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "grNq1I6_5dxC",
        "outputId": "42022951-93f7-4958-e5bf-052567f9f4ec"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "[SystemMessagePromptTemplate(prompt=PromptTemplate(input_variables=[], input_types={}, partial_variables={}, template=\"Act as a helpful assistant.\\n                You run in a loop of Thought, Action, PAUSE, Observation.\\n                At the end of the loop, you output an Answer.\\n                Use Thought to describe your thoughts about the question you have been asked.\\n                Use Action to run one of the actions available to you - then return PAUSE.\\n                Observation will be the result of running those actions.\\n                Repeat till you get to the answer for the given user query.\\n\\n                Use the following workflow format:\\n                  Question: the input task you must solve\\n                  Thought: you should always think about what to do\\n                  Action: the action to take which can be any of the following:\\n                            - break it into smaller steps if needed\\n                            - see if you can answer the given task with your trained knowledge\\n                            - call the most relevant tools at your disposal mentioned below in case you need more information\\n                  Action Input: the input to the action\\n                  Observation: the result of the action\\n                  ... (this Thought/Action/Action Input/Observation can repeat N times)\\n                  Thought: I now know the final answer\\n                  Final Answer: the final answer to the original input question\\n\\n                Tools at your disposal to perform tasks as needed:\\n                  - get_weather: whenever user asks get the weather of a place.\\n                  - search_web_extract_info: whenever user asks for specific information or if you don't know the answer.\\n             \"), additional_kwargs={}),\n",
              " MessagesPlaceholder(variable_name='history', optional=True),\n",
              " HumanMessagePromptTemplate(prompt=PromptTemplate(input_variables=['query'], input_types={}, partial_variables={}, template='{query}'), additional_kwargs={}),\n",
              " MessagesPlaceholder(variable_name='agent_scratchpad')]"
            ]
          },
          "execution_count": 9,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "from langchain_core.prompts import ChatPromptTemplate, MessagesPlaceholder\n",
        "\n",
        "SYS_PROMPT = \"\"\"Act as a helpful assistant.\n",
        "                You run in a loop of Thought, Action, PAUSE, Observation.\n",
        "                At the end of the loop, you output an Answer.\n",
        "                Use Thought to describe your thoughts about the question you have been asked.\n",
        "                Use Action to run one of the actions available to you - then return PAUSE.\n",
        "                Observation will be the result of running those actions.\n",
        "                Repeat till you get to the answer for the given user query.\n",
        "\n",
        "                Use the following workflow format:\n",
        "                  Question: the input task you must solve\n",
        "                  Thought: you should always think about what to do\n",
        "                  Action: the action to take which can be any of the following:\n",
        "                            - break it into smaller steps if needed\n",
        "                            - see if you can answer the given task with your trained knowledge\n",
        "                            - call the most relevant tools at your disposal mentioned below in case you need more information\n",
        "                  Action Input: the input to the action\n",
        "                  Observation: the result of the action\n",
        "                  ... (this Thought/Action/Action Input/Observation can repeat N times)\n",
        "                  Thought: I now know the final answer\n",
        "                  Final Answer: the final answer to the original input question\n",
        "\n",
        "                Tools at your disposal to perform tasks as needed:\n",
        "                  - get_weather: whenever user asks get the weather of a place.\n",
        "                  - search_web_extract_info: whenever user asks for specific information or if you don't know the answer.\n",
        "             \"\"\"\n",
        "\n",
        "prompt_template = ChatPromptTemplate.from_messages(\n",
        "    [\n",
        "        (\"system\", SYS_PROMPT),\n",
        "        MessagesPlaceholder(variable_name=\"history\", optional=True),\n",
        "        (\"human\", \"{query}\"),\n",
        "        MessagesPlaceholder(variable_name=\"agent_scratchpad\"),\n",
        "    ]\n",
        ")\n",
        "\n",
        "prompt_template.messages"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jlJwVepDmsZw"
      },
      "source": [
        "Now, we can initalize the agent with the LLM, the prompt, and the tools.\n",
        "\n",
        "The agent is responsible for taking in input and deciding what actions to take.\n",
        "\n",
        "REMEMBER the Agent does not execute those actions - that is done by the AgentExecutor\n",
        "\n",
        "Note that we are passing in the model `chatgpt`, not `chatgpt_with_tools`.\n",
        "\n",
        "That is because `create_tool_calling_agent` will call `.bind_tools` for us under the hood.\n",
        "\n",
        "This should ideally be used with an LLM which supports tool \\ function calling"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "u4NMA82HpueH"
      },
      "outputs": [],
      "source": [
        "from langchain.agents import create_tool_calling_agent\n",
        "from langchain_openai import ChatOpenAI\n",
        "\n",
        "chatgpt = ChatOpenAI(model=\"gpt-4o\", temperature=0)\n",
        "tools = [search_web_extract_info, get_weather]\n",
        "agent = =-\n",
        "(chatgpt, tools, prompt_template)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TiL70NCrmkkW"
      },
      "source": [
        "Finally, we combine the `agent` (the brains) with the `tools` inside the `AgentExecutor` (which will repeatedly call the agent and execute tools)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "vAuGe5G5pugJ"
      },
      "outputs": [],
      "source": [
        "from langchain.agents import AgentExecutor\n",
        "\n",
        "agent_executor = AgentExecutor(agent=agent,\n",
        "                               tools=tools,\n",
        "                               early_stopping_method='force',\n",
        "                               max_iterations=10)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Cw9mxPskx734"
      },
      "source": [
        "## Build and Test Multi-User Conversational AI Agent\n",
        "\n",
        "We will now use `SQLChatMessageHistory` which we learnt in the previous module to store separate conversation histories per user or session.\n",
        "\n",
        "This will help us build a conversational Agentic Chatbot which will be accessed by many users at the same time"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EUG09xD5zd2N",
        "outputId": "d3a5e771-912b-43a4-80b8-0342783dbe54"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "rm: memory.db: No such file or directory\n"
          ]
        }
      ],
      "source": [
        "# removes the memory database file - usually not needed\n",
        "# you can run this only when you want to remove ALL conversation histories\n",
        "# ok if you get rm: cannot remove 'memory.db': No such file or directory  because initially no memory exists\n",
        "!rm memory.db"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "id": "_XSzUrlyZyFF"
      },
      "outputs": [],
      "source": [
        "from langchain_community.chat_message_histories import SQLChatMessageHistory\n",
        "from langchain_core.runnables.history import RunnableWithMessageHistory\n",
        "\n",
        "# used to retrieve conversation history from database\n",
        "# based on a specific user or session ID\n",
        "def get_session_history_db(session_id):\n",
        "    return SQLChatMessageHistory(session_id, \"sqlite:///memory.db\")\n",
        "\n",
        "# create a conversation chain + agent which can load memory based on specific user or session id\n",
        "agentic_chatbot = RunnableWithMessageHistory(\n",
        "    agent_executor,\n",
        "    get_session_history_db,\n",
        "    input_messages_key=\"query\",\n",
        "    history_messages_key=\"history\",\n",
        ")\n",
        "\n",
        "# function to call the agent show results per user session\n",
        "from IPython.display import display, Markdown\n",
        "def chat_with_agent(prompt: str, session_id: str):\n",
        "    response = agentic_chatbot.invoke({\"query\": prompt},\n",
        "                                      {'configurable': { 'session_id': session_id}})\n",
        "    display(Markdown(response['output']))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vYTNL_iJ6ibC"
      },
      "source": [
        "Let's now simulate User 1 using the agent"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 517
        },
        "id": "irMU68Ds0NTm",
        "outputId": "0d251ab7-5e47-4149-b562-2c25b88afbd8"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/Users/sourav.banerjee/Documents/Codebases/2. AI ENGINEERING/LangChain_Demystified/.venv/lib/python3.13/site-packages/langchain_core/runnables/history.py:606: LangChainDeprecationWarning: `connection_string` was deprecated in LangChain 0.2.2 and will be removed in 1.0. Use connection instead.\n",
            "  message_history = self.get_session_history(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Calling web search tool\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 20%|██        | 1/5 [00:00<00:00,  9.77it/s]Cannot set gray non-stroke color because /'P25' is an invalid float value\n",
            "Cannot set gray non-stroke color because /'P46' is an invalid float value\n",
            "Cannot set gray non-stroke color because /'P137' is an invalid float value\n",
            "Cannot set gray non-stroke color because /'P172' is an invalid float value\n",
            "Cannot set gray non-stroke color because /'P205' is an invalid float value\n",
            "Cannot set gray non-stroke color because /'P238' is an invalid float value\n",
            "Cannot set gray non-stroke color because /'P271' is an invalid float value\n",
            "Cannot set gray non-stroke color because /'P306' is an invalid float value\n",
            "Cannot set gray non-stroke color because /'P339' is an invalid float value\n",
            "Cannot set gray non-stroke color because /'P374' is an invalid float value\n",
            "Cannot set gray non-stroke color because /'P442' is an invalid float value\n",
            " 40%|████      | 2/5 [00:00<00:01,  1.93it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Error extracting from url: https://s201.q4cdn.com/141608511/files/doc_financials/2024/q4/NVDA-F4Q24-Quarterly-Presentation-FINAL.pdf - 'NoneType' object has no attribute 'strip'\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 60%|██████    | 3/5 [00:01<00:01,  1.78it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Error extracting from url: https://www.youtube.com/watch?v=hV6WxM3S80g - 'NoneType' object has no attribute 'strip'\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 5/5 [00:03<00:00,  1.55it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Error extracting from url: https://nvidianews.nvidia.com/_gallery/download_pdf/65d669a33d63329bbf62672a/ - 'NoneType' object has no attribute 'strip'\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "data": {
            "text/markdown": [
              "Nvidia's Q4 2024 earnings call highlighted several key points:\n",
              "\n",
              "1. **Financial Performance**: Nvidia reported a significant increase in revenue, reaching $22.1 billion for the quarter, a 22% increase from the previous quarter and a 265% rise from the same period a year ago. The fiscal year 2024's revenue totaled $60.9 billion, up by 126%. The earnings per share (EPS) also saw substantial growth, with GAAP EPS at $4.93 and Non-GAAP EPS at $5.16.\n",
              "\n",
              "2. **Data Center and AI Growth**: Approximately 40% of Nvidia's record data center revenue of $18.4 billion was attributed to AI inference. The company's AI enterprise software reached an annualized revenue run rate of $1 billion, indicating potential growth in leveraging AI across various industries.\n",
              "\n",
              "3. **Market Sentiment and Stock Performance**: Following the earnings announcement, Nvidia's stock surged by more than 8% in after-hours trading, reflecting positive market sentiment and investor confidence in the company's growth trajectory.\n",
              "\n",
              "4. **Strategic Initiatives and Challenges**: Nvidia's strategic focus on AI and accelerated computing, along with its expansive ecosystem of partnerships, positions it well for sustained growth. Despite facing regulatory challenges in China, Nvidia adapted by offering alternative products, mitigating potential impacts on its business.\n",
              "\n",
              "Overall, Nvidia's Q4 2024 earnings call underscored its strong financial performance, strategic focus on AI, and ability to navigate regulatory challenges, positioning it for continued growth and innovation."
            ],
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "user_id = 'john001'\n",
        "prompt = \"Summarize the key points discussed in Nvidia's Q4 2024 earnings call\"\n",
        "chat_with_agent(prompt, user_id)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 342
        },
        "id": "XT4vtvku0TBW",
        "outputId": "34930943-0543-4f06-bb55-04ab680cca5a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Calling web search tool\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 40%|████      | 2/5 [00:01<00:02,  1.40it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Error extracting from url: https://morethanmoore.substack.com/p/intel-2024-q4-financials - 'NoneType' object has no attribute 'strip'\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 60%|██████    | 3/5 [00:02<00:01,  1.05it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Error extracting from url: https://www.fool.com/earnings/call-transcripts/2025/01/30/intel-intc-q4-2024-earnings-call-transcript/ - 'NoneType' object has no attribute 'strip'\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 5/5 [00:05<00:00,  1.17s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Error extracting from url: https://newsroom.intel.com/corporate/intel-reports-fourth-quarter-full-year-2024-financial-results - 'NoneType' object has no attribute 'strip'\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "data": {
            "text/markdown": [
              "Intel's Q4 2024 earnings call highlighted several key points:\n",
              "\n",
              "1. **Financial Performance**: Intel reported Q4 revenue of $14.3 billion, which was a 7% sequential increase and surpassed guidance. The non-GAAP gross margin was 42.1%, exceeding expectations by 260 basis points. Earnings per share (EPS) were $0.13, slightly above the guidance of $0.12. However, the full-year 2024 revenue was $53.1 billion, down 2.1% year-over-year, with a full-year EPS of minus $0.13.\n",
              "\n",
              "2. **Challenges and Guidance**: Despite surpassing guidance, Intel faces challenges such as increased competition in the AI PC category and a lack of significant participation in the cloud-based AI data center market. The company reported a significant operating loss in its foundry services. For Q1 2025, Intel provided a revenue guidance of $11.7 billion to $12.7 billion, with a breakeven EPS on a non-GAAP basis.\n",
              "\n",
              "3. **Strategic Initiatives**: Intel is focusing on its AI PC CPUs and plans to ship over 100 million systems by the end of 2025. The launch of Panther Lake on Intel 18A is on track for the second half of 2025. Intel Foundry is making progress with Intel 18A, showing competitive offerings and a healthy pipeline of potential customers.\n",
              "\n",
              "4. **Leadership Changes**: The company appointed two interim co-CEOs, David Zinsner and Michelle Johnston Holthaus, following the departure of CEO Pat Gelsinger. The search for a new CEO is ongoing.\n",
              "\n",
              "5. **Market Dynamics**: Intel's guidance reflects macroeconomic uncertainty and seasonality, impacting all product segments. The company is taking a conservative approach to capital deployment and focusing on building a world-class foundry.\n",
              "\n",
              "Overall, Intel's Q4 2024 earnings call highlighted its ability to surpass guidance amidst market challenges, while also outlining strategic initiatives and leadership changes to enhance its competitive position."
            ],
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "prompt = \"What about Intel?\"\n",
        "chat_with_agent(prompt, user_id)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 253
        },
        "id": "u-sz15g8YGNA",
        "outputId": "73eec36b-8363-4ddb-a8c8-a9a9c5396153"
      },
      "outputs": [
        {
          "data": {
            "text/markdown": [
              "Based on the Q4 2024 earnings calls for both Nvidia and Intel, Nvidia appears to be performing better overall. Here are some key points that support this assessment:\n",
              "\n",
              "1. **Revenue Growth**: Nvidia reported a significant increase in revenue, with a 22% sequential increase and a 265% year-over-year rise, reaching $22.1 billion for the quarter. In contrast, Intel's revenue for the quarter was $14.3 billion, with a 7% sequential increase but a decline in full-year revenue by 2.1% year-over-year.\n",
              "\n",
              "2. **Profitability**: Nvidia's earnings per share (EPS) showed substantial growth, with both GAAP and Non-GAAP EPS significantly higher than the previous year. Intel, on the other hand, reported a full-year EPS of minus $0.13, indicating a loss.\n",
              "\n",
              "3. **Market Sentiment**: Nvidia's stock surged by more than 8% in after-hours trading following the earnings announcement, reflecting positive market sentiment. Intel's guidance reflects macroeconomic uncertainty, and the company is taking a conservative approach.\n",
              "\n",
              "4. **Strategic Positioning**: Nvidia's strong focus on AI and data center growth, with a significant portion of revenue coming from AI inference, positions it well for future growth. Intel is facing challenges in the AI PC category and cloud-based AI data center market, although it is making strategic moves in its foundry services.\n",
              "\n",
              "5. **Leadership Stability**: Nvidia did not report any major leadership changes, while Intel is undergoing a leadership transition with the appointment of interim co-CEOs and the search for a new CEO.\n",
              "\n",
              "Overall, Nvidia's strong financial performance, strategic focus on AI, and positive market sentiment suggest it is currently in a better position compared to Intel, which is facing challenges and undergoing leadership changes."
            ],
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "prompt = \"Which company seems to be doing better?\"\n",
        "chat_with_agent(prompt, user_id)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "B4zIlISy6m-x"
      },
      "source": [
        "Let's now simulate User 2 using the agent"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 301
        },
        "id": "ta1RUF_81RxX",
        "outputId": "c2996859-5fe7-4ef1-bd21-0ee5257afc93"
      },
      "outputs": [
        {
          "data": {
            "text/markdown": [
              "The weather in Bangalore today is as follows:\n",
              "\n",
              "- **Condition**: Mist\n",
              "- **Temperature**: 14.84°C\n",
              "- **Feels Like**: 14.76°C\n",
              "- **Minimum Temperature**: 13.9°C\n",
              "- **Maximum Temperature**: 15.28°C\n",
              "- **Pressure**: 1015 hPa\n",
              "- **Humidity**: 91%\n",
              "- **Visibility**: 1800 meters\n",
              "- **Wind Speed**: 5.36 m/s\n",
              "- **Wind Direction**: 74° (East-Northeast)\n",
              "- **Wind Gust**: 12.96 m/s\n",
              "- **Cloudiness**: 20%\n",
              "\n",
              "The sun will rise at 5:43 AM and set at 5:51 PM local time."
            ],
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "user_id = 'bond007'\n",
        "prompt = \"how is the weather in Bangalore today? Show detailed statistics\"\n",
        "chat_with_agent(prompt, user_id)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 301
        },
        "id": "vfn_Wxxg42rZ",
        "outputId": "c695b4fc-0d20-44f8-bfa4-646ac682c9f2"
      },
      "outputs": [
        {
          "data": {
            "text/markdown": [
              "The weather in Mumbai today is as follows:\n",
              "\n",
              "- **Condition**: Smoke\n",
              "- **Temperature**: 22.99°C\n",
              "- **Feels Like**: 22.81°C\n",
              "- **Minimum Temperature**: 22.99°C\n",
              "- **Maximum Temperature**: 22.99°C\n",
              "- **Pressure**: 1012 hPa\n",
              "- **Humidity**: 56%\n",
              "- **Visibility**: 3000 meters\n",
              "- **Wind Speed**: 2.57 m/s\n",
              "- **Wind Direction**: 100° (East)\n",
              "- **Cloudiness**: 18%\n",
              "\n",
              "The sun will rise at 6:13 AM and set at 6:53 PM local time.\n",
              "\n",
              "Comparing the temperatures, Mumbai is currently warmer than Bangalore, which has a temperature of 14.84°C."
            ],
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "user_id = 'bond007'\n",
        "prompt = \"what about Mumbai?\"\n",
        "chat_with_agent(prompt, user_id)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 46
        },
        "id": "I7jjxtmz6Qzi",
        "outputId": "34323085-f10f-4552-a919-98382dc8a812"
      },
      "outputs": [
        {
          "data": {
            "text/markdown": [
              "Based on the current weather data:\n",
              "\n",
              "- **Bangalore**: 14.84°C\n",
              "- **Mumbai**: 22.99°C\n",
              "\n",
              "Mumbai is currently hotter than Bangalore."
            ],
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "user_id = 'bond007'\n",
        "prompt = \"which city is hotter?\"\n",
        "chat_with_agent(prompt, user_id)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": ".venv",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.13.11"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
