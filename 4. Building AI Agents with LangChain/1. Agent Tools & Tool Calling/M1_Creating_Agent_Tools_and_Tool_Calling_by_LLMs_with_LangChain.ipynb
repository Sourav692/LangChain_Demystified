{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-CVPAiNAy9MH"
      },
      "source": [
        "# Exploring Tools in LangChain"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "L1KvMtf54l0d"
      },
      "source": [
        "## Install OpenAI, and LangChain dependencies"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yXgPP-n3lDy6"
      },
      "outputs": [],
      "source": [
        "from warnings import filterwarnings\n",
        "filterwarnings('ignore')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2evPp14fy258",
        "outputId": "ab34056e-c484-42bd-f1b7-ae0a05c43059"
      },
      "outputs": [],
      "source": [
        "# !pip install langchain==0.3.14\n",
        "# !pip install langchain-openai==0.3.0\n",
        "# !pip install langchain-community==0.3.14"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TlfidBdQZRGj"
      },
      "source": [
        "## Install Data Extraction APIs"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uZKQDgQURhmF",
        "outputId": "e965e299-4f80-4e20-a8c9-4186483f7b0a"
      },
      "outputs": [],
      "source": [
        "# # to create custom tools\n",
        "# !pip install wikipedia==1.4.0\n",
        "# !pip install markitdown\n",
        "# # to highlight json\n",
        "# !pip install rich"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "H9c37cLnSrbg"
      },
      "source": [
        "## Enter Open AI API Key"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cv3JzCEx_PAd",
        "outputId": "d2368589-e313-4cc8-909c-9399e147ef1d"
      },
      "outputs": [],
      "source": [
        "# from getpass import getpass\n",
        "\n",
        "# OPENAI_KEY = getpass('Enter Open AI API Key: ')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ucWRRI3QztL2"
      },
      "source": [
        "## Enter Tavily Search API Key\n",
        "\n",
        "Get a free API key from [here](https://tavily.com/#api)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mK-1WLzOrJdb",
        "outputId": "df080905-75fc-4b9d-96bd-562bce8afa84"
      },
      "outputs": [],
      "source": [
        "# TAVILY_API_KEY = getpass('Enter Tavily Search API Key: ')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ce5arICZEEov"
      },
      "source": [
        "## Enter WeatherAPI API Key\n",
        "\n",
        "Get a free API key from [here](https://www.weatherapi.com/signup.aspx)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XpAMz1XgEEov",
        "outputId": "2a18b0a1-ffea-4fbf-f185-d9116fbaf6b2"
      },
      "outputs": [],
      "source": [
        "# WEATHER_API_KEY = getpass('Enter WeatherAPI API Key: ')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1T0s0um5Svfa"
      },
      "source": [
        "## Setup Environment Variables"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from dotenv import load_dotenv, find_dotenv\n",
        "\n",
        "load_dotenv(find_dotenv())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "x1YSuHNF_lbh"
      },
      "outputs": [],
      "source": [
        "# import os\n",
        "\n",
        "# os.environ['OPENAI_API_KEY'] = OPENAI_KEY\n",
        "# os.environ['TAVILY_API_KEY'] = TAVILY_API_KEY"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "65C3PellZGYf"
      },
      "source": [
        "## Exploring Built-in Tools"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "howf-v0ARWbv"
      },
      "source": [
        "### Exploring the Wikipedia Tool\n",
        "\n",
        "Enables you to tap into the Wikipedia API to search wikipedia pages for information"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "q2CMhK9Rjk2t"
      },
      "outputs": [],
      "source": [
        "from langchain_community.tools import WikipediaQueryRun\n",
        "from langchain_community.utilities import WikipediaAPIWrapper\n",
        "\n",
        "wiki_api_wrapper = WikipediaAPIWrapper(top_k_results=3,\n",
        "                                       doc_content_chars_max=8000)\n",
        "wiki_tool = WikipediaQueryRun(api_wrapper=wiki_api_wrapper, features=\"lxml\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 53
        },
        "id": "t1Ce8wbYodYO",
        "outputId": "dc4ad085-54a8-450f-d32a-bb261bdfc362"
      },
      "outputs": [],
      "source": [
        "wiki_tool.description"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "d2MSVAh2osSE",
        "outputId": "02e23a35-bf58-453b-adf3-64fa5536588c"
      },
      "outputs": [],
      "source": [
        "wiki_tool.args"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "luhjlzeSkgUq",
        "outputId": "0c781ee6-9a3e-459c-969d-54f6dbe72251"
      },
      "outputs": [],
      "source": [
        "print(wiki_tool.invoke({\"query\": \"Microsoft\"}))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jglV7GRXjk5O",
        "outputId": "c5982698-fe63-4d74-faa0-f6b5b7ffd2d5"
      },
      "outputs": [],
      "source": [
        "print(wiki_tool.invoke({\"query\": \"AI\"}))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LnfMeoXJVn-i"
      },
      "source": [
        " You can customize the default tool with its own name, description and so on as follows"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1tO5g9Q1jk7x"
      },
      "outputs": [],
      "source": [
        "from langchain.agents import Tool\n",
        "\n",
        "wiki_tool_init = Tool(name=\"Wikipedia\",\n",
        "                      func=wiki_api_wrapper.run,\n",
        "                      description=\"useful when you need a detailed answer about general knowledge\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "ZRTfVUuGo7ti",
        "outputId": "e7f5b9e0-d851-472b-ab66-cff39b04f84c"
      },
      "outputs": [],
      "source": [
        "wiki_tool_init.description"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TW0emMEIou-L",
        "outputId": "e0fba8f6-1da1-4791-e4af-8913e4f38245"
      },
      "outputs": [],
      "source": [
        "wiki_tool_init.args"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kgAwdPrBjk-x",
        "outputId": "fe3765d3-356d-4545-af7f-3a65076578ea"
      },
      "outputs": [],
      "source": [
        "print(wiki_tool_init.invoke({\"tool_input\": \"AI\"}))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cnQfnkQeV7Hp"
      },
      "source": [
        "### Exploring the Tavily Search Tool\n",
        "\n",
        "Tavily Search API is a search engine optimized for LLMs and RAG, aimed at efficient, quick and persistent search results"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UjWM95p5pB4k"
      },
      "outputs": [],
      "source": [
        "from langchain_community.tools.tavily_search import TavilySearchResults\n",
        "\n",
        "tavily_tool = TavilySearchResults(max_results=5,\n",
        "                                search_depth='advanced',\n",
        "                                include_raw_content=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WmawzibmjlC6",
        "outputId": "ccd9cdcc-7ece-42bb-ca1a-b6dc0d727d72"
      },
      "outputs": [],
      "source": [
        "tavily_tool.args"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 53
        },
        "id": "eERoFFoPjlGJ",
        "outputId": "a14facad-3ba4-4a0f-a68b-34d12658fc79"
      },
      "outputs": [],
      "source": [
        "tavily_tool.description"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "khqWQVcvrnG9",
        "outputId": "287a0237-f323-4e40-9d35-3df6d100515f"
      },
      "outputs": [],
      "source": [
        "results = tavily_tool.invoke(\"Tell me about Microsoft\")\n",
        "results"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-GNP2J9Dd_nj"
      },
      "source": [
        "## Build your own tools in LangChain\n",
        "\n",
        "Tools are interfaces that an agent, chain, or LLM can use to interact with the world. They combine a few things:\n",
        "\n",
        "- The name of the tool\n",
        "- A description of what the tool is\n",
        "- JSON schema of what the inputs to the tool are\n",
        "- The function to call\n",
        "- Whether the result of a tool should be returned directly to the user\n",
        "\n",
        "It is useful to have all this information because this information can be used to build action-taking systems! The name, description, and JSON schema can be used to prompt the LLM so it knows how to specify what action to take, and then the function to call is equivalent to taking that action."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZtoArDYfheYD"
      },
      "source": [
        "### Building a Simple Math Tool"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JvPAmW62eLyE"
      },
      "source": [
        "We will start by building a simple tool which does some basic math"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wa0mztbQ8Ae3",
        "outputId": "0a94a594-dcec-4710-8756-74f96200d7d2"
      },
      "outputs": [],
      "source": [
        "from langchain_core.tools import tool\n",
        "\n",
        "@tool\n",
        "def multiply(a, b):\n",
        "    \"\"\"Multiply two numbers.\"\"\"\n",
        "    return a * b\n",
        "\n",
        "\n",
        "# Let's inspect some of the attributes associated with the tool.\n",
        "print(multiply.name)\n",
        "print(multiply.description)\n",
        "print(multiply.args)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 121
        },
        "id": "tfP2TjeK8FsR",
        "outputId": "60859e65-098c-4ebf-aeb4-69bbf29fcb6e"
      },
      "outputs": [],
      "source": [
        "type(multiply)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EsOVBIvX8Agu",
        "outputId": "c30cfbac-b30c-466d-ddaa-0c3b3974f030"
      },
      "outputs": [],
      "source": [
        "multiply.invoke({\"a\": 2, \"b\": 3})"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cC7o_Mv5-Grc",
        "outputId": "b7ad7932-9a39-465d-88ef-3cff9d508021"
      },
      "outputs": [],
      "source": [
        "multiply.invoke({\"a\": 2.1, \"b\": 3.2})"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "vN4tHdDa-Tm2",
        "outputId": "49359bb5-6ae6-4b03-993a-ae04b100a67a"
      },
      "outputs": [],
      "source": [
        "multiply.invoke({\"a\": 2, \"b\": 'abc'})"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XED8giGYeS_I"
      },
      "source": [
        "Let's now build a tool with data type enforcing"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9sKF2zqQ8Aih",
        "outputId": "7508ee9f-3492-4386-9be5-cf870b690d09"
      },
      "outputs": [],
      "source": [
        "from pydantic import BaseModel, Field\n",
        "from langchain_core.tools import StructuredTool\n",
        "\n",
        "class CalculatorInput(BaseModel):\n",
        "    a: float = Field(description=\"first number\")\n",
        "    b: float = Field(description=\"second number\")\n",
        "\n",
        "\n",
        "def multiply(a: float, b: float) -> float:\n",
        "    \"\"\"Multiply two numbers.\"\"\"\n",
        "    return a * b\n",
        "\n",
        "# we could also use the @tool decorator from before\n",
        "multiply = StructuredTool.from_function(\n",
        "    func=multiply,\n",
        "    name=\"multiply\",\n",
        "    description=\"use to multiply numbers\",\n",
        "    args_schema=CalculatorInput,\n",
        "    return_direct=True\n",
        "    )\n",
        "\n",
        "# Let's inspect some of the attributes associated with the tool.\n",
        "print(multiply.name)\n",
        "print(multiply.description)\n",
        "print(multiply.args)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "H5taFxZg8Akc",
        "outputId": "c20364a3-8405-4713-f963-d42bdee4b688"
      },
      "outputs": [],
      "source": [
        "multiply.invoke({\"a\": 2, \"b\": 3})"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 356
        },
        "id": "3PTl9ezG8Ans",
        "outputId": "2c769158-1a30-4991-8211-0a7471acd4a2"
      },
      "outputs": [],
      "source": [
        "# this code will error out as abc is not a floating point number\n",
        "try:\n",
        "    multiply.invoke({\"a\": 2, \"b\": 'abc'})\n",
        "except Exception as e:\n",
        "    print(e)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QMsvq9sVhjuL"
      },
      "source": [
        "### Build a Web Search & Information Extraction Tool"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cazBMQsghoaB",
        "outputId": "e5c7d31e-1197-46da-b0ac-20ff234e19b0"
      },
      "outputs": [],
      "source": [
        "tavily_tool = TavilySearchResults(max_results=5,\n",
        "                                  search_depth='advanced',\n",
        "                                  include_raw_content=True)\n",
        "\n",
        "result = tavily_tool.invoke(\"Tell me about Microsoft's Q4 2024 earning call report\")\n",
        "result"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "xZ-WELThiwjK",
        "outputId": "dddff98f-74ed-43b8-b9bc-bdefc69b2046"
      },
      "outputs": [],
      "source": [
        "result[0]['url']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 460
        },
        "id": "IXfm6C2UizLk",
        "outputId": "d3f4702b-388b-4c87-af8b-6d1de29c0901"
      },
      "outputs": [],
      "source": [
        "from markitdown import MarkItDown\n",
        "\n",
        "md = MarkItDown()\n",
        "doc_content = md.convert(result[0]['url'])\n",
        "print(doc_content.title.strip())\n",
        "print(doc_content.text_content)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cK2iU3buYDsB"
      },
      "outputs": [],
      "source": [
        "doc_content = md.convert(result[3]['url'])\n",
        "print(doc_content.title.strip())\n",
        "print(doc_content.text_content)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0G6V3Kv1jwU0"
      },
      "outputs": [],
      "source": [
        "from markitdown import MarkItDown\n",
        "from langchain_community.tools.tavily_search import TavilySearchResults\n",
        "from tqdm import tqdm\n",
        "import requests\n",
        "\n",
        "tavily_tool = TavilySearchResults(max_results=5,\n",
        "                                  search_depth='advanced',\n",
        "                                  include_answer=False,\n",
        "                                  include_raw_content=True)\n",
        "md = MarkItDown()\n",
        "\n",
        "@tool\n",
        "def search_web_extract_info(query: str) -> list:\n",
        "    \"\"\"Search the web for a query and extracts useful information from the search links\"\"\"\n",
        "    results = tavily_tool.invoke(query)\n",
        "    docs = []\n",
        "    for result in tqdm(results):\n",
        "        # Extracting all text content from the URL\n",
        "        try:\n",
        "            extracted_info = md.convert(result['url'])\n",
        "            text_title = extracted_info.title.strip()\n",
        "            text_content = extracted_info.text_content.strip()\n",
        "            docs.append(text_title + '\\n' + text_content)\n",
        "        except:\n",
        "            print('Extraction blocked for url: ', result['url'])\n",
        "            pass\n",
        "\n",
        "    return docs"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_qNB0fSmlhLQ",
        "outputId": "ff852d1e-aaf1-4b69-e516-744d923b6092"
      },
      "outputs": [],
      "source": [
        "docs = search_web_extract_info('OpenAI GPT-4o')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000,
          "resources": {
            "http://localhost:8080/_next/image?url=https%3A%2F%2Favatars.githubusercontent.com%2Fu%2F96567547%3Fs%3D400%26u%3D08b9757200906ab12e3989b561cff6c4b95a12cb%26v%3D4&w=64&q=75": {
              "data": "",
              "headers": [
                [
                  "content-length",
                  "0"
                ]
              ],
              "ok": false,
              "status": 404,
              "status_text": ""
            },
            "http://localhost:8080/_next/static/media/openai-logomark.e026557a.svg": {
              "data": "",
              "headers": [
                [
                  "content-length",
                  "0"
                ]
              ],
              "ok": false,
              "status": 404,
              "status_text": ""
            }
          }
        },
        "id": "jHJb63LQm2If",
        "outputId": "2ebcd166-88f6-4af1-de57-540b2c08567d"
      },
      "outputs": [],
      "source": [
        "from IPython.display import display, Markdown\n",
        "\n",
        "display(Markdown(docs[0]))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3km3-7WcnYk6"
      },
      "source": [
        "### Build a Weather Tool"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "WEATHER_API_KEY = os.getenv('WEATHER_API_KEY')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZM8R-JgOnXdN"
      },
      "outputs": [],
      "source": [
        "import requests\n",
        "\n",
        "@tool\n",
        "def get_weather(query: str) -> list:\n",
        "    \"\"\"Search weatherapi to get the current weather.\"\"\"\n",
        "    url = f\"https://api.openweathermap.org/data/2.5/weather?q={query},IN&appid={WEATHER_API_KEY}&units=metric\"\n",
        "\n",
        "    response = requests.get(url)\n",
        "    data = response.json()\n",
        "    if data.get(\"name\"):\n",
        "        return data\n",
        "    else:\n",
        "        return \"Weather Data Not Found\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "12xdLSJ3ZUiv",
        "outputId": "cbf2b782-48b1-4417-960d-b599278bb199"
      },
      "outputs": [],
      "source": [
        "import rich\n",
        "\n",
        "result = get_weather.invoke(\"Bangalore\")\n",
        "rich.print_json(data=result)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 914
        },
        "id": "dyL1L1ifn0mj",
        "outputId": "9fee08e8-31de-4671-c2d4-d43b1f6ef554"
      },
      "outputs": [],
      "source": [
        "import rich\n",
        "\n",
        "result = get_weather.invoke(\"Kolkata\")\n",
        "rich.print_json(data=result)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bIOhB430gpW9"
      },
      "source": [
        "## Explore LLM tool calling with custom tools\n",
        "\n",
        "An agent is basically an LLM which has the capability to automatically call relevant functions to perform complex or tool-based tasks based on input human prompts.\n",
        "\n",
        "Tool calling also popularly known as function calling is the ability to reliably enable such LLMs to call external tools and APIs.\n",
        "\n",
        "We will leverate the custom tools we created earlier in the previous section and try to see if the LLM can automatically call the right tools based on input prompts"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4Y26Ohn3P54j"
      },
      "source": [
        "### Tool calling for LLMs with native support for tool or function calling"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1nACq0NgL5yM"
      },
      "source": [
        "Tool calling allows a model to respond to a given prompt by generating output that matches a user-defined schema. While the name implies that the model is performing some action, this is actually not the case! The model is coming up with the arguments to a tool, and actually running the tool (or not) is up to the user or agent defined by the user.\n",
        "\n",
        "Many LLM providers, including Anthropic, Cohere, Google, Mistral, OpenAI, and others, support variants of a tool calling feature. These features typically allow requests to the LLM to include available tools and their schemas, and for responses to include calls to these tools.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "s0wCNpzCBvtS",
        "outputId": "9cf3776a-5fe1-4bbb-fcde-70ff7bca9b1f"
      },
      "outputs": [],
      "source": [
        "from langchain_openai import ChatOpenAI\n",
        "\n",
        "chatgpt = ChatOpenAI(model=\"gpt-4o\", temperature=0)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rjKWxFNgB2t_"
      },
      "outputs": [],
      "source": [
        "tools = [multiply, search_web_extract_info, get_weather]\n",
        "chatgpt_with_tools = chatgpt.bind_tools(tools)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hJ271K_tB9K7"
      },
      "outputs": [],
      "source": [
        "# LLMs are still not perfect in tool calling so you might need to play around with the following prompt\n",
        "from langchain_core.messages import HumanMessage, ToolMessage\n",
        "\n",
        "# prompt = \"\"\"\n",
        "#             Given only the tools at your disposal, mention tool calls for the following tasks:\n",
        "#             Do not change the query given for any search tasks\n",
        "#             1. What is 2.1 times 3.5\n",
        "#             2. What is the current weather in Bangalore today\n",
        "#             3. What are the 4 major Agentic AI Design Patterns\n",
        "#          \"\"\"\n",
        "\n",
        "prompt = [\n",
        "    HumanMessage(\n",
        "        \"\"\"\n",
        "            Given only the tools at your disposal, mention tool calls for the following tasks:\n",
        "            Do not change the query given for any search tasks\n",
        "            1. What is 2.1 times 3.5\n",
        "         \"\"\"\n",
        "    )\n",
        "]\n",
        "\n",
        "results = chatgpt_with_tools.invoke(prompt)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "prompt.append(results)\n",
        "prompt"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ckZz5pcpCQau",
        "outputId": "4e96c257-c347-45cd-f5ec-6e1c071d9f86"
      },
      "outputs": [],
      "source": [
        "results.tool_calls"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "POvGp_xZCpSg",
        "outputId": "56aef3e3-78d7-416e-e0a9-553ae3f7e9c8"
      },
      "outputs": [],
      "source": [
        "toolkit = {\n",
        "    \"multiply\": multiply,\n",
        "    \"search_web_extract_info\": search_web_extract_info,\n",
        "    \"get_weather\": get_weather\n",
        "}\n",
        "\n",
        "for tool_call in results.tool_calls:\n",
        "    selected_tool = toolkit[tool_call[\"name\"].lower()]\n",
        "    print(f\"Calling tool: {tool_call['name']}\")\n",
        "    tool_output = selected_tool.invoke(tool_call[\"args\"])\n",
        "    print(tool_output)\n",
        "    updated_prompt = prompt[:-1].append(ToolMessage(tool_output, tool_call_id=tool_call[\"id\"]))\n",
        "    print(updated_prompt)\n",
        "    response = chatgpt_with_tools.invoke(updated_prompt)\n",
        "    response.content"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_1Yc8d9MQDqa"
      },
      "source": [
        "### Tool calling for LLMs without native support for tool or function calling"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yIXJC1-9RXnx"
      },
      "source": [
        "Some models like ChatGPT have been fine-tuned for tool calling and provide a dedicated API for tool calling. Generally, such models are better at tool calling than non-fine-tuned models, and are recommended for use cases that require tool calling.\n",
        "\n",
        "Here we will explore an alternative method to invoke tools if you're using a model that does not natively support tool calling (even though we use ChatGPT here which supports it, we will assume it could be any LLM which doesn't support tool calling).\n",
        "\n",
        "We'll do this by simply writing a prompt that will get the model to invoke the appropriate tools."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xr2Wt-iuHEuw",
        "outputId": "f855c868-140a-4ad6-d107-92828004566b"
      },
      "outputs": [],
      "source": [
        "from langchain_core.output_parsers import JsonOutputParser\n",
        "from langchain_core.prompts import ChatPromptTemplate\n",
        "from langchain_core.tools import render_text_description\n",
        "\n",
        "rendered_tools = render_text_description(tools)\n",
        "print(rendered_tools)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sO8AT_uiK3zV"
      },
      "outputs": [],
      "source": [
        "system_prompt = f\"\"\"\\\n",
        "You are an assistant that has access to the following set of tools.\n",
        "Here are the names and descriptions for each tool:\n",
        "\n",
        "{rendered_tools}\n",
        "\n",
        "Given the user instructions, for each instruction do the following:\n",
        " - Return the name and input of the tool to use.\n",
        " - Return your response as a JSON blob with 'name' and 'arguments' keys.\n",
        " - The `arguments` should be a dictionary, with keys corresponding\n",
        "   to the argument names and the values corresponding to the requested values.\n",
        "\"\"\"\n",
        "\n",
        "prompt = ChatPromptTemplate.from_messages(\n",
        "    [\n",
        "        (\"system\", system_prompt),\n",
        "        (\"user\", \"{input}\")\n",
        "    ]\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "aNq3a5B9HEy-"
      },
      "outputs": [],
      "source": [
        "instructions = [\n",
        "                  {\"input\" : \"What is 2.1 times 3.5\"},\n",
        "                  {\"input\" : \"What is the current weather in Greenland\"},\n",
        "                  {\"input\" : \"Tell me about the current state of Agentic AI in the industry\" }\n",
        "               ]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GJWWhI0NHE3J"
      },
      "outputs": [],
      "source": [
        "from langchain_core.output_parsers import JsonOutputParser\n",
        "\n",
        "chain = (prompt\n",
        "            |\n",
        "         chatgpt\n",
        "            |\n",
        "         JsonOutputParser())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "a8O7pvViHE5l",
        "outputId": "9a5c31a2-63d9-4637-e0d5-96c1257e1f8b"
      },
      "outputs": [],
      "source": [
        "responses = chain.map().invoke(instructions)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4F7Cqo6yMGzU",
        "outputId": "0f1e4782-6b84-44fa-fe3f-25882d82fcd3"
      },
      "outputs": [],
      "source": [
        "responses"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rLsWGvOkM5Qe",
        "outputId": "29df7cdd-dd9e-494a-c7a3-9b0b70bb4758"
      },
      "outputs": [],
      "source": [
        "toolkit = {\n",
        "    \"multiply\": multiply,\n",
        "    \"search_web_extract_info\": search_web_extract_info,\n",
        "    \"get_weather\": get_weather\n",
        "}\n",
        "\n",
        "for tool_call in responses:\n",
        "    selected_tool = toolkit[tool_call[\"name\"].lower()]\n",
        "    print(f\"Calling tool: {tool_call['name']}\")\n",
        "    tool_output = selected_tool.invoke(tool_call[\"arguments\"])\n",
        "    print(tool_output)\n",
        "    print()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mOS3qwf6tKNF",
        "outputId": "b7caee23-452d-4de5-b0cd-909a5fc7ff62"
      },
      "outputs": [],
      "source": [
        "for doc in tool_output:\n",
        "    print(doc)\n",
        "    print()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": ".venv",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.13.7"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
