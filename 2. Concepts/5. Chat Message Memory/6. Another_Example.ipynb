{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "016143da",
   "metadata": {},
   "source": [
    "## Example 1: Message Placeholder with ConversationBufferMemory\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9ed6198",
   "metadata": {},
   "source": [
    "### Step 1: Import basics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "6e177c4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# =============================================================================\n",
    "# ESSENTIAL IMPORTS FOR CHAT MESSAGE MEMORY\n",
    "# =============================================================================\n",
    "\n",
    "# ChatOpenAI: LangChain's wrapper for OpenAI's chat models (GPT-3.5, GPT-4, etc.)\n",
    "from langchain_openai import ChatOpenAI\n",
    "\n",
    "# ChatPromptTemplate: Creates structured prompts for chat models\n",
    "# MessagesPlaceholder: A placeholder in prompts where conversation history gets injected\n",
    "from langchain_core.prompts import ChatPromptTemplate, MessagesPlaceholder\n",
    "\n",
    "# StrOutputParser: Converts LLM output (AIMessage) to a plain string\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "\n",
    "# SQLChatMessageHistory: Persists chat history to a SQLite database\n",
    "# This enables conversation memory that survives application restarts\n",
    "from langchain_community.chat_message_histories import SQLChatMessageHistory\n",
    "\n",
    "# RunnableWithMessageHistory: The key component that wraps any chain with automatic\n",
    "# message history management - it handles loading, saving, and injecting history\n",
    "from langchain_core.runnables.history import RunnableWithMessageHistory\n",
    "\n",
    "from langchain.prompts import ChatPromptTemplate, MessagesPlaceholder\n",
    "from langchain.memory import ConversationBufferMemory\n",
    "from langchain.chains import LLMChain\n",
    "\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "30373310",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# =============================================================================\n",
    "# ENVIRONMENT SETUP\n",
    "# =============================================================================\n",
    "# Load environment variables from .env file\n",
    "# This is where we store sensitive API keys (OPENAI_API_KEY, GROQ_API_KEY, etc.)\n",
    "# Never hardcode API keys in your code - always use environment variables!\n",
    "\n",
    "from dotenv import load_dotenv\n",
    "import os\n",
    "\n",
    "# load_dotenv() searches for a .env file and loads its contents as environment variables\n",
    "# Returns True if successful, False otherwise\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "b48d3be3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# =============================================================================\n",
    "# INITIALIZE THE LLM (Large Language Model)\n",
    "# =============================================================================\n",
    "\n",
    "# ChatOpenAI creates a connection to OpenAI's chat API\n",
    "# Parameters:\n",
    "#   - model_name: Which GPT model to use ('gpt-4o-mini' is cost-effective and fast)\n",
    "#   - temperature: Controls randomness (0 = deterministic, 1 = creative)\n",
    "#                  Lower values = more consistent, predictable responses\n",
    "#                  Higher values = more varied, creative responses\n",
    "\n",
    "chatgpt = ChatOpenAI(model_name='gpt-4o-mini', temperature=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff6d9610",
   "metadata": {},
   "source": [
    "### Step 2: Create memory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "5b958e56",
   "metadata": {},
   "outputs": [],
   "source": [
    "memory = ConversationBufferMemory(\n",
    "    memory_key=\"chat_history\",\n",
    "    return_messages=True\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "454a29f1",
   "metadata": {},
   "source": [
    "### Step 3: Create prompt with Message Placeholder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "7a59499c",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt = ChatPromptTemplate.from_messages([\n",
    "    (\"system\", \"You are a helpful assistant\"),\n",
    "    MessagesPlaceholder(variable_name=\"chat_history\"),\n",
    "    (\"human\", \"{question}\")\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5eed5192",
   "metadata": {},
   "source": [
    "### Step 4: Create chain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "e4682c38",
   "metadata": {},
   "outputs": [],
   "source": [
    "chain = LLMChain(\n",
    "    llm=chatgpt,\n",
    "    prompt=prompt,\n",
    "    memory=memory\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40b3b199",
   "metadata": {},
   "source": [
    "### Step 5: Chat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "9e4313af",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Your name is Sourav. How can I help you today?'"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chain.run(\"My name is Sourav\")\n",
    "chain.run(\"What is my name?\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c504b305",
   "metadata": {},
   "source": [
    "Example 2: Message Placeholder with SQLChatMessageHistory\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "24271927",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.memory.chat_message_histories import SQLChatMessageHistory\n",
    "\n",
    "chat_history = SQLChatMessageHistory(\n",
    "    session_id=\"user_123\",\n",
    "    connection_string=\"sqlite:///chat.db\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "e4f11e5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.memory import ConversationBufferMemory\n",
    "\n",
    "memory = ConversationBufferMemory(\n",
    "    chat_memory=chat_history,\n",
    "    memory_key=\"chat_history\",\n",
    "    return_messages=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "d63339f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt = ChatPromptTemplate.from_messages([\n",
    "    (\"system\", \"You are a helpful assistant\"),\n",
    "    MessagesPlaceholder(variable_name=\"chat_history\"),\n",
    "    (\"human\", \"{question}\")\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "d37866d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "chain = LLMChain(\n",
    "    llm=ChatOpenAI(),\n",
    "    prompt=prompt,\n",
    "    memory=memory\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "7e4e88c6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"I'm here to assist you with information and guidance to the best of my abilities. If you have any questions or need help with anything specific about Bangalore, please let me know, and I'll be happy to assist you.\""
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chain.run(\"I live in Bangalore\")\n",
    "chain.run(\"Where do I live?\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77341c54",
   "metadata": {},
   "source": [
    "https://chatgpt.com/share/6940995b-1978-800a-93ab-c9634c47d502"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae40edce",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
