{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "205ddd42",
   "metadata": {},
   "source": [
    "Reference:\n",
    "\n",
    "[**Introduction to LangChain for Agentic AI**](https://courses.analyticsvidhya.com/courses/take/introduction-to-langchain-for-agentic-ai/lessons/61748853-course-introduction) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d3ef54a",
   "metadata": {},
   "source": [
    "# Exploring Conversation Chains and Memory with LCEL"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91950cda",
   "metadata": {},
   "source": [
    "## Install OpenAI, and LangChain dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ace8d78b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install -qq langchain\n",
    "# !pip install -qq langchain-openai\n",
    "# !pip install -qq langchain-community\n",
    "# !pip install -qq langchain-chroma"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86e16309",
   "metadata": {},
   "source": [
    "## Enter Open AI API Key"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9112fa95",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76fbc8f2",
   "metadata": {},
   "source": [
    "## Load Connection to LLM\n",
    "\n",
    "Here we create a connection to ChatGPT to use later in our chains"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0d4c931d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_openai import ChatOpenAI\n",
    "\n",
    "chatgpt = ChatOpenAI(model_name='gpt-4o-mini', temperature=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3efeeecb",
   "metadata": {},
   "source": [
    "## Working with LangChain Chains\n",
    "\n",
    "Using an LLM in isolation is fine for simple applications, but more complex applications require chaining LLMs - either with each other or with other components. Also running on multiple data points can be done easily with chains.\n",
    "\n",
    "Chain's are the legacy interface for \"chained\" applications. We define a Chain very generically as a sequence of calls to components, which can include other chains.\n",
    "\n",
    "Here we will be using LCEL chains exclusively"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56b81c94",
   "metadata": {},
   "source": [
    "### The Problem with Simple LLM Chains\n",
    "\n",
    "Simple LLM Chains cannot keep a track of past conversation history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "18e253fd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The capital of France is Paris.\n"
     ]
    }
   ],
   "source": [
    "from langchain_core.prompts import ChatPromptTemplate,PromptTemplate\n",
    "\n",
    "prompt_text = \"\"\"{query}\"\"\"\n",
    "prompt = ChatPromptTemplate.from_template(prompt_text)\n",
    "\n",
    "llm_chain = prompt | chatgpt\n",
    "\n",
    "response = llm_chain.invoke({\"query\": \"What is the capital of France?\"})\n",
    "print(response.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3d1c9b6d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Could you please provide more context or specify what aspect of India you are interested in? India is a vast country with a rich history, diverse culture, and significant developments in various fields such as politics, economy, technology, and social issues. Let me know what specific information you are looking for!\n"
     ]
    }
   ],
   "source": [
    "response = llm_chain.invoke({\"query\":\"And what about India?\"})\n",
    "print(response.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad4c4688",
   "metadata": {},
   "source": [
    "## Conversation Chains with LCEL\n",
    "\n",
    "LangChain Expression Language (LCEL) connects prompts, models, parsers and retrieval components using a `|` pipe operator.\n",
    "\n",
    "A conversation chain basically consists of user prompts, historical conversation memory and the LLM. The LLM uses the history memory to give more contextual answers to every new prompt or user query.\n",
    "\n",
    "Memory is very important for having a true conversation with LLMs. LangChain allows us to manage conversation memory using various constructs. The main ones we will cover include:\n",
    "\n",
    "- ConversationBufferMemory\n",
    "- ConversationBufferWindowMemory\n",
    "- ConversationSummaryMemory\n",
    "- VectorStoreRetrieverMemory\n",
    "- ChatMessageHistory\n",
    "- SQLChatMessageHistory"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0eea1254",
   "metadata": {},
   "source": [
    "\n",
    "These specialized memory classes implement different approaches to managing conversation context.They determines what information is retained and how it's presented to the language model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f316d7c",
   "metadata": {},
   "source": [
    "## Conversation Chains with ConversationBufferMemory\n",
    "\n",
    "This is the simplest version of in-memory storage of historical conversation messages. It is basically a buffer for storing conversation memory.\n",
    "\n",
    "Remember if you have a really long conversation, you might exceed the max token limit of the context window allowed for the LLM."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32728699",
   "metadata": {},
   "source": [
    "The `return_messages=True` parameter in `ConversationBufferMemory` controls the **format** in which conversation history is returned.\n",
    "\n",
    "## What it does:\n",
    "\n",
    "| `return_messages` | History Format | Use Case |\n",
    "|---|---|---|\n",
    "| `True` | List of message objects (`HumanMessage`, `AIMessage`) | Chat models (like `ChatOpenAI`) |\n",
    "| `False` (default) | Single formatted string | Completion-style LLMs |\n",
    "\n",
    "## Why it matters here:\n",
    "\n",
    "In your code, you're using:\n",
    "\n",
    "```14:14:2. Concepts/4. Chat Message Memory/2.2 Conversation_Chains_and_Memory_with_LCEL.ipynb\n",
    "memory = ConversationBufferMemory(return_messages=True)\n",
    "```\n",
    "\n",
    "This is required because your prompt uses `MessagesPlaceholder`:\n",
    "\n",
    "```9:9:2. Concepts/4. Chat Message Memory/2.2 Conversation_Chains_and_Memory_with_LCEL.ipynb\n",
    "        MessagesPlaceholder(variable_name=\"history\"), # This is where the conversation history will be stored\n",
    "```\n",
    "\n",
    "`MessagesPlaceholder` expects a **list of message objects**, not a string.\n",
    "\n",
    "## Example comparison:\n",
    "\n",
    "**With `return_messages=True`:**\n",
    "```python\n",
    "memory.load_memory_variables({})['history']\n",
    "# Returns: [HumanMessage(content='Hello'), AIMessage(content='Hi there!')]\n",
    "```\n",
    "\n",
    "**With `return_messages=False`:**\n",
    "```python\n",
    "memory.load_memory_variables({})['history']\n",
    "# Returns: \"Human: Hello\\nAI: Hi there!\"\n",
    "```\n",
    "\n",
    "Since you're using `ChatOpenAI` (a chat model) with `ChatPromptTemplate`, you need the message objects formatâ€”hence `return_messages=True` is the correct choice."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "24257419",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.prompts import ChatPromptTemplate, MessagesPlaceholder\n",
    "from langchain.memory import ConversationBufferMemory\n",
    "from langchain.schema.runnable import RunnablePassthrough, RunnableLambda\n",
    "\n",
    "SYS_PROMPT = \"\"\"Act as a helpful assistant and give brief answers\"\"\"\n",
    "prompt = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        (\"system\", SYS_PROMPT),\n",
    "        MessagesPlaceholder(variable_name=\"history\"), # This is where the conversation history will be stored\n",
    "        (\"human\", \"{query}\"),\n",
    "    ]\n",
    ")\n",
    "\n",
    "memory = ConversationBufferMemory(return_messages=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "8254735a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'langchain.memory.buffer.ConversationBufferMemory'>\n"
     ]
    }
   ],
   "source": [
    "print(type(memory))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "6ead6b46",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'history': []}\n"
     ]
    }
   ],
   "source": [
    "# function to get historical conversation messages from the memory\n",
    "print(memory.load_memory_variables({}))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "c2d447db",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Direct buffer access:\n",
      "[]\n"
     ]
    }
   ],
   "source": [
    "# Get buffer content directly\n",
    "print(f\"\\nDirect buffer access:\\n{memory.buffer}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "c8d65341",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[]\n"
     ]
    }
   ],
   "source": [
    "print(memory.load_memory_variables({})['history'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "0acd0936",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[]\n"
     ]
    }
   ],
   "source": [
    "# lets create a function now which returns the list of messages from memory\n",
    "def get_memory_messages(query):\n",
    "    return memory.load_memory_variables(query)['history']\n",
    "\n",
    "print(get_memory_messages('What are the first four colors of a rainbow?'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "8f5af102",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "langchain_core.runnables.base.RunnableLambda"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(RunnableLambda(get_memory_messages))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "01afa779",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[]\n"
     ]
    }
   ],
   "source": [
    "# testing out the function with a runnable lambda which will go into our chain\n",
    "# this returns the history but we also need to send our current query to the prompt\n",
    "print(RunnableLambda(get_memory_messages).invoke({'query': 'What are the first four colors of a rainbow?'}))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "eaa66797",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'query': 'What are the first four colors of a rainbow1?',\n",
       " 'query2': 'sourav',\n",
       " 'history': []}"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# We use RunnablePassthrough.assign() to combine the current input with memory history\n",
    "# This allows us to pass the query unchanged while adding the conversation history\n",
    "# The .assign() method adds a new key 'history' to the input dictionary\n",
    "# RunnableLambda(get_memory_messages) extracts the conversation history from memory\n",
    "RunnablePassthrough.assign(\n",
    "        history=RunnableLambda(get_memory_messages)\n",
    "    ).invoke({'query': 'What are the first four colors of a rainbow1?','query2':\"sourav\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "4e299f5e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'query': 'sourav', 'history': []}"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chain1 = {\n",
    "    'query': RunnableLambda(lambda x: x['query2'])\n",
    "} |RunnablePassthrough.assign(\n",
    "        history=RunnableLambda(get_memory_messages)\n",
    "    )\n",
    "chain1.invoke({'query1': 'What are the first four colors of a rainbow1?','query2':\"sourav\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "0e3b1dca",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'query': 'What are the first four colors of a rainbow1?', 'history': []}"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chain2 = {\n",
    "    'query': RunnableLambda(lambda x: x['query1'])\n",
    "} |RunnablePassthrough.assign(\n",
    "        history=RunnableLambda(get_memory_messages)\n",
    "    )\n",
    "\n",
    "chain2.invoke({'query1': 'What are the first four colors of a rainbow1?','query2':\"sourav\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "0f8ec867",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'What are the first four colors of a rainbow1?'"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "runnable = RunnableLambda(lambda x: x['query1'])\n",
    "runnable.invoke({'query1': 'What are the first four colors of a rainbow1?', 'query2': \"sourav\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "8cfa6b50",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'query': 'What are the first four colors of a rainbow1?',\n",
       " 'llm1': 'completion',\n",
       " 'llm2': 'completion',\n",
       " 'history': []}"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def fake_llm(prompt: str) -> str: # Fake LLM for the example\n",
    "    return \"completion\"\n",
    "\n",
    "chain = {\n",
    "    'query': RunnableLambda(lambda x: x['query']), \n",
    "    'llm1':  fake_llm,\n",
    "    'llm2':  fake_llm,\n",
    "} | RunnablePassthrough.assign(\n",
    "    history=RunnableLambda(get_memory_messages)\n",
    ")\n",
    "\n",
    "chain.invoke({'query': 'What are the first four colors of a rainbow1?'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c85f56fd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "content='The first four colors of a rainbow are red, orange, yellow, and green.' additional_kwargs={'refusal': None} response_metadata={'token_usage': {'completion_tokens': 17, 'prompt_tokens': 30, 'total_tokens': 47, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_name': 'gpt-4o-mini-2024-07-18', 'system_fingerprint': 'fp_11f3029f6b', 'id': 'chatcmpl-CllE6wigfYOAsAdhyYmsZprFwaufu', 'finish_reason': 'stop', 'logprobs': None} id='run-5365c3bd-5541-4189-b1bb-70f41a97bb91-0' usage_metadata={'input_tokens': 30, 'output_tokens': 17, 'total_tokens': 47, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}}\n"
     ]
    }
   ],
   "source": [
    "from langchain_core.prompts import ChatPromptTemplate, MessagesPlaceholder\n",
    "from langchain.memory import ConversationBufferMemory\n",
    "from langchain.schema.runnable import RunnablePassthrough, RunnableLambda\n",
    "\n",
    "SYS_PROMPT = \"\"\"Act as a helpful assistant and give brief answers\"\"\"\n",
    "prompt = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        (\"system\", SYS_PROMPT),\n",
    "        MessagesPlaceholder(variable_name=\"history\"), # This is where the conversation history will be stored\n",
    "        (\"human\", \"{query}\"),\n",
    "    ]\n",
    ")\n",
    "\n",
    "memory = ConversationBufferMemory(return_messages=True)\n",
    "\n",
    "# creating our conversation chain now\n",
    "def get_memory_messages(query):\n",
    "    return memory.load_memory_variables(query)['history']\n",
    "\n",
    "conversation_chain = (\n",
    "    RunnablePassthrough.assign(\n",
    "        history=RunnableLambda(get_memory_messages)\n",
    "    ) # sends current query (input by user at runtime) and history messages to next step\n",
    "      |\n",
    "    prompt # creates prompt using the previous two variables\n",
    "      |\n",
    "    chatgpt # generates response using the prompt from previous step\n",
    ")\n",
    "\n",
    "query = {'query': 'What are the first four colors of a rainbow?'}\n",
    "response = conversation_chain.invoke(query)\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "469eb5f0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'content': 'The first four colors of a rainbow are red, orange, yellow, and green.',\n",
       " 'additional_kwargs': {'refusal': None},\n",
       " 'response_metadata': {'token_usage': {'completion_tokens': 17,\n",
       "   'prompt_tokens': 30,\n",
       "   'total_tokens': 47,\n",
       "   'completion_tokens_details': {'accepted_prediction_tokens': 0,\n",
       "    'audio_tokens': 0,\n",
       "    'reasoning_tokens': 0,\n",
       "    'rejected_prediction_tokens': 0},\n",
       "   'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}},\n",
       "  'model_name': 'gpt-4o-mini-2024-07-18',\n",
       "  'system_fingerprint': 'fp_11f3029f6b',\n",
       "  'id': 'chatcmpl-CllE6wigfYOAsAdhyYmsZprFwaufu',\n",
       "  'finish_reason': 'stop',\n",
       "  'logprobs': None},\n",
       " 'type': 'ai',\n",
       " 'name': None,\n",
       " 'id': 'run-5365c3bd-5541-4189-b1bb-70f41a97bb91-0',\n",
       " 'example': False,\n",
       " 'tool_calls': [],\n",
       " 'invalid_tool_calls': [],\n",
       " 'usage_metadata': {'input_tokens': 30,\n",
       "  'output_tokens': 17,\n",
       "  'total_tokens': 47,\n",
       "  'input_token_details': {'audio': 0, 'cache_read': 0},\n",
       "  'output_token_details': {'audio': 0, 'reasoning': 0}}}"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# response.dict() #deprecated\n",
    "response.model_dump()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "1d800c5c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The first four colors of a rainbow are red, orange, yellow, and green.\n"
     ]
    }
   ],
   "source": [
    "print(response.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "af24bf50",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[]\n"
     ]
    }
   ],
   "source": [
    "print(memory.load_memory_variables({})['history'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "0f806661",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'query': 'What are the first four colors of a rainbow?'}"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "query"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "02985654",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the current conversation turn to memory.\n",
    "# This ensures that the user's query and the model's response are stored,\n",
    "# so that future queries can access the full conversation history.\n",
    "# The `save_context` method takes the input query and the output response as arguments.\n",
    "# Here, we save the query and the model's response content.\n",
    "memory.save_context(query, {\"output\": response.content})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "bf6b62d2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[HumanMessage(content='What are the first four colors of a rainbow?', additional_kwargs={}, response_metadata={}), AIMessage(content='The first four colors of a rainbow are red, orange, yellow, and green.', additional_kwargs={}, response_metadata={})]\n"
     ]
    }
   ],
   "source": [
    "# Let's inspect the current conversation history in memory.\n",
    "# This will show all previous exchanges (user queries and model responses) stored so far.\n",
    "print(memory.load_memory_variables({})['history'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "81a50609",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== Messages in Chat Memory ===\n",
      "1. human: What are the first four colors of a rainbow?\n",
      "2. ai: The first four colors of a rainbow are red, orange, yellow, and green.\n"
     ]
    }
   ],
   "source": [
    "print(\"=== Messages in Chat Memory ===\")\n",
    "for i, message in enumerate(memory.chat_memory.messages):\n",
    "    print(f\"{i+1}. {message.type}: {message.content}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "62f6156d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Memory as string:\n",
      "[HumanMessage(content='What are the first four colors of a rainbow?', additional_kwargs={}, response_metadata={}), AIMessage(content='The first four colors of a rainbow are red, orange, yellow, and green.', additional_kwargs={}, response_metadata={})]\n"
     ]
    }
   ],
   "source": [
    "# Get memory as variables (what would be passed to prompt)\n",
    "memory_vars = memory.load_memory_variables({})\n",
    "print(f\"\\nMemory as string:\\n{memory_vars['history']}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "a89ec967",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The other three colors of a rainbow are blue, indigo, and violet.\n"
     ]
    }
   ],
   "source": [
    "query = {'query': 'and the other 3?'}\n",
    "response = conversation_chain.invoke(query)\n",
    "memory.save_context(query, {\"output\": response.content}) # remember to save your current conversation in memory\n",
    "print(response.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "25fdc930",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[HumanMessage(content='What are the first four colors of a rainbow?', additional_kwargs={}, response_metadata={}), AIMessage(content='The first four colors of a rainbow are red, orange, yellow, and green.', additional_kwargs={}, response_metadata={}), HumanMessage(content='and the other 3?', additional_kwargs={}, response_metadata={}), AIMessage(content='The other three colors of a rainbow are blue, indigo, and violet.', additional_kwargs={}, response_metadata={})]\n"
     ]
    }
   ],
   "source": [
    "print(memory.load_memory_variables({})['history'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "0bf6abe5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[HumanMessage(content='What are the first four colors of a rainbow?', additional_kwargs={}, response_metadata={}),\n",
       " AIMessage(content='The first four colors of a rainbow are red, orange, yellow, and green.', additional_kwargs={}, response_metadata={}),\n",
       " HumanMessage(content='and the other 3?', additional_kwargs={}, response_metadata={}),\n",
       " AIMessage(content='The other three colors of a rainbow are blue, indigo, and violet.', additional_kwargs={}, response_metadata={})]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "memory.load_memory_variables({})['history']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "3767e35b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== Messages in Chat Memory ===\n",
      "1. human: What are the first four colors of a rainbow?\n",
      "2. ai: The first four colors of a rainbow are red, orange, yellow, and green.\n",
      "3. human: and the other 3?\n",
      "4. ai: The other three colors of a rainbow are blue, indigo, and violet.\n"
     ]
    }
   ],
   "source": [
    "print(\"=== Messages in Chat Memory ===\")\n",
    "for i, message in enumerate(memory.chat_memory.messages):\n",
    "    print(f\"{i+1}. {message.type}: {message.content}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "f0246457",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "- **Definition**: Artificial Intelligence (AI) refers to the simulation of human intelligence in machines programmed to think and learn, enabling them to perform tasks that typically require human cognitive functions, such as problem-solving, understanding language, and recognizing patterns.\n",
      "\n",
      "- **Applications**: AI is used in various fields, including healthcare (diagnosis and treatment recommendations), finance (fraud detection and algorithmic trading), and everyday technology (virtual assistants and recommendation systems).\n"
     ]
    }
   ],
   "source": [
    "query = {'query': 'Explain AI in 2 bullet points'}\n",
    "response = conversation_chain.invoke(query)\n",
    "memory.save_context(query, {\"output\": response.content}) # remember to save your current conversation in memory\n",
    "print(response.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "5a4268d0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== Messages in Chat Memory ===\n",
      "1. human: What are the first four colors of a rainbow?\n",
      "2. ai: The first four colors of a rainbow are red, orange, yellow, and green.\n",
      "3. human: and the other 3?\n",
      "4. ai: The other three colors of a rainbow are blue, indigo, and violet.\n",
      "5. human: Explain AI in 2 bullet points\n",
      "6. ai: - **Definition**: Artificial Intelligence (AI) refers to the simulation of human intelligence in machines programmed to think and learn, enabling them to perform tasks that typically require human cognitive functions, such as problem-solving, understanding language, and recognizing patterns.\n",
      "\n",
      "- **Applications**: AI is used in various fields, including healthcare (diagnosis and treatment recommendations), finance (fraud detection and algorithmic trading), and everyday technology (virtual assistants and recommendation systems).\n"
     ]
    }
   ],
   "source": [
    "print(\"=== Messages in Chat Memory ===\")\n",
    "for i, message in enumerate(memory.chat_memory.messages):\n",
    "    print(f\"{i+1}. {message.type}: {message.content}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "9d247b51",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "- **Definition**: Deep Learning is a subset of machine learning that uses neural networks with many layers (deep neural networks) to model complex patterns in large datasets, enabling machines to learn from data in a way that mimics human brain function.\n",
      "\n",
      "- **Applications**: Deep Learning is widely used in image and speech recognition, natural language processing, autonomous vehicles, and various other fields requiring advanced data analysis and pattern recognition.\n"
     ]
    }
   ],
   "source": [
    "query = {'query': 'Now do the same for Deep Learning'}\n",
    "response = conversation_chain.invoke(query)\n",
    "memory.save_context(query, {\"output\": response.content}) # remember to save your current conversation in memory\n",
    "print(response.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "b9b61a47",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== Messages in Chat Memory ===\n",
      "1. human: What are the first four colors of a rainbow?\n",
      "2. ai: The first four colors of a rainbow are red, orange, yellow, and green.\n",
      "3. human: and the other 3?\n",
      "4. ai: The other three colors of a rainbow are blue, indigo, and violet.\n",
      "5. human: Explain AI in 2 bullet points\n",
      "6. ai: - **Definition**: Artificial Intelligence (AI) refers to the simulation of human intelligence in machines programmed to think and learn, enabling them to perform tasks that typically require human cognitive functions, such as problem-solving, understanding language, and recognizing patterns.\n",
      "\n",
      "- **Applications**: AI is used in various fields, including healthcare (diagnosis and treatment recommendations), finance (fraud detection and algorithmic trading), and everyday technology (virtual assistants and recommendation systems).\n",
      "7. human: Now do the same for Deep Learning\n",
      "8. ai: - **Definition**: Deep Learning is a subset of machine learning that uses neural networks with many layers (deep neural networks) to model complex patterns in large datasets, enabling machines to learn from data in a way that mimics human brain function.\n",
      "\n",
      "- **Applications**: Deep Learning is widely used in image and speech recognition, natural language processing, autonomous vehicles, and various other fields requiring advanced data analysis and pattern recognition.\n"
     ]
    }
   ],
   "source": [
    "print(\"=== Messages in Chat Memory ===\")\n",
    "for i, message in enumerate(memory.chat_memory.messages):\n",
    "    print(f\"{i+1}. {message.type}: {message.content}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "b7a826de",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "So far, we have discussed the following topics:\n",
      "\n",
      "1. The first four colors of a rainbow (red, orange, yellow, green) and the remaining three (blue, indigo, violet).\n",
      "2. A brief explanation of Artificial Intelligence (AI) in two bullet points.\n",
      "3. A brief explanation of Deep Learning in two bullet points.\n"
     ]
    }
   ],
   "source": [
    "query = {'query': 'What have we discussed so far?'}\n",
    "response = conversation_chain.invoke(query)\n",
    "memory.save_context(query, {\"output\": response.content}) # remember to save your current conversation in memory\n",
    "print(response.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "872d0e16",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[HumanMessage(content='What are the first four colors of a rainbow?', additional_kwargs={}, response_metadata={}),\n",
       " AIMessage(content='The first four colors of a rainbow are red, orange, yellow, and green.', additional_kwargs={}, response_metadata={}),\n",
       " HumanMessage(content='and the other 3?', additional_kwargs={}, response_metadata={}),\n",
       " AIMessage(content='The other three colors of a rainbow are blue, indigo, and violet.', additional_kwargs={}, response_metadata={}),\n",
       " HumanMessage(content='Explain AI in 2 bullet points', additional_kwargs={}, response_metadata={}),\n",
       " AIMessage(content='- **Definition**: Artificial Intelligence (AI) refers to the simulation of human intelligence in machines programmed to think and learn, enabling them to perform tasks that typically require human cognitive functions, such as problem-solving, understanding language, and recognizing patterns.\\n\\n- **Applications**: AI is used in various fields, including healthcare (diagnosis and treatment recommendations), finance (fraud detection and algorithmic trading), and everyday technology (virtual assistants and recommendation systems).', additional_kwargs={}, response_metadata={}),\n",
       " HumanMessage(content='Now do the same for Deep Learning', additional_kwargs={}, response_metadata={}),\n",
       " AIMessage(content='- **Definition**: Deep Learning is a subset of machine learning that uses neural networks with many layers (deep neural networks) to model complex patterns in large datasets, enabling machines to learn from data in a way that mimics human brain function.\\n\\n- **Applications**: Deep Learning is widely used in image and speech recognition, natural language processing, autonomous vehicles, and various other fields requiring advanced data analysis and pattern recognition.', additional_kwargs={}, response_metadata={}),\n",
       " HumanMessage(content='What have we discussed so far?', additional_kwargs={}, response_metadata={}),\n",
       " AIMessage(content='So far, we have discussed the following topics:\\n\\n1. The first four colors of a rainbow (red, orange, yellow, green) and the remaining three (blue, indigo, violet).\\n2. A brief explanation of Artificial Intelligence (AI) in two bullet points.\\n3. A brief explanation of Deep Learning in two bullet points.', additional_kwargs={}, response_metadata={})]"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "memory.load_memory_variables({})['history']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "1abba5a4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== Messages in Chat Memory ===\n",
      "1. human: What are the first four colors of a rainbow?\n",
      "2. ai: The first four colors of a rainbow are red, orange, yellow, and green.\n",
      "3. human: and the other 3?\n",
      "4. ai: The other three colors of a rainbow are blue, indigo, and violet.\n",
      "5. human: Explain AI in 2 bullet points\n",
      "6. ai: - **Definition**: Artificial Intelligence (AI) refers to the simulation of human intelligence in machines programmed to think and learn, enabling them to perform tasks that typically require human cognitive functions, such as problem-solving, understanding language, and recognizing patterns.\n",
      "\n",
      "- **Applications**: AI is used in various fields, including healthcare (diagnosis and treatment recommendations), finance (fraud detection and algorithmic trading), and everyday technology (virtual assistants and recommendation systems).\n",
      "7. human: Now do the same for Deep Learning\n",
      "8. ai: - **Definition**: Deep Learning is a subset of machine learning that uses neural networks with many layers (deep neural networks) to model complex patterns in large datasets, enabling machines to learn from data in a way that mimics human brain function.\n",
      "\n",
      "- **Applications**: Deep Learning is widely used in image and speech recognition, natural language processing, autonomous vehicles, and various other fields requiring advanced data analysis and pattern recognition.\n",
      "9. human: What have we discussed so far?\n",
      "10. ai: So far, we have discussed the following topics:\n",
      "\n",
      "1. The first four colors of a rainbow (red, orange, yellow, green) and the remaining three (blue, indigo, violet).\n",
      "2. A brief explanation of Artificial Intelligence (AI) in two bullet points.\n",
      "3. A brief explanation of Deep Learning in two bullet points.\n"
     ]
    }
   ],
   "source": [
    "print(\"=== Messages in Chat Memory ===\")\n",
    "for i, message in enumerate(memory.chat_memory.messages):\n",
    "    print(f\"{i+1}. {message.type}: {message.content}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f96a382b",
   "metadata": {},
   "source": [
    "## Conversation Chains with ConversationBufferWindowMemory\n",
    "\n",
    "If you have a really long conversation, you might exceed the max token limit of the context window allowed for the LLM when using `ConversationBufferMemory` so `ConversationBufferWindowMemory` helps in just storing the last K conversations (one conversation piece is one user message and the corresponding AI message from the LLM) and thus helps you manage token limits and costs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "cf5d475a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.prompts import ChatPromptTemplate, MessagesPlaceholder\n",
    "from langchain.memory import ConversationBufferWindowMemory\n",
    "from langchain.schema.runnable import RunnablePassthrough, RunnableLambda\n",
    "\n",
    "SYS_PROMPT = \"\"\"Act as a helpful assistant and give brief answers\"\"\"\n",
    "prompt = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        (\"system\", SYS_PROMPT),\n",
    "        MessagesPlaceholder(variable_name=\"history\"),\n",
    "        (\"human\", \"{query}\"),\n",
    "    ]\n",
    ")\n",
    "\n",
    "# stores last 2 sets of human-AI conversations\n",
    "memory = ConversationBufferWindowMemory(return_messages=True, k=3)\n",
    "\n",
    "# creating our conversation chain now\n",
    "def get_memory_messages(query):\n",
    "    return memory.load_memory_variables(query)['history']\n",
    "\n",
    "conversation_chain = (\n",
    "    RunnablePassthrough.assign(\n",
    "        history=RunnableLambda(get_memory_messages)\n",
    "    ) # sends current query (input by user at runtime) and history messages to next step\n",
    "      |\n",
    "    prompt # creates prompt using the previous two variables\n",
    "      |\n",
    "    chatgpt # generates response using the prompt from previous step\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "8a4f1f06",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The first four colors of a rainbow are red, orange, yellow, and green.\n"
     ]
    }
   ],
   "source": [
    "query = {'query': 'What are the first four colors of a rainbow?'}\n",
    "response = conversation_chain.invoke(query)\n",
    "memory.save_context(query, {\"output\": response.content}) # remember to save your current conversation in memory\n",
    "print(response.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "28df3749",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The other three colors of a rainbow are blue, indigo, and violet.\n"
     ]
    }
   ],
   "source": [
    "query = {'query': 'and the other 3?'}\n",
    "response = conversation_chain.invoke(query)\n",
    "memory.save_context(query, {\"output\": response.content}) # remember to save your current conversation in memory\n",
    "print(response.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "e8f941a6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "- **Definition**: Artificial Intelligence (AI) refers to the simulation of human intelligence in machines programmed to think and learn, enabling them to perform tasks that typically require human cognitive functions, such as problem-solving, understanding language, and recognizing patterns.\n",
      "\n",
      "- **Applications**: AI is used in various fields, including healthcare (diagnosis and treatment recommendations), finance (fraud detection and algorithmic trading), and everyday technology (virtual assistants and recommendation systems).\n"
     ]
    }
   ],
   "source": [
    "query = {'query': 'Explain AI in 2 bullet points'}\n",
    "response = conversation_chain.invoke(query)\n",
    "memory.save_context(query, {\"output\": response.content}) # remember to save your current conversation in memory\n",
    "print(response.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "53730694",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "- **Definition**: Deep Learning is a subset of machine learning that uses neural networks with many layers (deep neural networks) to model complex patterns in large datasets, enabling machines to learn from data in a way that mimics human brain function.\n",
      "\n",
      "- **Applications**: Deep Learning is widely used in image and speech recognition, natural language processing, autonomous vehicles, and various other fields requiring advanced data analysis and pattern recognition.\n"
     ]
    }
   ],
   "source": [
    "query = {'query': 'Now do the same for Deep Learning'}\n",
    "response = conversation_chain.invoke(query)\n",
    "memory.save_context(query, {\"output\": response.content}) # remember to save your current conversation in memory\n",
    "print(response.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "0495b43b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[HumanMessage(content='and the other 3?', additional_kwargs={}, response_metadata={}),\n",
       " AIMessage(content='The other three colors of a rainbow are blue, indigo, and violet.', additional_kwargs={}, response_metadata={}),\n",
       " HumanMessage(content='Explain AI in 2 bullet points', additional_kwargs={}, response_metadata={}),\n",
       " AIMessage(content='- **Definition**: Artificial Intelligence (AI) refers to the simulation of human intelligence in machines programmed to think and learn, enabling them to perform tasks that typically require human cognitive functions, such as problem-solving, understanding language, and recognizing patterns.\\n\\n- **Applications**: AI is used in various fields, including healthcare (diagnosis and treatment recommendations), finance (fraud detection and algorithmic trading), and everyday technology (virtual assistants and recommendation systems).', additional_kwargs={}, response_metadata={}),\n",
       " HumanMessage(content='Now do the same for Deep Learning', additional_kwargs={}, response_metadata={}),\n",
       " AIMessage(content='- **Definition**: Deep Learning is a subset of machine learning that uses neural networks with many layers (deep neural networks) to model complex patterns in large datasets, enabling machines to learn from data in a way that mimics human brain function.\\n\\n- **Applications**: Deep Learning is widely used in image and speech recognition, natural language processing, autonomous vehicles, and various other fields requiring advanced data analysis and pattern recognition.', additional_kwargs={}, response_metadata={})]"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "memory.load_memory_variables({})['history']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "05e8ae26",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "So far, we have discussed the following topics:\n",
      "\n",
      "1. The colors of a rainbow, specifically mentioning blue, indigo, and violet.\n",
      "2. A brief explanation of Artificial Intelligence (AI) in two bullet points.\n",
      "3. A brief explanation of Deep Learning in two bullet points.\n"
     ]
    }
   ],
   "source": [
    "query = {'query': 'What have we discussed so far?'}\n",
    "response = conversation_chain.invoke(query)\n",
    "memory.save_context(query, {\"output\": response.content}) # remember to save your current conversation in memory\n",
    "print(response.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "92bce860",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[HumanMessage(content='Explain AI in 2 bullet points', additional_kwargs={}, response_metadata={}),\n",
       " AIMessage(content='- **Definition**: Artificial Intelligence (AI) refers to the simulation of human intelligence in machines programmed to think and learn, enabling them to perform tasks that typically require human cognitive functions, such as problem-solving, understanding language, and recognizing patterns.\\n\\n- **Applications**: AI is used in various fields, including healthcare (diagnosis and treatment recommendations), finance (fraud detection and algorithmic trading), and everyday technology (virtual assistants and recommendation systems).', additional_kwargs={}, response_metadata={}),\n",
       " HumanMessage(content='Now do the same for Deep Learning', additional_kwargs={}, response_metadata={}),\n",
       " AIMessage(content='- **Definition**: Deep Learning is a subset of machine learning that uses neural networks with many layers (deep neural networks) to model complex patterns in large datasets, enabling machines to learn from data in a way that mimics human brain function.\\n\\n- **Applications**: Deep Learning is widely used in image and speech recognition, natural language processing, autonomous vehicles, and various other fields requiring advanced data analysis and pattern recognition.', additional_kwargs={}, response_metadata={}),\n",
       " HumanMessage(content='What have we discussed so far?', additional_kwargs={}, response_metadata={}),\n",
       " AIMessage(content='So far, we have discussed the following topics:\\n\\n1. The colors of a rainbow, specifically mentioning blue, indigo, and violet.\\n2. A brief explanation of Artificial Intelligence (AI) in two bullet points.\\n3. A brief explanation of Deep Learning in two bullet points.', additional_kwargs={}, response_metadata={})]"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "memory.load_memory_variables({})['history']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d1bd1a8",
   "metadata": {},
   "source": [
    "## Conversation Chains with ConversationSummaryMemory\n",
    "\n",
    "If you have a really long conversation or a lot of messages, you might exceed the max token limit of the context window allowed for the LLM when using `ConversationBufferMemory`\n",
    "\n",
    "`ConversationSummaryMemory` creates a summary of the conversation history over time. This can be useful for condensing information from the conversation messages over time.\n",
    "\n",
    "This memory is most useful for longer conversations, where keeping the past message history in the prompt verbatim would take up too many tokens."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "0f9d831b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.prompts import ChatPromptTemplate, MessagesPlaceholder\n",
    "from langchain.memory import ConversationSummaryMemory\n",
    "from langchain.schema.runnable import RunnablePassthrough, RunnableLambda\n",
    "\n",
    "SYS_PROMPT = \"\"\"Act as a helpful assistant and give brief answers\"\"\"\n",
    "prompt = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        (\"system\", SYS_PROMPT),\n",
    "        # MessagesPlaceholder(variable_name=\"history\") - This placeholder inserts conversation history messages into the prompt\n",
    "        # The variable_name can be any string - \"history\", \"history_summary\", \"chat_history\", etc.\n",
    "        # It will be populated by the memory.load_memory_variables() function with the corresponding key\n",
    "        MessagesPlaceholder(variable_name=\"history_summary\"),\n",
    "        (\"human\", \"{query}\"),\n",
    "    ]\n",
    ")\n",
    "\n",
    "memory = ConversationSummaryMemory(return_messages=True, llm=chatgpt)\n",
    "# creating our conversation chain now\n",
    "def get_memory_messages(query):\n",
    "    return memory.load_memory_variables(query)['history']\n",
    "\n",
    "conversation_chain = (\n",
    "    RunnablePassthrough.assign(\n",
    "        history_summary=RunnableLambda(get_memory_messages)\n",
    "    ) # sends current query (input by user at runtime) and history messages as a summary to next step\n",
    "      |\n",
    "    prompt # creates prompt using the previous two variables\n",
    "      |\n",
    "    chatgpt # generates response using the prompt from previous step\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "0bfdb166",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "- **Definition**: Artificial Intelligence (AI) refers to the simulation of human intelligence processes by machines, particularly computer systems, enabling them to perform tasks such as learning, reasoning, and problem-solving.\n",
      "\n",
      "- **Applications**: AI is used in various fields, including healthcare (diagnosis and treatment recommendations), finance (fraud detection), autonomous vehicles, customer service (chatbots), and more, enhancing efficiency and decision-making.\n"
     ]
    }
   ],
   "source": [
    "query = {'query': 'Explain AI in 2 bullet points'}\n",
    "response = conversation_chain.invoke(query)\n",
    "memory.save_context(query, {\"output\": response.content}) # remember to save your current conversation in memory\n",
    "print(response.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "1395e453",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "- Deep learning is a subset of machine learning that uses neural networks with many layers to analyze and interpret complex data patterns, enabling tasks like image and speech recognition.\n",
      "- It is widely applied in areas such as natural language processing, computer vision, and autonomous systems, significantly improving performance in these fields.\n"
     ]
    }
   ],
   "source": [
    "query = {'query': 'Now do the same for Deep Learning'}\n",
    "response = conversation_chain.invoke(query)\n",
    "memory.save_context(query, {\"output\": response.content}) # remember to save your current conversation in memory\n",
    "print(response.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "c1980503",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'history': [SystemMessage(content='The human asks the AI to explain artificial intelligence in two bullet points. The AI defines artificial intelligence as the simulation of human intelligence processes by machines, enabling tasks like learning and problem-solving, and highlights its applications in fields such as healthcare, finance, autonomous vehicles, and customer service, which enhance efficiency and decision-making. The human then requests a similar explanation for deep learning, and the AI describes deep learning as a subset of machine learning that uses neural networks with many layers to analyze complex data patterns, enabling tasks like image and speech recognition, and notes its applications in natural language processing, computer vision, and autonomous systems, which significantly improve performance in these areas.', additional_kwargs={}, response_metadata={})]}"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "memory.load_memory_variables({})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2f36e9f",
   "metadata": {},
   "source": [
    "## Conversation Chains with VectorStoreRetrieverMemory\n",
    "\n",
    "`VectorStoreRetrieverMemory` stores historical conversation messages in a vector store and queries the top-K most \"relevant\" history messages every time it is called.\n",
    "\n",
    "This differs from most of the other Memory classes in that it doesn't explicitly track the order of interactions but retrieves history based on embedding similarity to the current question or prompt.\n",
    "\n",
    "In this case, the \"docs\" are previous conversation snippets. This can be useful to refer to relevant pieces of information that the AI was told earlier in the conversation."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6955fc9",
   "metadata": {},
   "source": [
    "### Connect to  Open AI Embedding Models\n",
    "\n",
    "LangChain enables us to access Open AI embedding models which include the newest models: a smaller and highly efficient `text-embedding-3-small` model, and a larger and more powerful `text-embedding-3-large` model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "dbe7b33f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_openai import OpenAIEmbeddings\n",
    "\n",
    "# details here: https://openai.com/blog/new-embedding-models-and-api-updates\n",
    "openai_embed_model = OpenAIEmbeddings(model='text-embedding-3-small')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06752ae7",
   "metadata": {},
   "source": [
    "### Create a Vector Database to store conversation history\n",
    "\n",
    "Here we use the Chroma vector DB and initialize an empty database collection to store conversation messages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "b5185c59",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_chroma import Chroma\n",
    "\n",
    "# create empty vector DB\n",
    "chroma_db = Chroma(collection_name='history_db',\n",
    "                   embedding_function=openai_embed_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "1927e279",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.prompts import ChatPromptTemplate, MessagesPlaceholder\n",
    "from langchain.memory import VectorStoreRetrieverMemory\n",
    "from langchain.schema.runnable import RunnablePassthrough, RunnableLambda\n",
    "\n",
    "SYS_PROMPT = \"\"\"Act as a helpful assistant and give brief answers\"\"\"\n",
    "prompt = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        (\"system\", SYS_PROMPT),\n",
    "        MessagesPlaceholder(variable_name=\"history\"),\n",
    "        (\"human\", \"{query}\"),\n",
    "    ]\n",
    ")\n",
    "\n",
    "# load 2 most similar conversation messages from vector db history for each new message \\ prompt\n",
    "# this uses cosine embedding similarity to load the top 2 similar messgages to the input prompt \\ query\n",
    "retriever = chroma_db.as_retriever(search_type=\"similarity\",\n",
    "                                   search_kwargs={\"k\": 2})\n",
    "memory = VectorStoreRetrieverMemory(retriever=retriever, return_messages=True)\n",
    "\n",
    "# creating our conversation chain now\n",
    "def get_memory_messages(query):\n",
    "    return [memory.load_memory_variables(query)['history']]\n",
    "\n",
    "conversation_chain = (\n",
    "    RunnablePassthrough.assign(\n",
    "        history=RunnableLambda(get_memory_messages)\n",
    "    ) # sends current query (input by user at runtime) and history messages to next step\n",
    "      |\n",
    "    prompt # creates prompt using the previous two variables\n",
    "      |\n",
    "    chatgpt # generates response using the prompt from previous step\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "7cbc358f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Artificial Intelligence (AI) refers to the simulation of human intelligence in machines programmed to think and learn. It encompasses various technologies, including machine learning, natural language processing, and robotics. AI can perform tasks such as speech recognition, decision-making, and problem-solving, and is used in applications like virtual assistants, autonomous vehicles, and data analysis. AI continues to evolve, raising both opportunities and ethical considerations.\n"
     ]
    }
   ],
   "source": [
    "query = {'query': 'Tell me about AI'}\n",
    "response = conversation_chain.invoke(query)\n",
    "memory.save_context(query, {\"output\": response.content}) # remember to save your current conversation in memory\n",
    "print(response.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "373278c3",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Number of requested results 2 is greater than number of elements in index 1, updating n_results = 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Deep learning is a subset of machine learning that uses neural networks with many layers (deep neural networks) to analyze and learn from large amounts of data. It excels in tasks such as image and speech recognition, natural language processing, and game playing. Deep learning models automatically extract features from raw data, making them highly effective for complex problems. However, they require significant computational power and large datasets for training.\n"
     ]
    }
   ],
   "source": [
    "query = {'query': 'What about deep learning'}\n",
    "response = conversation_chain.invoke(query)\n",
    "memory.save_context(query, {\"output\": response.content}) # remember to save your current conversation in memory\n",
    "print(response.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "5f7711d2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The fastest animal in the world is the peregrine falcon, which can reach speeds of over 240 mph (386 km/h) during its hunting stoop (high-speed dive). On land, the cheetah holds the title, capable of sprinting up to 60-70 mph (97-113 km/h) in short bursts.\n"
     ]
    }
   ],
   "source": [
    "query = {'query': 'Tell me about the fastest animal in the world in 2 lines'}\n",
    "response = conversation_chain.invoke(query)\n",
    "memory.save_context(query, {\"output\": response.content}) # remember to save your current conversation in memory\n",
    "print(response.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "2e7e2066",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The cheetah is the fastest land animal, capable of reaching speeds of 60-70 mph (97-113 km/h) in short bursts covering distances up to 1,500 feet (460 meters). Its unique adaptations, such as a lightweight body, long legs, and a flexible spine, enable it to accelerate rapidly and make sharp turns while chasing prey.\n"
     ]
    }
   ],
   "source": [
    "query = {'query': 'What about the cheetah?'}\n",
    "response = conversation_chain.invoke(query)\n",
    "memory.save_context(query, {\"output\": response.content}) # remember to save your current conversation in memory\n",
    "print(response.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "726d44c2",
   "metadata": {},
   "source": [
    "\n",
    "Now for a new query around machine learning even if the most recent conversation messages have been about animals, it uses the vector databases to load the last 2 historical conversations which are closest to the current question in terms of semantic similarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "1daf45df",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "query: What about deep learning\n",
      "output: Deep learning is a subset of machine learning that uses neural networks with many layers (deep neural networks) to analyze and learn from large amounts of data. It excels in tasks such as image and speech recognition, natural language processing, and game playing. Deep learning models automatically extract features from raw data, making them highly effective for complex problems. However, they require significant computational power and large datasets for training.\n",
      "query: Tell me about AI\n",
      "output: Artificial Intelligence (AI) refers to the simulation of human intelligence in machines programmed to think and learn. It encompasses various technologies, including machine learning, natural language processing, and robotics. AI can perform tasks such as speech recognition, decision-making, and problem-solving, and is used in applications like virtual assistants, autonomous vehicles, and data analysis. AI continues to evolve, raising both opportunities and ethical considerations.\n"
     ]
    }
   ],
   "source": [
    "print(memory.load_memory_variables({'query': 'What about machine learning?'})['history'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "085814d0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Machine learning is a subset of artificial intelligence that focuses on the development of algorithms that enable computers to learn from and make predictions or decisions based on data. It involves training models on datasets to identify patterns and improve performance over time without being explicitly programmed. Machine learning is used in various applications, including recommendation systems, fraud detection, and predictive analytics. It can be categorized into supervised, unsupervised, and reinforcement learning.\n"
     ]
    }
   ],
   "source": [
    "query = {'query': 'What about machine learning?'}\n",
    "response = conversation_chain.invoke(query)\n",
    "memory.save_context(query, {\"output\": response.content}) # remember to save your current conversation in memory\n",
    "print(response.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "8094c5c9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "query: What about the cheetah?\n",
      "output: The cheetah is the fastest land animal, capable of reaching speeds of 60-70 mph (97-113 km/h) in short bursts covering distances up to 1,500 feet (460 meters). Its unique adaptations, such as a lightweight body, long legs, and a flexible spine, enable it to accelerate rapidly and make sharp turns while chasing prey.\n",
      "query: Tell me about AI\n",
      "output: Artificial Intelligence (AI) refers to the simulation of human intelligence in machines programmed to think and learn. It encompasses various technologies, including machine learning, natural language processing, and robotics. AI can perform tasks such as speech recognition, decision-making, and problem-solving, and is used in applications like virtual assistants, autonomous vehicles, and data analysis. AI continues to evolve, raising both opportunities and ethical considerations.\n"
     ]
    }
   ],
   "source": [
    "print(memory.load_memory_variables({'query': 'What is the capital of India?'})['history'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29c4cf72",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
