{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "89824022",
   "metadata": {},
   "source": [
    "Reference:\n",
    "\n",
    "[**Introduction to LangChain for Agentic AI**](https://courses.analyticsvidhya.com/courses/take/introduction-to-langchain-for-agentic-ai/lessons/61748853-course-introduction) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac3739a1",
   "metadata": {},
   "source": [
    "## Install OpenAI, and LangChain dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ee837715",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install -qq langchain\n",
    "# !pip install -qq langchain-openai\n",
    "# !pip install -qq langchain-community\n",
    "# !pip install -qq langchain-chroma"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa841a89",
   "metadata": {},
   "source": [
    "## Enter Open AI API Key"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "04f6eebe",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "470c3755",
   "metadata": {},
   "source": [
    "## Load Connection to LLM\n",
    "\n",
    "Here we create a connection to ChatGPT to use later in our chains"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8752dd44",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_openai import ChatOpenAI\n",
    "\n",
    "chatgpt = ChatOpenAI(model_name='gpt-4o-mini', temperature=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "071eac75",
   "metadata": {},
   "source": [
    "## Multi-user Window-based Conversation Chains with persistence - SQLChatMessageHistory\n",
    "\n",
    "The beauty of `SQLChatMessageHistory` is that we can store separate conversation histories per user or session which is often the need for real-world chatbots which will be accessed by many users at the same time. Instead of in-memory we can store it in a SQL database which can be used to store a lot of conversations.\n",
    "\n",
    "We use a `get_session_history` function which is expected to take in a `session_id` and return a Message History object. Everything is stored in a SQL database. This `session_id` is used to distinguish between separate conversations, and should be passed in as part of the config when calling the new chain\n",
    "\n",
    "We also use a `memory_buffer_window` function to only use the top-K last historical conversations before sending it to the LLM, basically our own implementation of `ConversationBufferWindowMemory`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62faeb5d",
   "metadata": {},
   "source": [
    "\n",
    "- `ChatMessageHistory`: This is a class in LangChain that stores a sequence of chat messages (such as HumanMessage, AIMessage, SystemMessage) for a conversation. It allows you to append new messages and retrieve the full message history, which is useful for maintaining conversational context.\n",
    "\n",
    "- `BaseChatMessageHistory`: This is an abstract base class that defines the interface for chat message history storage backends. It specifies methods like add_message, get_messages, and clear, which concrete implementations (like ChatMessageHistory, RedisChatMessageHistory, etc.) must provide.\n",
    "\n",
    "- `RunnableWithMessageHistory`: This is a wrapper for a Runnable (such as a chain or LLM) that automatically manages message history for each session or user. It uses a function (like get_session_history) to retrieve the appropriate message history object based on a session ID, and injects the history into the chain's input. This enables multi-user or multi-session conversational experiences.\n",
    "\n",
    "- `MessagesPlaceholder`: This is a special prompt template variable in LangChain that acts as a placeholder for a list of messages (e.g., the conversation history). When rendering a prompt, MessagesPlaceholder is replaced with the actual messages from history, allowing the LLM to see the full conversation context.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "97b7564a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# removes the memory database file - usually not needed\n",
    "# you can run this only when you want to remove all conversation histories\n",
    "# !rm memory.db"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "76dbbcb3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community.chat_message_histories import SQLChatMessageHistory\n",
    "from langchain_core.chat_history import BaseChatMessageHistory\n",
    "from langchain_core.runnables.history import RunnableWithMessageHistory\n",
    "from langchain_core.prompts import ChatPromptTemplate, MessagesPlaceholder\n",
    "from langchain_core.runnables import RunnablePassthrough\n",
    "\n",
    "# used to retrieve conversation history from database\n",
    "# based on a specific user or session ID\n",
    "def get_session_history_db(session_id):\n",
    "    return SQLChatMessageHistory(session_id, \"sqlite:///memory.db\")\n",
    "\n",
    "# prompt to load in history and current input from the user\n",
    "prompt_template = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        (\"system\", \"Act as a helpful AI Assistant\"),\n",
    "        MessagesPlaceholder(variable_name=\"history\"),\n",
    "        (\"human\", \"{human_input}\"),\n",
    "    ]\n",
    ")\n",
    "\n",
    "# create a memory buffer window function to return the last K conversations\n",
    "def memory_buffer_window(messages, k=2):\n",
    "    return messages[-(k+1):]\n",
    "\n",
    "# create a basic LLM Chain which only sends the last K conversations per user\n",
    "llm_chain = (\n",
    "    RunnablePassthrough.assign(history=lambda x: memory_buffer_window(x[\"history\"]))\n",
    "      |\n",
    "    prompt_template\n",
    "      |\n",
    "    chatgpt\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "0dfe400b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a conversation chain which can load memory based on specific user or session id\n",
    "conv_chain = RunnableWithMessageHistory(\n",
    "    llm_chain,\n",
    "    get_session_history_db,\n",
    "    input_messages_key=\"human_input\",\n",
    "    history_messages_key=\"history\",\n",
    ")\n",
    "\n",
    "# create a utility function to take in current user input prompt and their session ID\n",
    "# streams result live back to the user from the LLM\n",
    "def chat_with_llm(prompt: str, session_id: str):\n",
    "    for chunk in conv_chain.stream({\"human_input\": prompt},\n",
    "                                   {'configurable': { 'session_id': session_id}}):\n",
    "        print(chunk.content, end=\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "bbc953be",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/sourav.banerjee/Documents/Codebases/2. AI ENGINEERING/LangChain_Demystified/.venv/lib/python3.13/site-packages/langchain_core/runnables/history.py:606: LangChainDeprecationWarning: `connection_string` was deprecated in LangChain 0.2.2 and will be removed in 1.0. Use connection instead.\n",
      "  message_history = self.get_session_history(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The fastest animal in the world is the peregrine falcon. When in a dive, it can reach speeds of over 240 miles per hour (386 kilometers per hour). If you're considering land animals, the cheetah holds the title for the fastest, capable of running speeds up to 60-70 miles per hour (97-113 kilometers per hour) in short bursts. For the fastest animal in water, the black marlin is often cited, reaching speeds of up to 82 miles per hour (132 kilometers per hour)."
     ]
    }
   ],
   "source": [
    "user_id = 'jim001'\n",
    "prompt = \"Hi can you tell me which is the fastest animal?\"\n",
    "chat_with_llm(prompt, user_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "52ccc124",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The slowest animal is often considered to be the three-toed sloth. It moves at an average speed of about 0.24 kilometers per hour (0.15 miles per hour) when climbing trees. In water, they can swim slightly faster, but their overall movement is very slow due to their low metabolic rate and energy-efficient lifestyle. Another contender for the title of slowest animal is the garden snail, which moves at a speed of about 0.03 miles per hour (0.048 kilometers per hour)."
     ]
    }
   ],
   "source": [
    "prompt = \"what about the slowest animal?\"\n",
    "chat_with_llm(prompt, user_id)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fbdf2cf9",
   "metadata": {},
   "source": [
    "\n",
    "#### ![Chat Message Memory Flow](../images/sqllite.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "23226454",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The largest animal on Earth is the blue whale (*Balaenoptera musculus*). Adult blue whales can reach lengths of up to 100 feet (30 meters) or more and can weigh as much as 200 tons (approximately 181 metric tonnes). These magnificent marine mammals are not only the largest animals alive today but are also believed to be the largest animals to have ever existed on Earth. Their size is truly remarkable, with hearts that can weigh as much as a small car and tongues that can weigh as much as an elephant!"
     ]
    }
   ],
   "source": [
    "prompt = \"what about the largest animal?\"\n",
    "chat_with_llm(prompt, user_id)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8173228b",
   "metadata": {},
   "source": [
    "In Below cell we will see the LLM always will get last 2 message in its history as we have kept window = 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "86eb8377",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sure! Here are the topics we've discussed so far:\n",
      "\n",
      "- The slowest animal (three-toed sloth and garden snail)\n",
      "- The largest animal (blue whale)"
     ]
    }
   ],
   "source": [
    "prompt = \"what topics have we discussed, show briefly as bullet points\"\n",
    "chat_with_llm(prompt, user_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "929f6b23",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sure! Here are three simple points to explain AI to a child:\n",
      "\n",
      "1. **Smart Helpers**: AI is like a smart robot or computer that can help us do things, like answering questions or playing games, by learning from lots of information.\n",
      "\n",
      "2. **Learning from Experience**: Just like you learn new things by practicing, AI learns by looking at examples and figuring out patterns, so it can get better over time.\n",
      "\n",
      "3. **Talking and Understanding**: AI can understand what we say and even talk back to us, like a friend who knows a lot and can help us find answers or tell stories!"
     ]
    }
   ],
   "source": [
    "user_id = 'john005'\n",
    "prompt = \"Explain AI in 3 bullets to a child\"\n",
    "chat_with_llm(prompt, user_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "9abec6e5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Of course! Here are three simple points to explain Generative AI to a child:\n",
      "\n",
      "1. **Creative Robot**: Generative AI is like a creative robot that can make new things, like pictures, stories, or music, all by itself!\n",
      "\n",
      "2. **Learning from Examples**: It learns by looking at lots of examples, just like how you get ideas for your drawings or stories by seeing what others have made.\n",
      "\n",
      "3. **Imagination in Action**: When you ask Generative AI to create something, it uses its imagination to come up with fun and unique ideas, almost like magic!"
     ]
    }
   ],
   "source": [
    "prompt = \"Now do the same for Generative AI\"\n",
    "chat_with_llm(prompt, user_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "c80bdac6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sure! Here are three simple points to explain machine learning to a child:\n",
      "\n",
      "1. **Learning Like You**: Machine learning is when computers learn from examples, just like you learn new things by practicing and trying different activities.\n",
      "\n",
      "2. **Finding Patterns**: It helps computers find patterns in information, like how you notice that some animals have stripes or spots, so they can make smart guesses about new things.\n",
      "\n",
      "3. **Getting Better Over Time**: The more examples the computer sees, the better it gets at understanding and making decisions, kind of like how you get better at a game the more you play it!"
     ]
    }
   ],
   "source": [
    "prompt = \"Now do the same for machine learning\"\n",
    "chat_with_llm(prompt, user_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "c1f7528a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sure! Here are the topics we've discussed so far:\n",
      "\n",
      "- **Generative AI**\n",
      "  - Creative robot that makes new things\n",
      "  - Learns from examples\n",
      "  - Uses imagination to create unique ideas\n",
      "\n",
      "- **Machine Learning**\n",
      "  - Computers learn like humans do\n",
      "  - Finds patterns in information\n",
      "  - Improves over time with more examples"
     ]
    }
   ],
   "source": [
    "prompt = \"what topics have we discussed, show briefly as bullet points\"\n",
    "chat_with_llm(prompt, user_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e5197f0",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
