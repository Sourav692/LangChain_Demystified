{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8bbf7232",
   "metadata": {},
   "source": [
    "Here we will see briefly how you can use popular commercial LLM APIs including\n",
    "\n",
    "- OpenAI GPT (Paid)\n",
    "- Google Gemini (Paid and Free)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "969aaeb7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "zsh:1: /Users/sourav.banerjee/Documents/Codebases/2. AI ENGINEERING/AgenticAI_Demystified/.venv/bin/pip: bad interpreter: /Users/sourav.banerjee/Documents/Codebases/AgenticAI_Demystified/.venv/bin/python: no such file or directory\n",
      "zsh:1: /Users/sourav.banerjee/Documents/Codebases/2. AI ENGINEERING/AgenticAI_Demystified/.venv/bin/pip: bad interpreter: /Users/sourav.banerjee/Documents/Codebases/AgenticAI_Demystified/.venv/bin/python: no such file or directory\n"
     ]
    }
   ],
   "source": [
    "!pip install -qq openai==1.57.0\n",
    "!pip install -qq google-generativeai==0.8.3"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e945c667",
   "metadata": {},
   "source": [
    "## Get OpenAI API Key\n",
    "\n",
    "Here you need to get API keys from the following websites based on your LLM preference:\n",
    "\n",
    "- Open AI API Key: Go [here](https://platform.openai.com/account/api-keys) and create a key, you need to setup an account and your own billing as this is a paid API. Unfortunately as per recent updates, OpenAI has phased out the free 5\\$ credits. In order to use the API, you now have to pay in your own funds (min: 5\\$).\n",
    "\n",
    "\n",
    "1. Go to [Settings -> Billing](https://platform.openai.com/settings/organization/billing/overview) after creating your account and make sure to add in a payment method and do a minimum 5$ topup (good enough for 1000s of calls as you are charged per token)\n",
    "\n",
    "![](https://i.imgur.com/pXgs31r.png)\n",
    "\n",
    "2. Go to [Dashboard -> API Keys](https://platform.openai.com/api-keys) and create a new project API key as shown below.\n",
    "\n",
    "\n",
    "![](https://i.imgur.com/YbIBBtc.png)\n",
    "\n",
    "\n",
    "\n",
    "3. Remember to __Save__ your key somewhere safe as it will just be shown once as shown below. So copy and save it in a local secure file to use it later on. If you forget, just create a new key anytime.\n",
    "\n",
    "![](https://i.imgur.com/myFXgZg.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "719d29f8",
   "metadata": {},
   "source": [
    "## Load OpenAI API Credentials"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4589b819",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from getpass import getpass\n",
    "\n",
    "# openai_key = getpass(\"Enter your OpenAI API Key: \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e53debea",
   "metadata": {},
   "outputs": [],
   "source": [
    "from dotenv import load_dotenv\n",
    "import os\n",
    "\n",
    "# Load from .env file in current directory\n",
    "load_dotenv()\n",
    "\n",
    "# Access variables\n",
    "openai_key = os.getenv(\"OPENAI_API_KEY\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14d668b5",
   "metadata": {},
   "source": [
    "## Using ChatGPT Directly via API (Without LangChain)\n",
    "\n",
    "This is if you want to use it without wrappers like LangChain, we will show you how you use ChatGPT via the Open AI library and then how you can do the same for Gemini with Google's Gen AI library"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a11a6890",
   "metadata": {},
   "outputs": [],
   "source": [
    "import openai"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "6a86e6ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "openai.api_key = openai_key"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a889715",
   "metadata": {},
   "source": [
    "### API Pricing\n",
    "\n",
    "Right now the best models to use include GPT-4o-mini considering price and GPT-4o considering performance. GPT-3.5-Turbo is also a good stable alternative. Check out [pricing details here](https://openai.com/api/pricing/)\n",
    "\n",
    "![](https://i.imgur.com/U0C1Xhx.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87841e93",
   "metadata": {},
   "source": [
    "### Use ChatGPT for Prompting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "f1fb1f6b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The Los Angeles Dodgers won the World Series in 2020. They defeated the Tampa Bay Rays in six games to claim the championship. This victory marked the Dodgers' first World Series title since 1988.\n"
     ]
    }
   ],
   "source": [
    "messages = [{\"role\": \"system\", \"content\": \"You are a helpful assistant.\"},\n",
    "           {\"role\": \"user\", \"content\": \"Who won the world series in 2020?\"}]\n",
    "response = openai.chat.completions.create(\n",
    "  model=\"gpt-4o-mini\",\n",
    "    messages=messages,\n",
    "    temperature=0)\n",
    "\n",
    "print(response.choices[0].message.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "e662e00e",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Wrap the above logic in a function\n",
    "\n",
    "def get_completion_chatgpt(prompt, model=\"gpt-4o-mini\"):\n",
    "    \"\"\"\n",
    "    Get a completion from OpenAI's ChatGPT model.\n",
    "\n",
    "    Args:\n",
    "        prompt (str): The user prompt to send to the model.\n",
    "        model (str): The model to use for the completion.\n",
    "\n",
    "    Returns:\n",
    "        str: The content of the response message.\n",
    "    \"\"\"\n",
    "    messages = [{\"role\": \"system\", \"content\": \"You are a helpful assistant.\"},\n",
    "           {\"role\": \"user\", \"content\": prompt}]\n",
    "    \n",
    "    response = openai.chat.completions.create(\n",
    "        model=model,\n",
    "        messages=messages,\n",
    "        temperature=0\n",
    "    )\n",
    "    return response.choices[0].message.content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "62816781",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "- **Definition and Functionality**: Generative AI refers to a class of artificial intelligence models that can create new content, such as text, images, music, or videos, by learning patterns and structures from existing data. These models, like GPT-3 for text or DALL-E for images, use deep learning techniques to generate outputs that resemble human-created content.\n",
      "\n",
      "- **Applications and Impact**: Generative AI has a wide range of applications, including content creation, design, gaming, and personalized experiences. It can enhance creativity, automate tasks, and provide innovative solutions across various industries, but it also raises ethical concerns regarding authenticity, copyright, and misinformation.\n"
     ]
    }
   ],
   "source": [
    "prompt = 'Explain Generative AI in 2 bullet points'\n",
    "response = get_completion_chatgpt(prompt=prompt, model=\"gpt-4o-mini\")\n",
    "\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "ff64c930",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "- Generative AI refers to a type of artificial intelligence that is capable of creating new content, such as images, text, or music, based on patterns and data it has been trained on.\n",
      "- It works by learning the underlying structure of the data it is trained on and then generating new content that is similar to the input data but not an exact copy, allowing for the creation of original and unique outputs.\n"
     ]
    }
   ],
   "source": [
    "prompt = 'Explain Generative AI in 2 bullet points'\n",
    "response = get_completion_chatgpt(prompt=prompt, model=\"gpt-3.5-turbo\")\n",
    "\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd1666e8",
   "metadata": {},
   "source": [
    "## Get Google Gemini API Key\n",
    "\n",
    "Here you need to get API keys from the following websites based on your LLM preference:\n",
    "\n",
    "- - Gemini API Key: Go [here](https://aistudio.google.com/app/u/0/apikey) and create a key, you just need a gmail account to sign in. Till now (Oct-2024 so far), Gemini keys do not need billing as mentioned [here](https://ai.google.dev/pricing)\n",
    "\n",
    "\n",
    "1. Go to [Get API Key -> Create API Key](https://aistudio.google.com/app/u/0/apikey) after creating your account and you should be able to generate your API Key\n",
    "\n",
    "![](https://i.imgur.com/UYVkKmK.png)\n",
    "\n",
    "2. Remember to __Save__ your key somewhere safe. So copy and save it in a local secure file to use it later on.\n",
    "\n",
    "![](https://i.imgur.com/9JZyw2t.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4cd6904e",
   "metadata": {},
   "source": [
    "## Load Gemini API credentials\n",
    "\n",
    "Run this section only if you are using Google Gemini"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "ee988186",
   "metadata": {},
   "outputs": [],
   "source": [
    "from dotenv import load_dotenv\n",
    "import os\n",
    "\n",
    "# Load from .env file in current directory\n",
    "load_dotenv()\n",
    "\n",
    "# Access variables\n",
    "gemini_key = os.getenv(\"GOOGLE_GENAI_API_KEY\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3525f1d9",
   "metadata": {},
   "source": [
    "## Configure Gemini Key in Environment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "856171ff",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\2. My Github Codebase\\GenerativAI_Demystified\\.venv\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import google.generativeai as genai\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "e40289f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "genai.configure(api_key=gemini_key)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc3383f7",
   "metadata": {},
   "source": [
    "## API Pricing\n",
    "\n",
    "Right now the best models to use include Gemini 1.5 Flash and Gemini 1.5 Pro. Check out [pricing details here](https://ai.google.dev/pricing)\n",
    "\n",
    "![](https://i.imgur.com/8hR2Ti8.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "52a51968",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "models/gemini-1.0-pro-vision-latest -----> ['generateContent', 'countTokens']\n",
      "models/gemini-pro-vision -----> ['generateContent', 'countTokens']\n",
      "models/gemini-1.5-pro-latest -----> ['generateContent', 'countTokens']\n",
      "models/gemini-1.5-pro-002 -----> ['generateContent', 'countTokens', 'createCachedContent']\n",
      "models/gemini-1.5-pro -----> ['generateContent', 'countTokens']\n",
      "models/gemini-1.5-flash-latest -----> ['generateContent', 'countTokens']\n",
      "models/gemini-1.5-flash -----> ['generateContent', 'countTokens']\n",
      "models/gemini-1.5-flash-002 -----> ['generateContent', 'countTokens', 'createCachedContent']\n",
      "models/gemini-1.5-flash-8b -----> ['createCachedContent', 'generateContent', 'countTokens']\n",
      "models/gemini-1.5-flash-8b-001 -----> ['createCachedContent', 'generateContent', 'countTokens']\n",
      "models/gemini-1.5-flash-8b-latest -----> ['createCachedContent', 'generateContent', 'countTokens']\n",
      "models/gemini-2.5-pro-preview-03-25 -----> ['generateContent', 'countTokens', 'createCachedContent', 'batchGenerateContent']\n",
      "models/gemini-2.5-flash-preview-04-17 -----> ['generateContent', 'countTokens', 'createCachedContent', 'batchGenerateContent']\n",
      "models/gemini-2.5-flash-preview-05-20 -----> ['generateContent', 'countTokens', 'createCachedContent', 'batchGenerateContent']\n",
      "models/gemini-2.5-flash -----> ['generateContent', 'countTokens', 'createCachedContent', 'batchGenerateContent']\n",
      "models/gemini-2.5-flash-preview-04-17-thinking -----> ['generateContent', 'countTokens', 'createCachedContent', 'batchGenerateContent']\n",
      "models/gemini-2.5-flash-lite-preview-06-17 -----> ['generateContent', 'countTokens', 'createCachedContent', 'batchGenerateContent']\n",
      "models/gemini-2.5-pro-preview-05-06 -----> ['generateContent', 'countTokens', 'createCachedContent', 'batchGenerateContent']\n",
      "models/gemini-2.5-pro-preview-06-05 -----> ['generateContent', 'countTokens', 'createCachedContent', 'batchGenerateContent']\n",
      "models/gemini-2.5-pro -----> ['generateContent', 'countTokens', 'createCachedContent', 'batchGenerateContent']\n",
      "models/gemini-2.0-flash-exp -----> ['generateContent', 'countTokens', 'bidiGenerateContent']\n",
      "models/gemini-2.0-flash -----> ['generateContent', 'countTokens', 'createCachedContent', 'batchGenerateContent']\n",
      "models/gemini-2.0-flash-001 -----> ['generateContent', 'countTokens', 'createCachedContent', 'batchGenerateContent']\n",
      "models/gemini-2.0-flash-exp-image-generation -----> ['generateContent', 'countTokens', 'bidiGenerateContent']\n",
      "models/gemini-2.0-flash-lite-001 -----> ['generateContent', 'countTokens', 'createCachedContent', 'batchGenerateContent']\n",
      "models/gemini-2.0-flash-lite -----> ['generateContent', 'countTokens', 'createCachedContent', 'batchGenerateContent']\n",
      "models/gemini-2.0-flash-preview-image-generation -----> ['generateContent', 'countTokens']\n",
      "models/gemini-2.0-flash-lite-preview-02-05 -----> ['generateContent', 'countTokens', 'createCachedContent', 'batchGenerateContent']\n",
      "models/gemini-2.0-flash-lite-preview -----> ['generateContent', 'countTokens', 'createCachedContent', 'batchGenerateContent']\n",
      "models/gemini-2.0-pro-exp -----> ['generateContent', 'countTokens', 'createCachedContent', 'batchGenerateContent']\n",
      "models/gemini-2.0-pro-exp-02-05 -----> ['generateContent', 'countTokens', 'createCachedContent', 'batchGenerateContent']\n",
      "models/gemini-exp-1206 -----> ['generateContent', 'countTokens', 'createCachedContent', 'batchGenerateContent']\n",
      "models/gemini-2.0-flash-thinking-exp-01-21 -----> ['generateContent', 'countTokens', 'createCachedContent', 'batchGenerateContent']\n",
      "models/gemini-2.0-flash-thinking-exp -----> ['generateContent', 'countTokens', 'createCachedContent', 'batchGenerateContent']\n",
      "models/gemini-2.0-flash-thinking-exp-1219 -----> ['generateContent', 'countTokens', 'createCachedContent', 'batchGenerateContent']\n",
      "models/gemini-2.5-flash-preview-tts -----> ['countTokens', 'generateContent']\n",
      "models/gemini-2.5-pro-preview-tts -----> ['countTokens', 'generateContent']\n",
      "models/learnlm-2.0-flash-experimental -----> ['generateContent', 'countTokens']\n",
      "models/gemma-3-1b-it -----> ['generateContent', 'countTokens']\n",
      "models/gemma-3-4b-it -----> ['generateContent', 'countTokens']\n",
      "models/gemma-3-12b-it -----> ['generateContent', 'countTokens']\n",
      "models/gemma-3-27b-it -----> ['generateContent', 'countTokens']\n",
      "models/gemma-3n-e4b-it -----> ['generateContent', 'countTokens']\n",
      "models/gemma-3n-e2b-it -----> ['generateContent', 'countTokens']\n"
     ]
    }
   ],
   "source": [
    "for m in genai.list_models():\n",
    "    if 'generateContent' in m.supported_generation_methods:\n",
    "        print(m.name,\"----->\", m.supported_generation_methods)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "6e0220b6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Paris\\n'"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prompt = \"What is the capital of France?\"\n",
    "model = genai.GenerativeModel(\"gemini-1.5-flash\")\n",
    "response = model.generate_content(prompt)\n",
    "response.text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "07dede6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Wrap this in a function\n",
    "def get_completion_gemini(prompt, model_name=\"gemini-1.5-flash\"):\n",
    "    \"\"\"\n",
    "    Get a completion from Google's Gemini model.\n",
    "\n",
    "    Args:\n",
    "        prompt (str): The user prompt to send to the model.\n",
    "        model_name (str): The name of the Gemini model to use.\n",
    "\n",
    "    Returns:\n",
    "        str: The text of the response.\n",
    "    \"\"\"\n",
    "    model = genai.GenerativeModel(model_name)\n",
    "    response = model.generate_content(prompt)\n",
    "    return response.text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "381bd8d2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "* **Creates new content:** Generative AI uses algorithms to produce various forms of content, including text, images, audio, and video, instead of simply analyzing or classifying existing data.\n",
      "\n",
      "* **Learns from data to generate:**  It's trained on massive datasets and learns patterns within that data to generate new, original outputs that share similar characteristics but are not direct copies.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "prompt = 'Explain Generative AI in 2 bullet points'\n",
    "response = get_completion_gemini(prompt=prompt, model_name=\"gemini-1.5-flash-latest\")\n",
    "\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dfe11b2c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
