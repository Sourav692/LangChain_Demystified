{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3d3fe166",
   "metadata": {},
   "source": [
    "# Using Commercial LLMs with LangChain\n",
    "\n",
    "Here we will see briefly how you can use popular commercial LLM APIs with LangChain including\n",
    "\n",
    "- OpenAI GPT (Paid)\n",
    "- Google Gemini (Paid and Free)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2dec642f",
   "metadata": {},
   "source": [
    "## Install Dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64db85c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================================\n",
    "# REQUIRED DEPENDENCIES\n",
    "# ============================================================================\n",
    "# Uncomment and run these commands to install the necessary packages:\n",
    "#\n",
    "# langchain: Core LangChain library providing chains, prompts, and abstractions\n",
    "# langchain-openai: Integration package for OpenAI's GPT models\n",
    "# langchain-google-genai: Integration package for Google's Gemini models\n",
    "#\n",
    "# The -qq flag suppresses output for cleaner installation\n",
    "# ============================================================================\n",
    "\n",
    "# !pip install -qq langchain==0.3.11\n",
    "# !pip install -qq langchain-openai==0.2.12\n",
    "# !pip install -qq langchain-google-genai==2.0.6"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49c31fee",
   "metadata": {},
   "source": [
    "## Load OpenAI API Credentials\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f18cbfb9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================================\n",
    "# METHOD 1: Interactive API Key Input (Alternative Approach)\n",
    "# ============================================================================\n",
    "# Use getpass for secure input - the key won't be visible while typing\n",
    "# This is useful for notebooks shared publicly where you don't want to\n",
    "# expose your API key in the code\n",
    "# ============================================================================\n",
    "\n",
    "# from getpass import getpass\n",
    "# openai_key = getpass(\"Enter your OpenAI API Key: \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "dcff1a7a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# ============================================================================\n",
    "# METHOD 2: Load API Keys from Environment File (Recommended Approach)\n",
    "# ============================================================================\n",
    "# Using python-dotenv to load API keys from a .env file is the best practice:\n",
    "# 1. Create a .env file in your project root with:\n",
    "#    OPENAI_API_KEY=your_openai_key_here\n",
    "#    GOOGLE_API_KEY=your_google_key_here\n",
    "# 2. Add .env to your .gitignore to prevent accidental commits\n",
    "# 3. LangChain automatically reads OPENAI_API_KEY and GOOGLE_API_KEY from env\n",
    "# ============================================================================\n",
    "\n",
    "from dotenv import load_dotenv\n",
    "import os\n",
    "\n",
    "# Load environment variables from .env file\n",
    "# Returns True if .env file was found and loaded successfully\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "675f3cfc",
   "metadata": {},
   "source": [
    "## Use OpenAI ChatGPT with LangChain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "df839f12",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "- **Definition**: Artificial Intelligence (AI) refers to the simulation of human intelligence processes by machines, particularly computer systems, enabling them to perform tasks such as learning, reasoning, problem-solving, and understanding natural language.\n",
      "\n",
      "- **Applications**: AI is utilized across various fields, including healthcare (diagnosis and treatment recommendations), finance (fraud detection and algorithmic trading), autonomous vehicles (navigation and decision-making), and customer service (chatbots and virtual assistants).\n"
     ]
    }
   ],
   "source": [
    "# ============================================================================\n",
    "# BASIC LANGCHAIN CHAIN WITH OPENAI GPT\n",
    "# ============================================================================\n",
    "# This demonstrates the fundamental pattern of LangChain:\n",
    "# 1. Create a prompt template with placeholders (e.g., {topic})\n",
    "# 2. Initialize an LLM (ChatOpenAI in this case)\n",
    "# 3. Chain them together using the pipe (|) operator (LCEL syntax)\n",
    "# 4. Invoke the chain with input variables\n",
    "# ============================================================================\n",
    "\n",
    "from langchain_core.prompts import PromptTemplate, ChatPromptTemplate\n",
    "from langchain_openai import ChatOpenAI\n",
    "\n",
    "# Initialize the ChatOpenAI model\n",
    "# - model_name: Specifies which GPT model to use (gpt-4o-mini is cost-effective)\n",
    "# - temperature: Controls randomness (0 = deterministic, 1 = creative)\n",
    "chatgpt = ChatOpenAI(\n",
    "    model_name=\"gpt-4o-mini\",\n",
    "    temperature=0  # Use 0 for consistent, reproducible outputs\n",
    ")\n",
    "\n",
    "# Create a prompt template with a placeholder variable {topic}\n",
    "# ChatPromptTemplate is designed for chat models (message-based)\n",
    "prompt = \"Explain {topic} in 2 bullet points\"\n",
    "prompt_template = ChatPromptTemplate.from_template(prompt)\n",
    "\n",
    "# Create a chain using LCEL (LangChain Expression Language)\n",
    "# The | operator pipes the output of one component to the next:\n",
    "# prompt_template -> formats the prompt -> chatgpt -> generates response\n",
    "chain = (\n",
    "    prompt_template \n",
    "    | \n",
    "    chatgpt\n",
    ")\n",
    "\n",
    "# Invoke the chain with actual values for the placeholders\n",
    "# Returns an AIMessage object containing the response\n",
    "response = chain.invoke({\"topic\": \"AI\"})\n",
    "\n",
    "# Access the text content from the AIMessage object\n",
    "print(response.content)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "2540f97a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content='- **Definition**: Artificial Intelligence (AI) refers to the simulation of human intelligence processes by machines, particularly computer systems, enabling them to perform tasks such as learning, reasoning, problem-solving, and understanding natural language.\\n\\n- **Applications**: AI is utilized across various fields, including healthcare (diagnosis and treatment recommendations), finance (fraud detection and algorithmic trading), autonomous vehicles (navigation and decision-making), and customer service (chatbots and virtual assistants).', additional_kwargs={'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 93, 'prompt_tokens': 14, 'total_tokens': 107, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_name': 'gpt-4o-mini-2024-07-18', 'system_fingerprint': 'fp_11f3029f6b', 'id': 'chatcmpl-Cl2belY6IBWuUNNyvoXzSKkVghTfA', 'finish_reason': 'stop', 'logprobs': None}, id='run-0b01fb59-f0d9-4de3-9150-a13e1ec62c7e-0', usage_metadata={'input_tokens': 14, 'output_tokens': 93, 'total_tokens': 107, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}})"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# ============================================================================\n",
    "# EXAMINING THE FULL RESPONSE OBJECT\n",
    "# ============================================================================\n",
    "# The response is an AIMessage object that contains:\n",
    "# - content: The actual text response from the model\n",
    "# - additional_kwargs: Extra data like refusal info\n",
    "# - response_metadata: Token usage, model info, finish reason, etc.\n",
    "# - id: Unique identifier for this response\n",
    "# - usage_metadata: Detailed token counts (input, output, total)\n",
    "# ============================================================================\n",
    "\n",
    "response"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b490d8d",
   "metadata": {},
   "source": [
    "## Some of the alternative method to write the above code"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2867f256",
   "metadata": {},
   "source": [
    "### Alternative 1: Using | with StrOutputParser (get string directly)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "29bed0d8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "- **Definition**: Artificial Intelligence (AI) refers to the simulation of human intelligence processes by machines, particularly computer systems, enabling them to perform tasks such as learning, reasoning, problem-solving, and understanding natural language.\n",
      "\n",
      "- **Applications**: AI is utilized across various fields, including healthcare (diagnosis and treatment recommendations), finance (fraud detection and algorithmic trading), autonomous vehicles (navigation and decision-making), and customer service (chatbots and virtual assistants).\n"
     ]
    }
   ],
   "source": [
    "# ============================================================================\n",
    "# ALTERNATIVE 1: Using StrOutputParser for Direct String Output\n",
    "# ============================================================================\n",
    "# StrOutputParser extracts the text content from AIMessage automatically\n",
    "# This is useful when you only need the text and want cleaner code\n",
    "# Chain flow: prompt -> LLM -> AIMessage -> StrOutputParser -> string\n",
    "# ============================================================================\n",
    "\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "from langchain_openai import ChatOpenAI\n",
    "\n",
    "chatgpt = ChatOpenAI(model_name=\"gpt-4o-mini\", temperature=0)\n",
    "prompt_template = ChatPromptTemplate.from_template(\"Explain {topic} in 2 bullet points\")\n",
    "\n",
    "# Adding StrOutputParser() to the chain extracts just the string content\n",
    "# No need to access .content on the response - it's already a string!\n",
    "chain = prompt_template | chatgpt | StrOutputParser()\n",
    "response = chain.invoke({\"topic\": \"AI\"})\n",
    "print(response)  # Direct string output - no .content needed!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2eef57d5",
   "metadata": {},
   "source": [
    "### Alternative 2: Using RunnableSequence explicitly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "50fd67a3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "- **Definition**: Artificial Intelligence (AI) refers to the simulation of human intelligence processes by machines, particularly computer systems, enabling them to perform tasks such as learning, reasoning, problem-solving, and understanding natural language.\n",
      "\n",
      "- **Applications**: AI is utilized across various fields, including healthcare (diagnosis and treatment recommendations), finance (fraud detection and algorithmic trading), autonomous vehicles, customer service (chatbots), and many more, enhancing efficiency and decision-making.\n"
     ]
    }
   ],
   "source": [
    "# ============================================================================\n",
    "# ALTERNATIVE 2: Using RunnableSequence Explicitly\n",
    "# ============================================================================\n",
    "# RunnableSequence is what the | operator creates under the hood\n",
    "# Using it explicitly can be useful for:\n",
    "# - Dynamic chain construction at runtime\n",
    "# - Programmatically building chains from a list of components\n",
    "# - When you need more control over the chain structure\n",
    "# ============================================================================\n",
    "\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langchain_core.runnables import RunnableSequence\n",
    "from langchain_openai import ChatOpenAI\n",
    "\n",
    "chatgpt = ChatOpenAI(model_name=\"gpt-4o-mini\", temperature=0)\n",
    "prompt_template = ChatPromptTemplate.from_template(\"Explain {topic} in 2 bullet points\")\n",
    "\n",
    "# RunnableSequence takes components as positional arguments\n",
    "# This is equivalent to: prompt_template | chatgpt\n",
    "chain = RunnableSequence(prompt_template, chatgpt)\n",
    "response = chain.invoke({\"topic\": \"AI\"})\n",
    "print(response.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b915551a",
   "metadata": {},
   "source": [
    "### Alternative 3: One-liner (no intermediate variables)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "489041f6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "- **Definition**: Artificial Intelligence (AI) refers to the simulation of human intelligence processes by machines, particularly computer systems, enabling them to perform tasks such as learning, reasoning, problem-solving, and understanding natural language.\n",
      "\n",
      "- **Applications**: AI is utilized across various fields, including healthcare (diagnosis and treatment recommendations), finance (fraud detection and algorithmic trading), autonomous vehicles, customer service (chatbots), and many more, enhancing efficiency and decision-making.\n"
     ]
    }
   ],
   "source": [
    "# ============================================================================\n",
    "# ALTERNATIVE 3: One-liner (Compact Style)\n",
    "# ============================================================================\n",
    "# For simple use cases, you can create and invoke a chain in one expression\n",
    "# Pros: Concise, good for quick experiments or simple scripts\n",
    "# Cons: Harder to debug, can't reuse the chain, less readable\n",
    "# Best for: Quick prototypes, simple one-off queries\n",
    "# ============================================================================\n",
    "\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langchain_openai import ChatOpenAI\n",
    "\n",
    "# Everything in a single expression - create chain and invoke immediately\n",
    "response = (\n",
    "    ChatPromptTemplate.from_template(\"Explain {topic} in 2 bullet points\") \n",
    "    | ChatOpenAI(model_name=\"gpt-4o-mini\", temperature=0)\n",
    ").invoke({\"topic\": \"AI\"})\n",
    "\n",
    "print(response.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b4275fd",
   "metadata": {},
   "source": [
    "### Alternative 4: Using pipe() method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "bc5ce28b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "- **Definition**: Artificial Intelligence (AI) refers to the simulation of human intelligence processes by machines, particularly computer systems, enabling them to perform tasks such as learning, reasoning, problem-solving, and understanding natural language.\n",
      "\n",
      "- **Applications**: AI is utilized across various fields, including healthcare (diagnosis and treatment recommendations), finance (fraud detection and algorithmic trading), autonomous vehicles (navigation and decision-making), and customer service (chatbots and virtual assistants).\n"
     ]
    }
   ],
   "source": [
    "# ============================================================================\n",
    "# ALTERNATIVE 4: Using pipe() Method\n",
    "# ============================================================================\n",
    "# The pipe() method is an alternative to the | operator\n",
    "# It's the method that | calls under the hood\n",
    "# Useful when you want to chain programmatically or avoid operator syntax\n",
    "# ============================================================================\n",
    "\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langchain_openai import ChatOpenAI\n",
    "\n",
    "chatgpt = ChatOpenAI(model_name=\"gpt-4o-mini\", temperature=0)\n",
    "prompt_template = ChatPromptTemplate.from_template(\"Explain {topic} in 2 bullet points\")\n",
    "\n",
    "# prompt_template.pipe(chatgpt) is equivalent to prompt_template | chatgpt\n",
    "# You can chain multiple: prompt.pipe(llm).pipe(parser)\n",
    "chain = prompt_template.pipe(chatgpt)\n",
    "response = chain.invoke({\"topic\": \"AI\"})\n",
    "print(response.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "864f95df",
   "metadata": {},
   "source": [
    "### Alternative 5: Direct invocation without chain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "bf806f5f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "- **Definition**: Artificial Intelligence (AI) refers to the simulation of human intelligence processes by machines, particularly computer systems, enabling them to perform tasks such as learning, reasoning, problem-solving, and understanding natural language.\n",
      "\n",
      "- **Applications**: AI is utilized across various fields, including healthcare (diagnosis and treatment recommendations), finance (fraud detection and algorithmic trading), autonomous vehicles, customer service (chatbots), and many more, enhancing efficiency and decision-making.\n"
     ]
    }
   ],
   "source": [
    "# ============================================================================\n",
    "# ALTERNATIVE 5: Direct Invocation Without Chain\n",
    "# ============================================================================\n",
    "# Instead of creating a chain, you can invoke each component separately\n",
    "# This gives you more control and visibility into intermediate results\n",
    "# Useful for debugging or when you need to inspect/modify data between steps\n",
    "# ============================================================================\n",
    "\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langchain_openai import ChatOpenAI\n",
    "\n",
    "chatgpt = ChatOpenAI(model_name=\"gpt-4o-mini\", temperature=0)\n",
    "prompt_template = ChatPromptTemplate.from_template(\"Explain {topic} in 2 bullet points\")\n",
    "\n",
    "# Step 1: Format the prompt with variables -> produces ChatPromptValue (messages)\n",
    "messages = prompt_template.invoke({\"topic\": \"AI\"})\n",
    "# You can inspect 'messages' here if needed: print(messages.to_messages())\n",
    "\n",
    "# Step 2: Send messages to the LLM -> produces AIMessage\n",
    "response = chatgpt.invoke(messages)\n",
    "print(response.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c502ab1",
   "metadata": {},
   "source": [
    "### Using from_messages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "fca1337c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "- **Definition**: Artificial Intelligence (AI) refers to the simulation of human intelligence in machines that are programmed to think, learn, and make decisions like humans. This includes capabilities such as problem-solving, understanding natural language, and recognizing patterns.\n",
      "\n",
      "- **Applications**: AI is used in various fields, including healthcare (for diagnostics), finance (for fraud detection), autonomous vehicles (for navigation), and customer service (through chatbots), enhancing efficiency and enabling new solutions to complex problems.\n"
     ]
    }
   ],
   "source": [
    "# ============================================================================\n",
    "# USING from_messages FOR MULTI-ROLE PROMPTS\n",
    "# ============================================================================\n",
    "# from_messages allows you to specify different roles in the conversation:\n",
    "# - \"system\": Sets the AI's behavior, personality, or context\n",
    "# - \"human\"/\"user\": Represents user messages\n",
    "# - \"ai\"/\"assistant\": Represents AI responses (for few-shot examples)\n",
    "# \n",
    "# This is essential for production applications where you need:\n",
    "# - System prompts to control behavior\n",
    "# - Few-shot learning examples\n",
    "# - Multi-turn conversation context\n",
    "# ============================================================================\n",
    "\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langchain_openai import ChatOpenAI\n",
    "\n",
    "chatgpt = ChatOpenAI(model_name=\"gpt-4o-mini\", temperature=0)\n",
    "\n",
    "# Using from_messages with role tuples (role, content)\n",
    "# The system message shapes how the AI responds\n",
    "prompt_template = ChatPromptTemplate.from_messages([\n",
    "    (\"system\", \"You are a helpful AI assistant that explains concepts clearly.\"),\n",
    "    (\"human\", \"Explain {topic} in 2 bullet points\")\n",
    "])\n",
    "\n",
    "chain = prompt_template | chatgpt\n",
    "response = chain.invoke({\"topic\": \"AI\"})\n",
    "print(response.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ceb3501",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content='- **Definition**: Artificial Intelligence (AI) refers to the simulation of human intelligence processes by machines, particularly computer systems, enabling them to perform tasks such as learning, reasoning, problem-solving, and understanding natural language.\\n\\n- **Applications**: AI is utilized across various fields, including healthcare (diagnosis and treatment recommendations), finance (fraud detection and algorithmic trading), autonomous vehicles, customer service (chatbots), and many more, enhancing efficiency and decision-making.', additional_kwargs={'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 94, 'prompt_tokens': 14, 'total_tokens': 108, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_name': 'gpt-4o-mini-2024-07-18', 'system_fingerprint': 'fp_34a54ae93c', 'finish_reason': 'stop', 'logprobs': None}, id='run--4f209459-6ac8-474c-a327-c1bd30df066a-0', usage_metadata={'input_tokens': 14, 'output_tokens': 94, 'total_tokens': 108, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}})"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Examine the full AIMessage object to understand its structure\n",
    "response"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee25e172",
   "metadata": {},
   "source": [
    "## `ChatPromptTemplate.from_template` vs `ChatPromptTemplate.from_messages`\n",
    "\n",
    "### Key Differences\n",
    "\n",
    "| Aspect | `from_template` | `from_messages` |\n",
    "|--------|-----------------|-----------------|\n",
    "| **Input** | Single string | List of message tuples |\n",
    "| **Roles** | Defaults to `HumanMessage` | Explicit control over roles |\n",
    "| **System prompt** | Not directly supported | âœ… Supported |\n",
    "| **Multi-turn context** | âŒ | âœ… Can include AI responses |\n",
    "| **Use case** | Simple, single prompts | Complex chat interactions |\n",
    "\n",
    "### Role Shortcuts for `from_messages`\n",
    "\n",
    "| Tuple Role | Message Class |\n",
    "|------------|---------------|\n",
    "| `\"system\"` | `SystemMessage` |\n",
    "| `\"human\"` / `\"user\"` | `HumanMessage` |\n",
    "| `\"ai\"` / `\"assistant\"` | `AIMessage` |\n",
    "\n",
    "### Under the Hood\n",
    "\n",
    "```python\n",
    "# from_template:\n",
    "prompt = ChatPromptTemplate.from_template(\"Explain {topic}\")\n",
    "\n",
    "# Is equivalent to:\n",
    "prompt = ChatPromptTemplate.from_messages([\n",
    "    (\"human\", \"Explain {topic}\")\n",
    "])\n",
    "```\n",
    "\n",
    "### When to Use\n",
    "\n",
    "- **`from_template`**: Quick, simple single-turn prompts\n",
    "- **`from_messages`**: When you need system prompts, few-shot examples, or multi-turn context"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "044fa67a",
   "metadata": {},
   "source": [
    "## use PromptTemplate iso ChatPromptTemplate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f37f30b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "- **Definition**: Artificial Intelligence (AI) refers to the simulation of human intelligence processes by machines, particularly computer systems, enabling them to perform tasks such as learning, reasoning, problem-solving, and understanding natural language.\n",
      "\n",
      "- **Applications**: AI is utilized across various fields, including healthcare (diagnosis and treatment recommendations), finance (fraud detection and algorithmic trading), autonomous vehicles, customer service (chatbots), and many more, enhancing efficiency and decision-making.\n"
     ]
    }
   ],
   "source": [
    "# ============================================================================\n",
    "# USING PromptTemplate WITH CHAT MODELS\n",
    "# ============================================================================\n",
    "# PromptTemplate (without \"Chat\") was originally designed for completion models\n",
    "# When used with ChatOpenAI, it works but gets auto-converted to HumanMessage\n",
    "# \n",
    "# Key difference:\n",
    "# - PromptTemplate.invoke() -> StringPromptValue (plain string)\n",
    "# - ChatPromptTemplate.invoke() -> ChatPromptValue (list of messages)\n",
    "#\n",
    "# LangChain handles the conversion automatically, but it's cleaner to use\n",
    "# ChatPromptTemplate with chat models for semantic correctness\n",
    "# ============================================================================\n",
    "\n",
    "from langchain_core.prompts import PromptTemplate\n",
    "from langchain_openai import ChatOpenAI\n",
    "\n",
    "# Initialize Chat Model\n",
    "chatgpt = ChatOpenAI(\n",
    "    model_name=\"gpt-4o-mini\",\n",
    "    temperature=0\n",
    ")\n",
    "\n",
    "# PromptTemplate produces a string (not messages)\n",
    "# LangChain auto-converts it to a HumanMessage when sent to ChatOpenAI\n",
    "prompt_template = PromptTemplate.from_template(\"Explain {topic} in 2 bullet points\")\n",
    "\n",
    "# Create and run chain - works the same way\n",
    "chain = prompt_template | chatgpt\n",
    "response1 = chain.invoke({\"topic\": \"AI\"})\n",
    "print(response1.content)  # Fixed: using response1 instead of response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7301bbf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content='- **Definition and Functionality**: Artificial Intelligence (AI) refers to the simulation of human intelligence in machines programmed to think, learn, and perform tasks autonomously, often using algorithms and data to improve their performance over time.\\n\\n- **Applications and Impact**: AI is utilized across various sectors, including healthcare, finance, and transportation, enhancing efficiency, decision-making, and personalization, while also raising ethical considerations regarding privacy, bias, and job displacement.', additional_kwargs={'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 91, 'prompt_tokens': 14, 'total_tokens': 105, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_name': 'gpt-4o-mini-2024-07-18', 'system_fingerprint': 'fp_34a54ae93c', 'finish_reason': 'stop', 'logprobs': None}, id='run--35e9907c-730e-40de-9bfd-6bb761101714-0', usage_metadata={'input_tokens': 14, 'output_tokens': 91, 'total_tokens': 105, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}})"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Examine response1 - notice the structure is the same as using ChatPromptTemplate\n",
    "# This shows that LangChain's automatic conversion works seamlessly\n",
    "response1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c1d9465",
   "metadata": {},
   "source": [
    "## `PromptTemplate` vs `ChatPromptTemplate`\n",
    "\n",
    "### Key Differences\n",
    "\n",
    "| Aspect | `PromptTemplate` | `ChatPromptTemplate` |\n",
    "|--------|------------------|----------------------|\n",
    "| **Output type** | `StringPromptValue` (string) | `ChatPromptValue` (list of messages) |\n",
    "| **Designed for** | Completion models (text-in, text-out) | Chat models (messages-in, message-out) |\n",
    "| **System prompt** | âŒ Not supported | âœ… Supported |\n",
    "| **Multiple roles** | âŒ Single string only | âœ… system, human, ai |\n",
    "| **With ChatOpenAI** | Auto-converts to HumanMessage | Native message format |\n",
    "\n",
    "### Under the Hood\n",
    "\n",
    "```python\n",
    "# PromptTemplate produces a string:\n",
    "prompt = PromptTemplate.from_template(\"Explain {topic}\")\n",
    "result = prompt.invoke({\"topic\": \"AI\"})\n",
    "# Output: StringPromptValue -> \"Explain AI\"\n",
    "\n",
    "# ChatPromptTemplate produces messages:\n",
    "chat_prompt = ChatPromptTemplate.from_template(\"Explain {topic}\")\n",
    "result = chat_prompt.invoke({\"topic\": \"AI\"})\n",
    "# Output: ChatPromptValue -> [HumanMessage(content='Explain AI')]\n",
    "```\n",
    "\n",
    "### When to Use Each\n",
    "\n",
    "| Use Case | Recommendation |\n",
    "|----------|----------------|\n",
    "| Simple prompts with ChatOpenAI | Either works âœ… |\n",
    "| Need system prompt | `ChatPromptTemplate` |\n",
    "| Need multi-turn/few-shot | `ChatPromptTemplate` |\n",
    "| Working with completion models (legacy) | `PromptTemplate` |\n",
    "| Building complex chat applications | `ChatPromptTemplate` |\n",
    "\n",
    "### Recommendation\n",
    "\n",
    "For **chat models** like ChatOpenAI, prefer `ChatPromptTemplate` because:\n",
    "- âœ… Semantically correct (designed for chat models)\n",
    "- âœ… Supports system prompts and multiple roles\n",
    "- âœ… More explicit about the message structure\n",
    "- âœ… Future-proof for complex use cases"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "9872eee3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'langchain_core.prompt_values.StringPromptValue'>\n",
      "Explain AI\n",
      "<class 'langchain_core.prompt_values.ChatPromptValue'>\n",
      "[HumanMessage(content='Explain AI', additional_kwargs={}, response_metadata={})]\n"
     ]
    }
   ],
   "source": [
    "# ============================================================================\n",
    "# DEMONSTRATION: PromptTemplate vs ChatPromptTemplate Output Types\n",
    "# ============================================================================\n",
    "# This cell shows the actual difference in what each template produces\n",
    "# when you invoke them with variables\n",
    "# ============================================================================\n",
    "\n",
    "# PromptTemplate produces a StringPromptValue (essentially a string wrapper)\n",
    "prompt = PromptTemplate.from_template(\"Explain {topic}\")\n",
    "result = prompt.invoke({\"topic\": \"AI\"})\n",
    "print(\"=== PromptTemplate Output ===\")\n",
    "print(f\"Type: {type(result)}\")  # StringPromptValue\n",
    "print(f\"String: {result.to_string()}\")  # \"Explain AI\"\n",
    "\n",
    "print()  # Blank line for readability\n",
    "\n",
    "# ChatPromptTemplate produces a ChatPromptValue (list of messages)\n",
    "chat_prompt = ChatPromptTemplate.from_template(\"Explain {topic}\")\n",
    "result = chat_prompt.invoke({\"topic\": \"AI\"})\n",
    "print(\"=== ChatPromptTemplate Output ===\")\n",
    "print(f\"Type: {type(result)}\")  # ChatPromptValue\n",
    "print(f\"Messages: {result.to_messages()}\")  # [HumanMessage(content='Explain AI')]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "173132ed",
   "metadata": {},
   "source": [
    "## Load Gemini API credentials\n",
    "\n",
    "Run this section only if you are using Google Gemini"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "c7e63271",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# ============================================================================\n",
    "# LOAD GOOGLE GEMINI API CREDENTIALS\n",
    "# ============================================================================\n",
    "# For Google Gemini, you need GOOGLE_API_KEY in your .env file\n",
    "# Get your API key from: https://makersuite.google.com/app/apikey\n",
    "# Gemini offers a generous free tier, making it great for learning!\n",
    "# ============================================================================\n",
    "\n",
    "from dotenv import load_dotenv\n",
    "import os\n",
    "\n",
    "# Load environment variables (including GOOGLE_API_KEY)\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "729105fb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Here are two bullets explaining AI:\n",
      "\n",
      "*   **AI (Artificial Intelligence) refers to computer systems designed to perform tasks that typically require human intelligence.** This includes abilities like understanding language, recognizing images, making decisions, and solving problems.\n",
      "*   **These systems learn from data to identify patterns, make predictions, and adapt their behavior without explicit programming for every scenario.** This allows them to automate complex cognitive tasks and continuously improve their performance.\n"
     ]
    }
   ],
   "source": [
    "# ============================================================================\n",
    "# USING GOOGLE GEMINI WITH LANGCHAIN\n",
    "# ============================================================================\n",
    "# LangChain provides a unified interface - the code structure is identical\n",
    "# to OpenAI! Only the model class changes:\n",
    "# - OpenAI: ChatOpenAI from langchain_openai\n",
    "# - Gemini: ChatGoogleGenerativeAI from langchain_google_genai\n",
    "#\n",
    "# This abstraction is one of LangChain's key benefits - easily swap models!\n",
    "# ============================================================================\n",
    "\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langchain_google_genai import ChatGoogleGenerativeAI\n",
    "\n",
    "# Initialize Gemini model\n",
    "# Available models: gemini-pro, gemini-1.5-pro, gemini-1.5-flash, gemini-2.5-flash\n",
    "# Flash models are faster and cheaper, Pro models are more capable\n",
    "gemini = ChatGoogleGenerativeAI(model=\"gemini-2.5-flash\")\n",
    "\n",
    "# Same prompt template syntax works across all LLMs\n",
    "PROMPT = \"Explain {topic} in 2 bullets\"\n",
    "prompt = ChatPromptTemplate.from_template(PROMPT)\n",
    "\n",
    "# Same chain pattern - this is the power of LangChain's abstraction!\n",
    "chain = (\n",
    "    prompt\n",
    "    |\n",
    "    gemini\n",
    ")\n",
    "\n",
    "# Invoke works exactly the same way\n",
    "response = chain.invoke({\"topic\": \"AI\"})\n",
    "print(response.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98a88e52",
   "metadata": {},
   "source": [
    "## Summary & Key Takeaways\n",
    "\n",
    "### ðŸŽ¯ Core Concepts Covered\n",
    "\n",
    "1. **LangChain's Value Proposition**: Provides a unified interface to work with different LLM providers (OpenAI, Google, etc.) using the same code patterns.\n",
    "\n",
    "2. **LCEL (LangChain Expression Language)**: The `|` pipe operator chains components together:\n",
    "   ```python\n",
    "   chain = prompt_template | llm | output_parser\n",
    "   ```\n",
    "\n",
    "3. **Prompt Templates**:\n",
    "   - `ChatPromptTemplate.from_template()` - Simple single-turn prompts\n",
    "   - `ChatPromptTemplate.from_messages()` - Multi-role prompts with system messages\n",
    "   - `PromptTemplate` - Legacy, works but prefer ChatPromptTemplate for chat models\n",
    "\n",
    "4. **Chain Invocation**: Always use `.invoke({\"key\": \"value\"})` with a dictionary of variables\n",
    "\n",
    "### ðŸ”‘ Best Practices\n",
    "\n",
    "- Store API keys in `.env` files, never hardcode them\n",
    "- Use `temperature=0` for consistent, reproducible outputs\n",
    "- Prefer `ChatPromptTemplate` over `PromptTemplate` for chat models\n",
    "- Use `StrOutputParser` when you only need the text response\n",
    "- System prompts (via `from_messages`) help control AI behavior\n",
    "\n",
    "### ðŸ“š Next Steps\n",
    "\n",
    "- Explore output parsers for structured data (JSON, Pydantic models)\n",
    "- Learn about memory for conversation history\n",
    "- Dive into RAG (Retrieval Augmented Generation)\n",
    "- Build agents with tools\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
