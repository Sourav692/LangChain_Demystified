{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## LangChain Agents - A Comprehensive Guide\n",
    "\n",
    "### What are Agents?\n",
    "\n",
    "**Agents** are one of the most powerful concepts in LangChain. Unlike simple chains that follow a predetermined sequence, agents use an LLM as a **reasoning engine** to dynamically determine:\n",
    "1. **Which actions** to perform\n",
    "2. **In what order** to perform them\n",
    "3. **When to stop** and return a final answer\n",
    "\n",
    "### Key Concepts\n",
    "\n",
    "| Concept | Description |\n",
    "|---------|-------------|\n",
    "| **Agent** | The decision-maker that uses an LLM to reason about what to do next |\n",
    "| **Tools** | Functions that agents can call to interact with the external world |\n",
    "| **Agent Executor** | The runtime that orchestrates the agent's reasoning and tool execution loop |\n",
    "| **Scratchpad** | Memory of previous actions and observations within a single run |\n",
    "\n",
    "### The ReAct Pattern\n",
    "\n",
    "Most agents follow the **ReAct (Reasoning + Acting)** pattern:\n",
    "1. **Thought**: The agent reasons about what to do\n",
    "2. **Action**: The agent decides which tool to use\n",
    "3. **Action Input**: The input to pass to the tool\n",
    "4. **Observation**: The result from the tool\n",
    "5. **Repeat** until the agent has enough information to provide a final answer\n",
    "\n",
    "> âš ï¸ **Note**: LangChain is transitioning to **LangGraph** for building agents. However, understanding these concepts is still valuable as they form the foundation."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Section 1: Understanding Tools\n",
    "\n",
    "### What are Tools?\n",
    "\n",
    "**Tools** are functions that agents can use to interact with the external world. They extend the agent's capabilities beyond just generating text.\n",
    "\n",
    "### Types of Tools\n",
    "\n",
    "| Type | Examples | Use Case |\n",
    "|------|----------|----------|\n",
    "| **Built-in Tools** | `llm-math`, `wikipedia`, `serpapi` | Common utilities provided by LangChain |\n",
    "| **Custom Tools** | Your own functions | Domain-specific operations |\n",
    "| **Chain Tools** | Other LangChain chains | Complex multi-step operations |\n",
    "| **Agent Tools** | Other agents | Hierarchical agent systems |\n",
    "\n",
    "### Tool Components\n",
    "\n",
    "Every tool has:\n",
    "- **name**: A unique identifier for the tool\n",
    "- **description**: Explains what the tool does (crucial for the agent to decide when to use it!)\n",
    "- **func**: The actual function that gets executed\n",
    "\n",
    "> ðŸ’¡ **Pro Tip**: The `description` is extremely important! The agent uses it to decide which tool to use. Make it clear and specific."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# =============================================================================\n",
    "# STEP 1: Environment Setup\n",
    "# =============================================================================\n",
    "# Load environment variables from .env file\n",
    "# This typically includes API keys like OPENAI_API_KEY\n",
    "# The find_dotenv() function searches for .env file in parent directories\n",
    "\n",
    "from dotenv import load_dotenv, find_dotenv\n",
    "\n",
    "load_dotenv(find_dotenv())  # Returns True if .env file was found and loaded"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Tool(name='Calculator', description='Useful for when you need to answer questions about math.', func=<bound method Chain.run of LLMMathChain(verbose=False, llm_chain=LLMChain(verbose=False, prompt=PromptTemplate(input_variables=['question'], input_types={}, partial_variables={}, template='Translate a math problem into a expression that can be executed using Python\\'s numexpr library. Use the output of running this code to answer the question.\\n\\nQuestion: ${{Question with math problem.}}\\n```text\\n${{single line mathematical expression that solves the problem}}\\n```\\n...numexpr.evaluate(text)...\\n```output\\n${{Output of running the code}}\\n```\\nAnswer: ${{Answer}}\\n\\nBegin.\\n\\nQuestion: What is 37593 * 67?\\n```text\\n37593 * 67\\n```\\n...numexpr.evaluate(\"37593 * 67\")...\\n```output\\n2518731\\n```\\nAnswer: 2518731\\n\\nQuestion: 37593^(1/5)\\n```text\\n37593**(1/5)\\n```\\n...numexpr.evaluate(\"37593**(1/5)\")...\\n```output\\n8.222831614237718\\n```\\nAnswer: 8.222831614237718\\n\\nQuestion: {question}\\n'), llm=ChatOpenAI(client=<openai.resources.chat.completions.completions.Completions object at 0x130320e10>, async_client=<openai.resources.chat.completions.completions.AsyncCompletions object at 0x130320f50>, root_client=<openai.OpenAI object at 0x11769c550>, root_async_client=<openai.AsyncOpenAI object at 0x130320cd0>, model_name='gpt-4o-mini', model_kwargs={}, openai_api_key=SecretStr('**********')), output_parser=StrOutputParser(), llm_kwargs={}))>, coroutine=<bound method Chain.arun of LLMMathChain(verbose=False, llm_chain=LLMChain(verbose=False, prompt=PromptTemplate(input_variables=['question'], input_types={}, partial_variables={}, template='Translate a math problem into a expression that can be executed using Python\\'s numexpr library. Use the output of running this code to answer the question.\\n\\nQuestion: ${{Question with math problem.}}\\n```text\\n${{single line mathematical expression that solves the problem}}\\n```\\n...numexpr.evaluate(text)...\\n```output\\n${{Output of running the code}}\\n```\\nAnswer: ${{Answer}}\\n\\nBegin.\\n\\nQuestion: What is 37593 * 67?\\n```text\\n37593 * 67\\n```\\n...numexpr.evaluate(\"37593 * 67\")...\\n```output\\n2518731\\n```\\nAnswer: 2518731\\n\\nQuestion: 37593^(1/5)\\n```text\\n37593**(1/5)\\n```\\n...numexpr.evaluate(\"37593**(1/5)\")...\\n```output\\n8.222831614237718\\n```\\nAnswer: 8.222831614237718\\n\\nQuestion: {question}\\n'), llm=ChatOpenAI(client=<openai.resources.chat.completions.completions.Completions object at 0x130320e10>, async_client=<openai.resources.chat.completions.completions.AsyncCompletions object at 0x130320f50>, root_client=<openai.OpenAI object at 0x11769c550>, root_async_client=<openai.AsyncOpenAI object at 0x130320cd0>, model_name='gpt-4o-mini', model_kwargs={}, openai_api_key=SecretStr('**********')), output_parser=StrOutputParser(), llm_kwargs={}))>)]"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# =============================================================================\n",
    "# STEP 2: Loading Built-in Tools\n",
    "# =============================================================================\n",
    "# LangChain provides several pre-built tools that you can use out of the box\n",
    "# Here we're loading the \"llm-math\" tool - a calculator that uses an LLM\n",
    "\n",
    "from langchain.agents import load_tools\n",
    "from langchain_openai import ChatOpenAI\n",
    "from langchain.agents import AgentType\n",
    "\n",
    "# Initialize the LLM that will power our agent\n",
    "# gpt-4o-mini is a cost-effective model suitable for agent tasks\n",
    "llm = ChatOpenAI(model=\"gpt-4o-mini\")\n",
    "\n",
    "# Load built-in tools by name\n",
    "# \"llm-math\" - Uses an LLM to solve math problems by generating Python expressions\n",
    "# Other available tools: \"wikipedia\", \"serpapi\", \"requests\", \"terminal\", etc.\n",
    "tool_names = [\"llm-math\"]\n",
    "\n",
    "# Some tools require an LLM to function (like llm-math which translates\n",
    "# natural language math problems into executable expressions)\n",
    "tools = load_tools(tool_names, llm=llm)\n",
    "\n",
    "# Let's inspect what we got - a list of Tool objects\n",
    "tools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# =============================================================================\n",
    "# STEP 3: Creating an Agent with initialize_agent\n",
    "# =============================================================================\n",
    "# The initialize_agent function creates an agent that can use the provided tools\n",
    "# This is the \"legacy\" way - LangGraph is the recommended approach for new projects\n",
    "\n",
    "from langchain.agents import initialize_agent\n",
    "\n",
    "# Create the agent with the following parameters:\n",
    "agent = initialize_agent(\n",
    "    tools,                                      # List of tools the agent can use\n",
    "    llm,                                        # The LLM to use for reasoning\n",
    "    agent=AgentType.ZERO_SHOT_REACT_DESCRIPTION,  # Agent type (see below)\n",
    "    verbose=True,                               # Print agent's thought process\n",
    "    max_iterations=3,                           # Prevent infinite loops\n",
    "    handle_parsing_errors=True                  # Gracefully handle LLM output parsing errors\n",
    ")\n",
    "\n",
    "# =============================================================================\n",
    "# Agent Types Explained:\n",
    "# =============================================================================\n",
    "# ZERO_SHOT_REACT_DESCRIPTION:\n",
    "#   - Uses ReAct pattern (Reasoning + Acting)\n",
    "#   - \"Zero-shot\" means no examples are provided\n",
    "#   - Decides which tool to use based on tool descriptions\n",
    "#\n",
    "# Other agent types:\n",
    "#   - CONVERSATIONAL_REACT_DESCRIPTION: For chat with memory\n",
    "#   - STRUCTURED_CHAT_ZERO_SHOT_REACT_DESCRIPTION: For complex tool inputs\n",
    "#   - OPENAI_FUNCTIONS: Uses OpenAI's function calling (more reliable)\n",
    "# ============================================================================="
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gpt-4o-mini\n"
     ]
    }
   ],
   "source": [
    "# =============================================================================\n",
    "# Inspecting the Agent's Components\n",
    "# =============================================================================\n",
    "# The agent has a nested structure - let's explore it\n",
    "\n",
    "# Access the underlying LLM model name\n",
    "# agent.agent -> The actual agent logic\n",
    "# agent.agent.llm_chain -> The chain that calls the LLM\n",
    "# agent.agent.llm_chain.llm -> The LLM instance\n",
    "print(agent.agent.llm_chain.llm.model_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer the following questions as best you can. You have access to the following tools:\n",
      "\n",
      "Calculator(*args: Any, callbacks: Union[list[langchain_core.callbacks.base.BaseCallbackHandler], langchain_core.callbacks.base.BaseCallbackManager, NoneType] = None, tags: Optional[List[str]] = None, metadata: Optional[Dict[str, Any]] = None, **kwargs: Any) -> Any - Useful for when you need to answer questions about math.\n",
      "\n",
      "Use the following format:\n",
      "\n",
      "Question: the input question you must answer\n",
      "Thought: you should always think about what to do\n",
      "Action: the action to take, should be one of [Calculator]\n",
      "Action Input: the input to the action\n",
      "Observation: the result of the action\n",
      "... (this Thought/Action/Action Input/Observation can repeat N times)\n",
      "Thought: I now know the final answer\n",
      "Final Answer: the final answer to the original input question\n",
      "\n",
      "Begin!\n",
      "\n",
      "Question: {input}\n",
      "Thought:{agent_scratchpad}\n"
     ]
    }
   ],
   "source": [
    "# Print the prompt template that guides the agent's behavior\n",
    "# This template is dynamically constructed based on the tools provided\n",
    "print(agent.agent.llm_chain.prompt.template)\n",
    "\n",
    "# =============================================================================\n",
    "# OUTPUT BREAKDOWN:\n",
    "# =============================================================================\n",
    "# 1. SYSTEM INSTRUCTIONS: \"Answer the following questions as best you can...\"\n",
    "# 2. TOOL DESCRIPTIONS: Lists available tools and their descriptions\n",
    "# 3. FORMAT INSTRUCTIONS: The ReAct format (Thought/Action/Observation)\n",
    "# 4. PLACEHOLDERS:\n",
    "#    - {input}: Where the user's question goes\n",
    "#    - {agent_scratchpad}: Previous thoughts/actions in current run\n",
    "# ============================================================================="
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Understanding the ReAct Prompt Template\n",
    "\n",
    "The ReAct (Reasoning + Acting) pattern is the foundation of how agents work. The prompt template instructs the LLM on:\n",
    "1. **How to think** through the problem step by step\n",
    "2. **When to use tools** based on their descriptions\n",
    "3. **How to format responses** so they can be parsed correctly\n",
    "4. **When to stop** and provide a final answer\n",
    "\n",
    "Let's examine the actual prompt template used by our agent. Notice the structured format with `Thought`, `Action`, `Action Input`, and `Observation` sections:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Example 1: Agent Using Its Knowledge (No Tool Needed)\n",
    "\n",
    "Let's ask the agent a question that doesn't require the calculator tool. Watch how the agent reasons and decides it already knows the answer:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
      "\u001b[32;1m\u001b[1;3mThe question asks about the number of members in the A Team. I need to recall or find out how many members are typically associated with the A Team. \n",
      "\n",
      "Action: None (I will answer based on knowledge)\u001b[0m\n",
      "Observation: Invalid Format: Missing 'Action Input:' after 'Action:'\n",
      "Thought:\u001b[32;1m\u001b[1;3mThe A Team is a fictional group of characters from the television show and movie of the same name. The original A Team consists of four main members:\n",
      "\n",
      "1. Colonel John \"Hannibal\" Smith\n",
      "2. Lieutenant Templeton \"Faceman\" Peck\n",
      "3. Captain H.M. \"Howling Mad\" Murdock\n",
      "4. Sergeant Bosco \"B.A.\" Baracus\n",
      "\n",
      "Thought: I now know the final answer\n",
      "Final Answer: The A Team has four members.\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'input': 'How many members does the A Team have?',\n",
       " 'output': 'The A Team has four members.'}"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# =============================================================================\n",
    "# Running the Agent - General Knowledge Question\n",
    "# =============================================================================\n",
    "# Notice in the output:\n",
    "# - The agent recognizes this is a general knowledge question\n",
    "# - It doesn't need to use the Calculator tool\n",
    "# - It goes straight to \"Final Answer\" after thinking\n",
    "\n",
    "result = agent.invoke(input=\"How many members does the A Team have?\")\n",
    "\n",
    "# The result is a dictionary containing:\n",
    "# - 'input': The original question\n",
    "# - 'output': The agent's final answer\n",
    "result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Example 2: Agent Using a Tool (Calculator)\n",
    "\n",
    "Now let's ask a math question. Watch how the agent:\n",
    "1. **Thinks** about what to do\n",
    "2. **Decides** to use the Calculator tool\n",
    "3. **Provides input** to the tool\n",
    "4. **Observes** the result\n",
    "5. **Formulates** the final answer\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
      "\u001b[32;1m\u001b[1;3mTo find the result of 100 divided by 25, I will perform the division calculation.  \n",
      "Action: Calculator  \n",
      "Action Input: 100 / 25  \u001b[0m\n",
      "Observation: \u001b[36;1m\u001b[1;3mAnswer: 4.0\u001b[0m\n",
      "Thought:\u001b[32;1m\u001b[1;3mI now know the final answer.  \n",
      "Final Answer: 4.0\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'input': 'What is 100 devided by 25?', 'output': '4.0'}"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# =============================================================================\n",
    "# Running the Agent - Math Question (Requires Tool)\n",
    "# =============================================================================\n",
    "# The verbose output shows the complete reasoning chain:\n",
    "#\n",
    "# > Entering new AgentExecutor chain...\n",
    "# Thought: I need to perform division\n",
    "# Action: Calculator\n",
    "# Action Input: 100 / 25\n",
    "# Observation: Answer: 4.0\n",
    "# Thought: I now know the final answer\n",
    "# Final Answer: 4.0\n",
    "# > Finished chain.\n",
    "\n",
    "agent.invoke(input=\"What is 100 devided by 25?\")\n",
    "\n",
    "# Note: Even with the typo \"devided\", the agent understands the intent!"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Section 2: Creating Custom Tools\n",
    "\n",
    "### Why Custom Tools?\n",
    "\n",
    "Built-in tools are great, but real-world applications often need domain-specific functionality. You can create custom tools to:\n",
    "- Query your own databases\n",
    "- Call internal APIs\n",
    "- Perform specialized computations\n",
    "- Access proprietary data sources\n",
    "\n",
    "### Ways to Create Custom Tools\n",
    "\n",
    "| Method | Complexity | Use Case |\n",
    "|--------|------------|----------|\n",
    "| `@tool` decorator | Simple | Quick functions with no state |\n",
    "| `BaseTool` subclass | Medium | When you need more control |\n",
    "| `StructuredTool` | Advanced | Complex inputs with validation |\n",
    "\n",
    "### Example: Restaurant Search Tool\n",
    "\n",
    "Let's create a custom tool that searches a FAISS vector store containing restaurant information:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# =============================================================================\n",
    "# STEP 1: Load the Vector Store (Knowledge Base)\n",
    "# =============================================================================\n",
    "# First, we need a data source for our custom tool\n",
    "# Here we're loading a pre-built FAISS vector store containing restaurant FAQ data\n",
    "\n",
    "from langchain_openai import OpenAIEmbeddings\n",
    "from langchain_community.vectorstores import FAISS\n",
    "\n",
    "# Initialize the same embeddings model used to create the index\n",
    "embeddings = OpenAIEmbeddings()\n",
    "\n",
    "# Load the pre-built FAISS index from disk\n",
    "# The 'index' folder contains:\n",
    "#   - index.faiss: The actual vector index\n",
    "#   - index.pkl: Metadata and document mappings\n",
    "# \n",
    "# âš ï¸ allow_dangerous_deserialization=True is required because loading\n",
    "# pickled data can be a security risk if from untrusted sources\n",
    "vectorstore = FAISS.load_local(\"index\", embeddings, allow_dangerous_deserialization=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# =============================================================================\n",
    "# STEP 2: Define a Custom Tool Using BaseTool\n",
    "# =============================================================================\n",
    "# Creating a custom tool by subclassing BaseTool gives you full control\n",
    "# over the tool's behavior and allows for more complex logic\n",
    "\n",
    "from typing import Optional\n",
    "from langchain.tools import BaseTool\n",
    "from langchain.callbacks.manager import AsyncCallbackManagerForToolRun, CallbackManagerForToolRun\n",
    "\n",
    "\n",
    "class CustomSearchTool(BaseTool):\n",
    "    \"\"\"\n",
    "    A custom tool that searches a restaurant FAQ vector store.\n",
    "    \n",
    "    When the agent needs information about the restaurant, it will use this tool\n",
    "    to retrieve relevant information from the vector store.\n",
    "    \"\"\"\n",
    "    \n",
    "    # REQUIRED: Tool name - used by the agent to reference this tool\n",
    "    name: str = \"restaurant search\"\n",
    "    \n",
    "    # REQUIRED: Description - CRITICAL! The agent uses this to decide when to use the tool\n",
    "    # Make it clear and specific about what the tool does\n",
    "    description: str = \"useful for when you need to answer questions about our restaurant\"\n",
    "\n",
    "    def _run(self, query: str, run_manager: Optional[CallbackManagerForToolRun] = None) -> str:\n",
    "        \"\"\"\n",
    "        The main method that gets called when the agent uses this tool.\n",
    "        \n",
    "        Args:\n",
    "            query: The search query from the agent\n",
    "            run_manager: Optional callback manager for tracking\n",
    "            \n",
    "        Returns:\n",
    "            String containing relevant information from the vector store\n",
    "        \"\"\"\n",
    "        # Convert vectorstore to a retriever\n",
    "        store = vectorstore.as_retriever()\n",
    "        \n",
    "        # Perform semantic search\n",
    "        docs = store.invoke(query)\n",
    "        \n",
    "        # Extract text content from retrieved documents\n",
    "        text_list = [doc.page_content for doc in docs]\n",
    "        \n",
    "        # Return combined results\n",
    "        return \"\\n\".join(text_list)\n",
    "\n",
    "    async def _arun(self, query: str, run_manager: Optional[AsyncCallbackManagerForToolRun] = None) -> str:\n",
    "        \"\"\"\n",
    "        Async version of the tool (required by BaseTool but not implemented here).\n",
    "        Raise NotImplementedError if async is not supported.\n",
    "        \"\"\"\n",
    "        raise NotImplementedError(\"custom_search does not support async\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "# =============================================================================\n",
    "# STEP 3: Create an Agent with Our Custom Tool\n",
    "# =============================================================================\n",
    "# Now we instantiate our custom tool and create a new agent\n",
    "# This agent will ONLY have access to the restaurant search tool\n",
    "\n",
    "from langchain.agents import AgentType\n",
    "\n",
    "# Create an instance of our custom tool\n",
    "# We can create multiple tools and pass them as a list\n",
    "tools = [CustomSearchTool()]\n",
    "\n",
    "# Initialize a new agent with our custom tool\n",
    "# Using the same ZERO_SHOT_REACT_DESCRIPTION pattern\n",
    "agent = initialize_agent(\n",
    "    tools, \n",
    "    llm, \n",
    "    agent=AgentType.ZERO_SHOT_REACT_DESCRIPTION, \n",
    "    verbose=True,               # Show the agent's thinking process\n",
    "    max_iterations=3,           # Limit iterations to prevent infinite loops\n",
    "    handle_parsing_errors=True  # Handle malformed LLM outputs gracefully\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Testing Our Custom Tool Agent\n",
    "\n",
    "#### Test 1: Question Outside the Tool's Scope\n",
    "\n",
    "Let's first ask a question that the restaurant tool can't answer. The agent should recognize this and use its own knowledge:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
      "\u001b[32;1m\u001b[1;3mThe A-Team is a fictional group from the television series of the same name. I need to recall the main characters and their roles. The primary members include:\n",
      "\n",
      "1. John \"Hannibal\" Smith - the leader and strategist.\n",
      "2. Templeton \"Faceman\" Peck - the conman and smooth talker.\n",
      "3. B.A. Baracus - the strongman and mechanic.\n",
      "4. H.M. Murdock - the pilot and often considered the crazy character.\n",
      "\n",
      "Thought: I now know the final answer\n",
      "Final Answer: The members of the A-Team are John \"Hannibal\" Smith, Templeton \"Faceman\" Peck, B.A. Baracus, and H.M. Murdock.\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'input': 'Who are the members of the A-Team?',\n",
       " 'output': 'The members of the A-Team are John \"Hannibal\" Smith, Templeton \"Faceman\" Peck, B.A. Baracus, and H.M. Murdock.'}"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# =============================================================================\n",
    "# Test 1: Out-of-Scope Question\n",
    "# =============================================================================\n",
    "# The agent only has the restaurant search tool, but this question is about\n",
    "# a TV show. The agent should:\n",
    "# 1. Recognize the tool won't help\n",
    "# 2. Use its own knowledge to answer\n",
    "#\n",
    "# Notice how the agent doesn't waste time searching for irrelevant info!\n",
    "\n",
    "agent.invoke(input=\"Who are the members of the A-Team?\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Test 2: Question Within the Tool's Scope\n",
    "\n",
    "Now let's ask about the restaurant. The agent should use our custom tool.\n",
    "\n",
    "---\n",
    "\n",
    "### ðŸ”§ Common Issue: \"Agent stopped due to iteration limit\"\n",
    "\n",
    "If you see this error, here's what's happening and how to fix it:\n",
    "\n",
    "**Root Cause**: The vector store returns fragmented results (questions without answers), causing the agent to keep searching.\n",
    "\n",
    "**Fixes (in order of effectiveness):**\n",
    "\n",
    "| Fix | Where | Code Change |\n",
    "|-----|-------|-------------|\n",
    "| 1. Retrieve more docs | `as_retriever()` | `search_kwargs={\"k\": 6}` |\n",
    "| 2. Better formatting | `_run()` return | Add clear headers like \"Information Found:\" |\n",
    "| 3. Increase iterations | `initialize_agent()` | `max_iterations=5` or higher |\n",
    "| 4. Improve description | `description` field | Be specific about what the tool returns |\n",
    "\n",
    "**Quick Fix** - Change the agent initialization to allow more iterations:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "# =============================================================================\n",
    "# ðŸ”§ FIX: Improved Custom Tool with Better Retrieval\n",
    "# =============================================================================\n",
    "# This improved version addresses the iteration limit issue\n",
    "\n",
    "class ImprovedSearchTool(BaseTool):\n",
    "    \"\"\"Improved restaurant search tool with better retrieval and formatting.\"\"\"\n",
    "    \n",
    "    name: str = \"restaurant search\"\n",
    "    \n",
    "    # FIX 1: More descriptive - tells agent what to expect\n",
    "    description: str = \"\"\"Search Bella Vista restaurant knowledge base.\n",
    "    Use for: hours, menu, reservations, ambiance, policies.\n",
    "    Returns FAQ answers - extract the information needed to answer the user.\"\"\"\n",
    "\n",
    "    def _run(self, query: str, run_manager: Optional[CallbackManagerForToolRun] = None) -> str:\n",
    "        # FIX 2: Retrieve more documents (6 instead of default 4)\n",
    "        store = vectorstore.as_retriever(search_kwargs={\"k\": 6})\n",
    "        docs = store.invoke(query)\n",
    "        \n",
    "        if not docs:\n",
    "            return \"No information found.\"\n",
    "        \n",
    "        # FIX 3: Format results clearly so agent can parse them\n",
    "        results = [f\"â€¢ {doc.page_content}\" for doc in docs]\n",
    "        return \"Restaurant Information:\\n\" + \"\\n\".join(results)\n",
    "    \n",
    "    async def _arun(self, query: str, run_manager=None) -> str:\n",
    "        raise NotImplementedError(\"Async not supported\")\n",
    "\n",
    "# FIX 4: Create agent with MORE iterations\n",
    "improved_tools = [ImprovedSearchTool()]\n",
    "improved_agent = initialize_agent(\n",
    "    improved_tools, \n",
    "    llm, \n",
    "    agent=AgentType.ZERO_SHOT_REACT_DESCRIPTION, \n",
    "    verbose=True,\n",
    "    max_iterations=5,  # Increased from 3 to 5\n",
    "    handle_parsing_errors=True\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
      "\u001b[32;1m\u001b[1;3mI need to find out the opening hours for the restaurant.  \n",
      "Action: restaurant search  \n",
      "Action Input: \"What are the opening hours of the restaurant?\"  \u001b[0m\n",
      "Observation: \u001b[36;1m\u001b[1;3mRestaurant Information:\n",
      "â€¢ Q: What are the hours of operation for Bella Vista?\n",
      "â€¢ Sundays, we welcome guests from 12 p.m. to 10 p.m.\n",
      "â€¢ during weekends and holidays, to ensure a seamless dining experience.\n",
      "â€¢ A: While walk-ins are always welcome, we recommend making a reservation, especially during weekends\n",
      "â€¢ Q: Do you offer vegetarian or vegan options at Bella Vista?\n",
      "â€¢ Q: What type of cuisine does Bella Vista serve?\u001b[0m\n",
      "Thought:\u001b[32;1m\u001b[1;3mI have found the opening hours for the restaurant.  \n",
      "Final Answer: Bella Vista opens on Sundays from 12 p.m. to 10 p.m.\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'input': 'When does the restaurant open?',\n",
       " 'output': 'Bella Vista opens on Sundays from 12 p.m. to 10 p.m.'}"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# =============================================================================\n",
    "# Test the Improved Agent\n",
    "# =============================================================================\n",
    "# Run the same query with the improved agent - should get better results!\n",
    "\n",
    "improved_agent.invoke(input=\"When does the restaurant open?\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Original Agent (for comparison - may hit iteration limit)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
      "\u001b[32;1m\u001b[1;3mI need to find out the opening hours of the restaurant.  \n",
      "Action: restaurant search  \n",
      "Action Input: \"restaurant opening hours\"  \u001b[0m\n",
      "Observation: \u001b[36;1m\u001b[1;3mduring weekends and holidays, to ensure a seamless dining experience.\n",
      "Sundays, we welcome guests from 12 p.m. to 10 p.m.\n",
      "A: While walk-ins are always welcome, we recommend making a reservation, especially during weekends\n",
      "Q: What are the hours of operation for Bella Vista?\u001b[0m\n",
      "Thought:\u001b[32;1m\u001b[1;3mI need to find out the hours of operation for Bella Vista.  \n",
      "Action: restaurant search  \n",
      "Action Input: \"Bella Vista hours of operation\"  \u001b[0m\n",
      "Observation: \u001b[36;1m\u001b[1;3mQ: What are the hours of operation for Bella Vista?\n",
      "dinner or a casual meal with friends, Bella Vista provides the perfect atmosphere.\n",
      "Q: Do I need a reservation for Bella Vista?\n",
      "Q: Is Bella Vista family-friendly?\u001b[0m\n",
      "Thought:\u001b[32;1m\u001b[1;3mI need to find out if Bella Vista is family-friendly.  \n",
      "Action: restaurant search  \n",
      "Action Input: \"Is Bella Vista family-friendly?\"  \u001b[0m\n",
      "Observation: \u001b[36;1m\u001b[1;3mQ: Is Bella Vista family-friendly?\n",
      "Q: What's the ambiance like at Bella Vista?\n",
      "dinner or a casual meal with friends, Bella Vista provides the perfect atmosphere.\n",
      "Q: Do I need a reservation for Bella Vista?\u001b[0m\n",
      "Thought:\u001b[32;1m\u001b[1;3m\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'input': 'When does the restaurant open?',\n",
       " 'output': 'Agent stopped due to iteration limit or time limit.'}"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# =============================================================================\n",
    "# Test 2: In-Scope Question (Uses Restaurant Tool)\n",
    "# =============================================================================\n",
    "# This question should trigger the restaurant search tool\n",
    "# Watch the Thought -> Action -> Observation cycle in the output\n",
    "#\n",
    "# The agent will:\n",
    "# 1. Recognize this is about the restaurant\n",
    "# 2. Call the \"restaurant search\" tool\n",
    "# 3. Parse the results\n",
    "# 4. Formulate an answer (or keep searching)\n",
    "\n",
    "agent.invoke(input=\"When does the restaurant open?\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Section 3: Conversational Agents with Memory\n",
    "\n",
    "### Why Add Memory?\n",
    "\n",
    "The agents we've built so far are **stateless** - they don't remember previous interactions. For chatbot-like applications, we need **conversational agents** that:\n",
    "- Remember the conversation history\n",
    "- Can refer back to previous topics\n",
    "- Maintain context across multiple turns\n",
    "\n",
    "### Key Differences from Stateless Agents\n",
    "\n",
    "| Feature | Stateless Agent | Conversational Agent |\n",
    "|---------|-----------------|---------------------|\n",
    "| Memory | None | Conversation history |\n",
    "| Context | Single query | Full conversation |\n",
    "| Agent Type | `ZERO_SHOT_REACT_DESCRIPTION` | `CHAT_CONVERSATIONAL_REACT_DESCRIPTION` |\n",
    "| Use Case | One-off questions | Multi-turn chat |"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "# =============================================================================\n",
    "# Creating a Conversational Agent with Memory\n",
    "# =============================================================================\n",
    "# This agent maintains conversation history and can reference previous messages\n",
    "\n",
    "from langchain.memory import ConversationBufferMemory\n",
    "from langchain_openai import ChatOpenAI\n",
    "\n",
    "# Create a memory object to store conversation history\n",
    "# memory_key=\"chat_history\" - The key used in the prompt template\n",
    "# return_messages=True - Store as message objects (required for chat models)\n",
    "memory = ConversationBufferMemory(memory_key=\"chat_history\", return_messages=True)\n",
    "\n",
    "# Initialize the LLM\n",
    "llm = ChatOpenAI(model=\"gpt-4o-mini\")\n",
    "\n",
    "# Create the conversational agent\n",
    "# Key differences from before:\n",
    "# 1. agent=AgentType.CHAT_CONVERSATIONAL_REACT_DESCRIPTION (chat-optimized)\n",
    "# 2. memory=memory (adds conversation history)\n",
    "agent_chain = initialize_agent(\n",
    "    tools, \n",
    "    llm, \n",
    "    agent=AgentType.CHAT_CONVERSATIONAL_REACT_DESCRIPTION,  # Chat-optimized agent\n",
    "    verbose=True, \n",
    "    memory=memory,                # Attach conversation memory\n",
    "    handle_parsing_errors=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[SystemMessagePromptTemplate(prompt=PromptTemplate(input_variables=[], input_types={}, partial_variables={}, template='Assistant is a large language model trained by OpenAI.\\n\\nAssistant is designed to be able to assist with a wide range of tasks, from answering simple questions to providing in-depth explanations and discussions on a wide range of topics. As a language model, Assistant is able to generate human-like text based on the input it receives, allowing it to engage in natural-sounding conversations and provide responses that are coherent and relevant to the topic at hand.\\n\\nAssistant is constantly learning and improving, and its capabilities are constantly evolving. It is able to process and understand large amounts of text, and can use this knowledge to provide accurate and informative responses to a wide range of questions. Additionally, Assistant is able to generate its own text based on the input it receives, allowing it to engage in discussions and provide explanations and descriptions on a wide range of topics.\\n\\nOverall, Assistant is a powerful system that can help with a wide range of tasks and provide valuable insights and information on a wide range of topics. Whether you need help with a specific question or just want to have a conversation about a particular topic, Assistant is here to assist.'), additional_kwargs={}), MessagesPlaceholder(variable_name='chat_history'), HumanMessagePromptTemplate(prompt=PromptTemplate(input_variables=['input'], input_types={}, partial_variables={}, template='TOOLS\\n------\\nAssistant can ask the user to use tools to look up information that may be helpful in answering the users original question. The tools the human can use are:\\n\\n> restaurant search: useful for when you need to answer questions about our restaurant\\n\\nRESPONSE FORMAT INSTRUCTIONS\\n----------------------------\\n\\nWhen responding to me, please output a response in one of two formats:\\n\\n**Option 1:**\\nUse this if you want the human to use a tool.\\nMarkdown code snippet formatted in the following schema:\\n\\n```json\\n{{\\n    \"action\": string, \\\\\\\\ The action to take. Must be one of restaurant search\\n    \"action_input\": string \\\\\\\\ The input to the action\\n}}\\n```\\n\\n**Option #2:**\\nUse this if you want to respond directly to the human. Markdown code snippet formatted in the following schema:\\n\\n```json\\n{{\\n    \"action\": \"Final Answer\",\\n    \"action_input\": string \\\\\\\\ You should put what you want to return to use here\\n}}\\n```\\n\\nUSER\\'S INPUT\\n--------------------\\nHere is the user\\'s input (remember to respond with a markdown code snippet of a json blob with a single action, and NOTHING else):\\n\\n{input}'), additional_kwargs={}), MessagesPlaceholder(variable_name='agent_scratchpad')]\n"
     ]
    }
   ],
   "source": [
    "# =============================================================================\n",
    "# Inspecting the Chat Agent's Prompt Template\n",
    "# =============================================================================\n",
    "# The conversational agent uses a different prompt structure with multiple \n",
    "# message templates instead of a single string template\n",
    "\n",
    "# Print the prompt messages (list of message templates)\n",
    "print(agent_chain.agent.llm_chain.prompt.messages)\n",
    "\n",
    "# =============================================================================\n",
    "# The output shows:\n",
    "# 1. SystemMessagePromptTemplate - Instructions for the AI assistant\n",
    "# 2. MessagesPlaceholder(\"chat_history\") - Where conversation history goes\n",
    "# 3. HumanMessagePromptTemplate - Where the current user input goes\n",
    "# 4. MessagesPlaceholder(\"agent_scratchpad\") - Agent's reasoning steps\n",
    "# ============================================================================="
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Demonstrating Conversational Memory\n",
    "\n",
    "Let's have a multi-turn conversation to see how the agent maintains context. Pay attention to:\n",
    "1. How the agent remembers the previous topic\n",
    "2. How \"there\" refers back to \"Paris\" from the previous question\n",
    "3. How the chat_history grows with each interaction\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
      "\u001b[32;1m\u001b[1;3m```json\n",
      "{\n",
      "    \"action\": \"Final Answer\",\n",
      "    \"action_input\": \"The capital of France is Paris.\"\n",
      "}\n",
      "```\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'input': 'What is the capital of France?',\n",
       " 'chat_history': [HumanMessage(content='What is the capital of France?', additional_kwargs={}, response_metadata={}),\n",
       "  AIMessage(content='The capital of France is Paris.', additional_kwargs={}, response_metadata={}),\n",
       "  HumanMessage(content='What is the capital of France?', additional_kwargs={}, response_metadata={}),\n",
       "  AIMessage(content='The capital of France is Paris.', additional_kwargs={}, response_metadata={})],\n",
       " 'output': 'The capital of France is Paris.'}"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# =============================================================================\n",
    "# Turn 1: Initial Question\n",
    "# =============================================================================\n",
    "# First message in the conversation - establishes context about France/Paris\n",
    "# The agent answers directly without needing to use any tools\n",
    "\n",
    "result = agent_chain.invoke(input=\"What is the capital of France?\")\n",
    "\n",
    "# Notice the output contains:\n",
    "# - 'input': The current question\n",
    "# - 'chat_history': List of previous messages (will grow)\n",
    "# - 'output': The agent's response\n",
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
      "\u001b[32;1m\u001b[1;3m```json\n",
      "{\n",
      "    \"action\": \"Final Answer\",\n",
      "    \"action_input\": \"In Paris, you might want to visit iconic landmarks such as the Eiffel Tower, the Louvre Museum, Notre-Dame Cathedral, and Montmartre. You can also explore beautiful parks like the Luxembourg Gardens and enjoy a stroll along the Seine River. Don't forget to try the local cuisine in charming cafÃ©s and restaurants!\"\n",
      "}\n",
      "```\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'input': 'Any suggestions what to visit there?',\n",
       " 'chat_history': [HumanMessage(content='What is the capital of France?', additional_kwargs={}, response_metadata={}),\n",
       "  AIMessage(content='The capital of France is Paris.', additional_kwargs={}, response_metadata={}),\n",
       "  HumanMessage(content='Any suggestions what to visit there?', additional_kwargs={}, response_metadata={}),\n",
       "  AIMessage(content=\"In Paris, you might want to visit iconic landmarks such as the Eiffel Tower, the Louvre Museum, Notre-Dame Cathedral, and Montmartre. You can also explore beautiful parks like the Luxembourg Gardens and enjoy a stroll along the Seine River. Don't forget to try the local cuisine in charming cafÃ©s and restaurants!\", additional_kwargs={}, response_metadata={})],\n",
       " 'output': \"In Paris, you might want to visit iconic landmarks such as the Eiffel Tower, the Louvre Museum, Notre-Dame Cathedral, and Montmartre. You can also explore beautiful parks like the Luxembourg Gardens and enjoy a stroll along the Seine River. Don't forget to try the local cuisine in charming cafÃ©s and restaurants!\"}"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# =============================================================================\n",
    "# Turn 2: Follow-up Question (Tests Memory!)\n",
    "# =============================================================================\n",
    "# Here's where memory matters: \"there\" refers to Paris!\n",
    "# Without memory, the agent wouldn't know what \"there\" means\n",
    "# \n",
    "# The agent correctly understands we're still talking about Paris\n",
    "\n",
    "result = agent_chain.invoke(input=\"Any suggestions what to visit there?\")\n",
    "\n",
    "# Check the chat_history - it now contains 2 exchanges (4 messages total)\n",
    "print(f\"Conversation now has {len(result['chat_history'])} messages\")\n",
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
      "\u001b[32;1m\u001b[1;3m```json\n",
      "{\n",
      "    \"action\": \"Final Answer\",\n",
      "    \"action_input\": \"China is a country in East Asia, known for its rich history, diverse culture, and significant global influence. The capital of China is Beijing.\"\n",
      "}\n",
      "```\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "Final conversation has 6 messages\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'input': 'What about china',\n",
       " 'chat_history': [HumanMessage(content='What is the capital of France?', additional_kwargs={}, response_metadata={}),\n",
       "  AIMessage(content='The capital of France is Paris.', additional_kwargs={}, response_metadata={}),\n",
       "  HumanMessage(content='What is the capital of France?', additional_kwargs={}, response_metadata={}),\n",
       "  AIMessage(content='The capital of France is Paris.', additional_kwargs={}, response_metadata={}),\n",
       "  HumanMessage(content='What about china', additional_kwargs={}, response_metadata={}),\n",
       "  AIMessage(content='China is a country in East Asia, known for its rich history, diverse culture, and significant global influence. The capital of China is Beijing.', additional_kwargs={}, response_metadata={})],\n",
       " 'output': 'China is a country in East Asia, known for its rich history, diverse culture, and significant global influence. The capital of China is Beijing.'}"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# =============================================================================\n",
    "# Turn 3: Topic Switch\n",
    "# =============================================================================\n",
    "# The agent can handle topic changes while maintaining full conversation history\n",
    "# It understands we're now asking about places to visit in China\n",
    "# (based on the context of previous travel-related questions)\n",
    "\n",
    "result = agent_chain.invoke(input=\"What about china\")\n",
    "\n",
    "# The full conversation history is preserved\n",
    "# This is useful for:\n",
    "# - Understanding user intent from context\n",
    "# - Providing personalized responses\n",
    "# - Maintaining coherent multi-turn dialogues\n",
    "print(f\"Final conversation has {len(result['chat_history'])} messages\")\n",
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# =============================================================================\n",
    "# ðŸŽ¯ EXERCISE: Try It Yourself!\n",
    "# =============================================================================\n",
    "# \n",
    "# Exercise 1: Create a simple tool using the @tool decorator\n",
    "# \n",
    "# from langchain.tools import tool\n",
    "# \n",
    "# @tool\n",
    "# def get_weather(city: str) -> str:\n",
    "#     \"\"\"Get the current weather for a city.\"\"\"\n",
    "#     # In a real app, you'd call a weather API\n",
    "#     return f\"The weather in {city} is sunny, 72Â°F\"\n",
    "# \n",
    "# Exercise 2: Add the weather tool to our agent and test it\n",
    "# \n",
    "# Exercise 3: Create an agent with multiple tools (calculator + restaurant + weather)\n",
    "#\n",
    "# =============================================================================\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your code here - try creating your own tools and agents!\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary & Key Takeaways\n",
    "\n",
    "### What We Learned\n",
    "\n",
    "1. **Agents** use LLMs as reasoning engines to decide which tools to use\n",
    "2. **Tools** extend agent capabilities with domain-specific functions\n",
    "3. **ReAct Pattern** (Thought â†’ Action â†’ Observation) is the foundation\n",
    "4. **Custom Tools** can be created by subclassing `BaseTool`\n",
    "5. **Conversational Agents** maintain memory across multiple turns\n",
    "\n",
    "### Agent Types Comparison\n",
    "\n",
    "| Agent Type | Memory | Best For |\n",
    "|------------|--------|----------|\n",
    "| `ZERO_SHOT_REACT_DESCRIPTION` | âŒ | One-off questions |\n",
    "| `CHAT_CONVERSATIONAL_REACT_DESCRIPTION` | âœ… | Multi-turn chat |\n",
    "| `OPENAI_FUNCTIONS` | Optional | Reliable tool calling |\n",
    "| `STRUCTURED_CHAT_ZERO_SHOT_REACT_DESCRIPTION` | âŒ | Complex tool inputs |\n",
    "\n",
    "### Best Practices\n",
    "\n",
    "1. **Tool Descriptions Matter**: Write clear, specific descriptions\n",
    "2. **Handle Errors**: Use `handle_parsing_errors=True`\n",
    "3. **Set Limits**: Use `max_iterations` to prevent infinite loops\n",
    "4. **Choose Right Agent**: Match agent type to your use case\n",
    "\n",
    "### What's Next?\n",
    "\n",
    "- Explore **LangGraph** for more advanced agent workflows\n",
    "- Learn about **Agent Tool Calling** with OpenAI Functions\n",
    "- Build **Multi-Agent Systems** for complex tasks\n",
    "\n",
    "---\n",
    "\n",
    "*For the latest best practices, check the [LangGraph Documentation](https://langchain-ai.github.io/langgraph/)*\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
