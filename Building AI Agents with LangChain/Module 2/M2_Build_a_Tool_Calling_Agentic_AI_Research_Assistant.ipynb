{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1kiH8lf1y4sD"
      },
      "source": [
        "# Build a Tool-Calling Agentic AI Research Assistant with LangChain"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NYBpZTjLnEXb"
      },
      "source": [
        "This demo will cover building AI Agents with the legacy LangChain `AgentExecutor`. These are fine for getting started, but for working with more advanced agents and having more finer control, LangChain recommends to use LangGraph, which we cover in other courses.\n",
        "\n",
        "Agents are systems that use an LLM as a reasoning engine to determine which actions to take and what the inputs to those actions should be. The results of those actions can then be fed back into the agent and it determines whether more actions are needed, or whether it is okay to stop.\n",
        "\n",
        "![](https://i.imgur.com/1uVnBAm.png)\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "L1KvMtf54l0d"
      },
      "source": [
        "## Install OpenAI, and LangChain dependencies"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2evPp14fy258",
        "outputId": "93aa791d-4f4c-4167-e6d1-7491fbeb93e5"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: langchain==0.3.14 in d:\\2. my workspace and notes\\1. demystify folders\\generativai_demystified\\venv\\lib\\site-packages (0.3.14)\n",
            "Requirement already satisfied: PyYAML>=5.3 in d:\\2. my workspace and notes\\1. demystify folders\\generativai_demystified\\venv\\lib\\site-packages (from langchain==0.3.14) (6.0.2)\n",
            "Requirement already satisfied: SQLAlchemy<3,>=1.4 in d:\\2. my workspace and notes\\1. demystify folders\\generativai_demystified\\venv\\lib\\site-packages (from langchain==0.3.14) (2.0.40)\n",
            "Requirement already satisfied: aiohttp<4.0.0,>=3.8.3 in d:\\2. my workspace and notes\\1. demystify folders\\generativai_demystified\\venv\\lib\\site-packages (from langchain==0.3.14) (3.11.18)\n",
            "Requirement already satisfied: langchain-core<0.4.0,>=0.3.29 in d:\\2. my workspace and notes\\1. demystify folders\\generativai_demystified\\venv\\lib\\site-packages (from langchain==0.3.14) (0.3.58)\n",
            "Requirement already satisfied: langchain-text-splitters<0.4.0,>=0.3.3 in d:\\2. my workspace and notes\\1. demystify folders\\generativai_demystified\\venv\\lib\\site-packages (from langchain==0.3.14) (0.3.8)\n",
            "Requirement already satisfied: langsmith<0.3,>=0.1.17 in d:\\2. my workspace and notes\\1. demystify folders\\generativai_demystified\\venv\\lib\\site-packages (from langchain==0.3.14) (0.2.11)\n",
            "Requirement already satisfied: numpy<3,>=1.26.2 in d:\\2. my workspace and notes\\1. demystify folders\\generativai_demystified\\venv\\lib\\site-packages (from langchain==0.3.14) (1.26.4)\n",
            "Requirement already satisfied: pydantic<3.0.0,>=2.7.4 in d:\\2. my workspace and notes\\1. demystify folders\\generativai_demystified\\venv\\lib\\site-packages (from langchain==0.3.14) (2.11.4)\n",
            "Requirement already satisfied: requests<3,>=2 in d:\\2. my workspace and notes\\1. demystify folders\\generativai_demystified\\venv\\lib\\site-packages (from langchain==0.3.14) (2.32.3)\n",
            "Requirement already satisfied: tenacity!=8.4.0,<10,>=8.1.0 in d:\\2. my workspace and notes\\1. demystify folders\\generativai_demystified\\venv\\lib\\site-packages (from langchain==0.3.14) (9.1.2)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in d:\\2. my workspace and notes\\1. demystify folders\\generativai_demystified\\venv\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain==0.3.14) (2.6.1)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in d:\\2. my workspace and notes\\1. demystify folders\\generativai_demystified\\venv\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain==0.3.14) (1.3.2)\n",
            "Requirement already satisfied: attrs>=17.3.0 in d:\\2. my workspace and notes\\1. demystify folders\\generativai_demystified\\venv\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain==0.3.14) (25.3.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in d:\\2. my workspace and notes\\1. demystify folders\\generativai_demystified\\venv\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain==0.3.14) (1.6.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in d:\\2. my workspace and notes\\1. demystify folders\\generativai_demystified\\venv\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain==0.3.14) (6.4.3)\n",
            "Requirement already satisfied: propcache>=0.2.0 in d:\\2. my workspace and notes\\1. demystify folders\\generativai_demystified\\venv\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain==0.3.14) (0.3.1)\n",
            "Requirement already satisfied: yarl<2.0,>=1.17.0 in d:\\2. my workspace and notes\\1. demystify folders\\generativai_demystified\\venv\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain==0.3.14) (1.20.0)\n",
            "Requirement already satisfied: jsonpatch<2.0,>=1.33 in d:\\2. my workspace and notes\\1. demystify folders\\generativai_demystified\\venv\\lib\\site-packages (from langchain-core<0.4.0,>=0.3.29->langchain==0.3.14) (1.33)\n",
            "Requirement already satisfied: packaging<25,>=23.2 in d:\\2. my workspace and notes\\1. demystify folders\\generativai_demystified\\venv\\lib\\site-packages (from langchain-core<0.4.0,>=0.3.29->langchain==0.3.14) (24.2)\n",
            "Requirement already satisfied: typing-extensions>=4.7 in d:\\2. my workspace and notes\\1. demystify folders\\generativai_demystified\\venv\\lib\\site-packages (from langchain-core<0.4.0,>=0.3.29->langchain==0.3.14) (4.13.2)\n",
            "Requirement already satisfied: jsonpointer>=1.9 in d:\\2. my workspace and notes\\1. demystify folders\\generativai_demystified\\venv\\lib\\site-packages (from jsonpatch<2.0,>=1.33->langchain-core<0.4.0,>=0.3.29->langchain==0.3.14) (3.0.0)\n",
            "Requirement already satisfied: httpx<1,>=0.23.0 in d:\\2. my workspace and notes\\1. demystify folders\\generativai_demystified\\venv\\lib\\site-packages (from langsmith<0.3,>=0.1.17->langchain==0.3.14) (0.28.1)\n",
            "Requirement already satisfied: orjson<4.0.0,>=3.9.14 in d:\\2. my workspace and notes\\1. demystify folders\\generativai_demystified\\venv\\lib\\site-packages (from langsmith<0.3,>=0.1.17->langchain==0.3.14) (3.10.18)\n",
            "Requirement already satisfied: requests-toolbelt<2.0.0,>=1.0.0 in d:\\2. my workspace and notes\\1. demystify folders\\generativai_demystified\\venv\\lib\\site-packages (from langsmith<0.3,>=0.1.17->langchain==0.3.14) (1.0.0)\n",
            "Requirement already satisfied: anyio in d:\\2. my workspace and notes\\1. demystify folders\\generativai_demystified\\venv\\lib\\site-packages (from httpx<1,>=0.23.0->langsmith<0.3,>=0.1.17->langchain==0.3.14) (4.9.0)\n",
            "Requirement already satisfied: certifi in d:\\2. my workspace and notes\\1. demystify folders\\generativai_demystified\\venv\\lib\\site-packages (from httpx<1,>=0.23.0->langsmith<0.3,>=0.1.17->langchain==0.3.14) (2025.4.26)\n",
            "Requirement already satisfied: httpcore==1.* in d:\\2. my workspace and notes\\1. demystify folders\\generativai_demystified\\venv\\lib\\site-packages (from httpx<1,>=0.23.0->langsmith<0.3,>=0.1.17->langchain==0.3.14) (1.0.9)\n",
            "Requirement already satisfied: idna in d:\\2. my workspace and notes\\1. demystify folders\\generativai_demystified\\venv\\lib\\site-packages (from httpx<1,>=0.23.0->langsmith<0.3,>=0.1.17->langchain==0.3.14) (3.10)\n",
            "Requirement already satisfied: h11>=0.16 in d:\\2. my workspace and notes\\1. demystify folders\\generativai_demystified\\venv\\lib\\site-packages (from httpcore==1.*->httpx<1,>=0.23.0->langsmith<0.3,>=0.1.17->langchain==0.3.14) (0.16.0)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in d:\\2. my workspace and notes\\1. demystify folders\\generativai_demystified\\venv\\lib\\site-packages (from pydantic<3.0.0,>=2.7.4->langchain==0.3.14) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.33.2 in d:\\2. my workspace and notes\\1. demystify folders\\generativai_demystified\\venv\\lib\\site-packages (from pydantic<3.0.0,>=2.7.4->langchain==0.3.14) (2.33.2)\n",
            "Requirement already satisfied: typing-inspection>=0.4.0 in d:\\2. my workspace and notes\\1. demystify folders\\generativai_demystified\\venv\\lib\\site-packages (from pydantic<3.0.0,>=2.7.4->langchain==0.3.14) (0.4.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in d:\\2. my workspace and notes\\1. demystify folders\\generativai_demystified\\venv\\lib\\site-packages (from requests<3,>=2->langchain==0.3.14) (3.4.2)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in d:\\2. my workspace and notes\\1. demystify folders\\generativai_demystified\\venv\\lib\\site-packages (from requests<3,>=2->langchain==0.3.14) (2.4.0)\n",
            "Requirement already satisfied: greenlet>=1 in d:\\2. my workspace and notes\\1. demystify folders\\generativai_demystified\\venv\\lib\\site-packages (from SQLAlchemy<3,>=1.4->langchain==0.3.14) (3.2.1)\n",
            "Requirement already satisfied: sniffio>=1.1 in d:\\2. my workspace and notes\\1. demystify folders\\generativai_demystified\\venv\\lib\\site-packages (from anyio->httpx<1,>=0.23.0->langsmith<0.3,>=0.1.17->langchain==0.3.14) (1.3.1)\n",
            "Requirement already satisfied: langchain-openai==0.3.0 in d:\\2. my workspace and notes\\1. demystify folders\\generativai_demystified\\venv\\lib\\site-packages (0.3.0)\n",
            "Requirement already satisfied: langchain-core<0.4.0,>=0.3.29 in d:\\2. my workspace and notes\\1. demystify folders\\generativai_demystified\\venv\\lib\\site-packages (from langchain-openai==0.3.0) (0.3.58)\n",
            "Requirement already satisfied: openai<2.0.0,>=1.58.1 in d:\\2. my workspace and notes\\1. demystify folders\\generativai_demystified\\venv\\lib\\site-packages (from langchain-openai==0.3.0) (1.77.0)\n",
            "Requirement already satisfied: tiktoken<1,>=0.7 in d:\\2. my workspace and notes\\1. demystify folders\\generativai_demystified\\venv\\lib\\site-packages (from langchain-openai==0.3.0) (0.9.0)\n",
            "Requirement already satisfied: langsmith<0.4,>=0.1.125 in d:\\2. my workspace and notes\\1. demystify folders\\generativai_demystified\\venv\\lib\\site-packages (from langchain-core<0.4.0,>=0.3.29->langchain-openai==0.3.0) (0.2.11)\n",
            "Requirement already satisfied: tenacity!=8.4.0,<10.0.0,>=8.1.0 in d:\\2. my workspace and notes\\1. demystify folders\\generativai_demystified\\venv\\lib\\site-packages (from langchain-core<0.4.0,>=0.3.29->langchain-openai==0.3.0) (9.1.2)\n",
            "Requirement already satisfied: jsonpatch<2.0,>=1.33 in d:\\2. my workspace and notes\\1. demystify folders\\generativai_demystified\\venv\\lib\\site-packages (from langchain-core<0.4.0,>=0.3.29->langchain-openai==0.3.0) (1.33)\n",
            "Requirement already satisfied: PyYAML>=5.3 in d:\\2. my workspace and notes\\1. demystify folders\\generativai_demystified\\venv\\lib\\site-packages (from langchain-core<0.4.0,>=0.3.29->langchain-openai==0.3.0) (6.0.2)\n",
            "Requirement already satisfied: packaging<25,>=23.2 in d:\\2. my workspace and notes\\1. demystify folders\\generativai_demystified\\venv\\lib\\site-packages (from langchain-core<0.4.0,>=0.3.29->langchain-openai==0.3.0) (24.2)\n",
            "Requirement already satisfied: typing-extensions>=4.7 in d:\\2. my workspace and notes\\1. demystify folders\\generativai_demystified\\venv\\lib\\site-packages (from langchain-core<0.4.0,>=0.3.29->langchain-openai==0.3.0) (4.13.2)\n",
            "Requirement already satisfied: pydantic<3.0.0,>=2.7.4 in d:\\2. my workspace and notes\\1. demystify folders\\generativai_demystified\\venv\\lib\\site-packages (from langchain-core<0.4.0,>=0.3.29->langchain-openai==0.3.0) (2.11.4)\n",
            "Requirement already satisfied: jsonpointer>=1.9 in d:\\2. my workspace and notes\\1. demystify folders\\generativai_demystified\\venv\\lib\\site-packages (from jsonpatch<2.0,>=1.33->langchain-core<0.4.0,>=0.3.29->langchain-openai==0.3.0) (3.0.0)\n",
            "Requirement already satisfied: httpx<1,>=0.23.0 in d:\\2. my workspace and notes\\1. demystify folders\\generativai_demystified\\venv\\lib\\site-packages (from langsmith<0.4,>=0.1.125->langchain-core<0.4.0,>=0.3.29->langchain-openai==0.3.0) (0.28.1)\n",
            "Requirement already satisfied: orjson<4.0.0,>=3.9.14 in d:\\2. my workspace and notes\\1. demystify folders\\generativai_demystified\\venv\\lib\\site-packages (from langsmith<0.4,>=0.1.125->langchain-core<0.4.0,>=0.3.29->langchain-openai==0.3.0) (3.10.18)\n",
            "Requirement already satisfied: requests<3,>=2 in d:\\2. my workspace and notes\\1. demystify folders\\generativai_demystified\\venv\\lib\\site-packages (from langsmith<0.4,>=0.1.125->langchain-core<0.4.0,>=0.3.29->langchain-openai==0.3.0) (2.32.3)\n",
            "Requirement already satisfied: requests-toolbelt<2.0.0,>=1.0.0 in d:\\2. my workspace and notes\\1. demystify folders\\generativai_demystified\\venv\\lib\\site-packages (from langsmith<0.4,>=0.1.125->langchain-core<0.4.0,>=0.3.29->langchain-openai==0.3.0) (1.0.0)\n",
            "Requirement already satisfied: anyio in d:\\2. my workspace and notes\\1. demystify folders\\generativai_demystified\\venv\\lib\\site-packages (from httpx<1,>=0.23.0->langsmith<0.4,>=0.1.125->langchain-core<0.4.0,>=0.3.29->langchain-openai==0.3.0) (4.9.0)\n",
            "Requirement already satisfied: certifi in d:\\2. my workspace and notes\\1. demystify folders\\generativai_demystified\\venv\\lib\\site-packages (from httpx<1,>=0.23.0->langsmith<0.4,>=0.1.125->langchain-core<0.4.0,>=0.3.29->langchain-openai==0.3.0) (2025.4.26)\n",
            "Requirement already satisfied: httpcore==1.* in d:\\2. my workspace and notes\\1. demystify folders\\generativai_demystified\\venv\\lib\\site-packages (from httpx<1,>=0.23.0->langsmith<0.4,>=0.1.125->langchain-core<0.4.0,>=0.3.29->langchain-openai==0.3.0) (1.0.9)\n",
            "Requirement already satisfied: idna in d:\\2. my workspace and notes\\1. demystify folders\\generativai_demystified\\venv\\lib\\site-packages (from httpx<1,>=0.23.0->langsmith<0.4,>=0.1.125->langchain-core<0.4.0,>=0.3.29->langchain-openai==0.3.0) (3.10)\n",
            "Requirement already satisfied: h11>=0.16 in d:\\2. my workspace and notes\\1. demystify folders\\generativai_demystified\\venv\\lib\\site-packages (from httpcore==1.*->httpx<1,>=0.23.0->langsmith<0.4,>=0.1.125->langchain-core<0.4.0,>=0.3.29->langchain-openai==0.3.0) (0.16.0)\n",
            "Requirement already satisfied: distro<2,>=1.7.0 in d:\\2. my workspace and notes\\1. demystify folders\\generativai_demystified\\venv\\lib\\site-packages (from openai<2.0.0,>=1.58.1->langchain-openai==0.3.0) (1.9.0)\n",
            "Requirement already satisfied: jiter<1,>=0.4.0 in d:\\2. my workspace and notes\\1. demystify folders\\generativai_demystified\\venv\\lib\\site-packages (from openai<2.0.0,>=1.58.1->langchain-openai==0.3.0) (0.9.0)\n",
            "Requirement already satisfied: sniffio in d:\\2. my workspace and notes\\1. demystify folders\\generativai_demystified\\venv\\lib\\site-packages (from openai<2.0.0,>=1.58.1->langchain-openai==0.3.0) (1.3.1)\n",
            "Requirement already satisfied: tqdm>4 in d:\\2. my workspace and notes\\1. demystify folders\\generativai_demystified\\venv\\lib\\site-packages (from openai<2.0.0,>=1.58.1->langchain-openai==0.3.0) (4.67.1)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in d:\\2. my workspace and notes\\1. demystify folders\\generativai_demystified\\venv\\lib\\site-packages (from pydantic<3.0.0,>=2.7.4->langchain-core<0.4.0,>=0.3.29->langchain-openai==0.3.0) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.33.2 in d:\\2. my workspace and notes\\1. demystify folders\\generativai_demystified\\venv\\lib\\site-packages (from pydantic<3.0.0,>=2.7.4->langchain-core<0.4.0,>=0.3.29->langchain-openai==0.3.0) (2.33.2)\n",
            "Requirement already satisfied: typing-inspection>=0.4.0 in d:\\2. my workspace and notes\\1. demystify folders\\generativai_demystified\\venv\\lib\\site-packages (from pydantic<3.0.0,>=2.7.4->langchain-core<0.4.0,>=0.3.29->langchain-openai==0.3.0) (0.4.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in d:\\2. my workspace and notes\\1. demystify folders\\generativai_demystified\\venv\\lib\\site-packages (from requests<3,>=2->langsmith<0.4,>=0.1.125->langchain-core<0.4.0,>=0.3.29->langchain-openai==0.3.0) (3.4.2)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in d:\\2. my workspace and notes\\1. demystify folders\\generativai_demystified\\venv\\lib\\site-packages (from requests<3,>=2->langsmith<0.4,>=0.1.125->langchain-core<0.4.0,>=0.3.29->langchain-openai==0.3.0) (2.4.0)\n",
            "Requirement already satisfied: regex>=2022.1.18 in d:\\2. my workspace and notes\\1. demystify folders\\generativai_demystified\\venv\\lib\\site-packages (from tiktoken<1,>=0.7->langchain-openai==0.3.0) (2024.11.6)\n",
            "Requirement already satisfied: colorama in d:\\2. my workspace and notes\\1. demystify folders\\generativai_demystified\\venv\\lib\\site-packages (from tqdm>4->openai<2.0.0,>=1.58.1->langchain-openai==0.3.0) (0.4.6)\n",
            "Requirement already satisfied: langchain-community==0.3.14 in d:\\2. my workspace and notes\\1. demystify folders\\generativai_demystified\\venv\\lib\\site-packages (0.3.14)\n",
            "Requirement already satisfied: PyYAML>=5.3 in d:\\2. my workspace and notes\\1. demystify folders\\generativai_demystified\\venv\\lib\\site-packages (from langchain-community==0.3.14) (6.0.2)\n",
            "Requirement already satisfied: SQLAlchemy<3,>=1.4 in d:\\2. my workspace and notes\\1. demystify folders\\generativai_demystified\\venv\\lib\\site-packages (from langchain-community==0.3.14) (2.0.40)\n",
            "Requirement already satisfied: aiohttp<4.0.0,>=3.8.3 in d:\\2. my workspace and notes\\1. demystify folders\\generativai_demystified\\venv\\lib\\site-packages (from langchain-community==0.3.14) (3.11.18)\n",
            "Requirement already satisfied: dataclasses-json<0.7,>=0.5.7 in d:\\2. my workspace and notes\\1. demystify folders\\generativai_demystified\\venv\\lib\\site-packages (from langchain-community==0.3.14) (0.6.7)\n",
            "Requirement already satisfied: httpx-sse<0.5.0,>=0.4.0 in d:\\2. my workspace and notes\\1. demystify folders\\generativai_demystified\\venv\\lib\\site-packages (from langchain-community==0.3.14) (0.4.0)\n",
            "Requirement already satisfied: langchain<0.4.0,>=0.3.14 in d:\\2. my workspace and notes\\1. demystify folders\\generativai_demystified\\venv\\lib\\site-packages (from langchain-community==0.3.14) (0.3.14)\n",
            "Requirement already satisfied: langchain-core<0.4.0,>=0.3.29 in d:\\2. my workspace and notes\\1. demystify folders\\generativai_demystified\\venv\\lib\\site-packages (from langchain-community==0.3.14) (0.3.58)\n",
            "Requirement already satisfied: langsmith<0.3,>=0.1.125 in d:\\2. my workspace and notes\\1. demystify folders\\generativai_demystified\\venv\\lib\\site-packages (from langchain-community==0.3.14) (0.2.11)\n",
            "Requirement already satisfied: numpy<3,>=1.26.2 in d:\\2. my workspace and notes\\1. demystify folders\\generativai_demystified\\venv\\lib\\site-packages (from langchain-community==0.3.14) (1.26.4)\n",
            "Requirement already satisfied: pydantic-settings<3.0.0,>=2.4.0 in d:\\2. my workspace and notes\\1. demystify folders\\generativai_demystified\\venv\\lib\\site-packages (from langchain-community==0.3.14) (2.9.1)\n",
            "Requirement already satisfied: requests<3,>=2 in d:\\2. my workspace and notes\\1. demystify folders\\generativai_demystified\\venv\\lib\\site-packages (from langchain-community==0.3.14) (2.32.3)\n",
            "Requirement already satisfied: tenacity!=8.4.0,<10,>=8.1.0 in d:\\2. my workspace and notes\\1. demystify folders\\generativai_demystified\\venv\\lib\\site-packages (from langchain-community==0.3.14) (9.1.2)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in d:\\2. my workspace and notes\\1. demystify folders\\generativai_demystified\\venv\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community==0.3.14) (2.6.1)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in d:\\2. my workspace and notes\\1. demystify folders\\generativai_demystified\\venv\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community==0.3.14) (1.3.2)\n",
            "Requirement already satisfied: attrs>=17.3.0 in d:\\2. my workspace and notes\\1. demystify folders\\generativai_demystified\\venv\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community==0.3.14) (25.3.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in d:\\2. my workspace and notes\\1. demystify folders\\generativai_demystified\\venv\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community==0.3.14) (1.6.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in d:\\2. my workspace and notes\\1. demystify folders\\generativai_demystified\\venv\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community==0.3.14) (6.4.3)\n",
            "Requirement already satisfied: propcache>=0.2.0 in d:\\2. my workspace and notes\\1. demystify folders\\generativai_demystified\\venv\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community==0.3.14) (0.3.1)\n",
            "Requirement already satisfied: yarl<2.0,>=1.17.0 in d:\\2. my workspace and notes\\1. demystify folders\\generativai_demystified\\venv\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community==0.3.14) (1.20.0)\n",
            "Requirement already satisfied: marshmallow<4.0.0,>=3.18.0 in d:\\2. my workspace and notes\\1. demystify folders\\generativai_demystified\\venv\\lib\\site-packages (from dataclasses-json<0.7,>=0.5.7->langchain-community==0.3.14) (3.26.1)\n",
            "Requirement already satisfied: typing-inspect<1,>=0.4.0 in d:\\2. my workspace and notes\\1. demystify folders\\generativai_demystified\\venv\\lib\\site-packages (from dataclasses-json<0.7,>=0.5.7->langchain-community==0.3.14) (0.9.0)\n",
            "Requirement already satisfied: langchain-text-splitters<0.4.0,>=0.3.3 in d:\\2. my workspace and notes\\1. demystify folders\\generativai_demystified\\venv\\lib\\site-packages (from langchain<0.4.0,>=0.3.14->langchain-community==0.3.14) (0.3.8)\n",
            "Requirement already satisfied: pydantic<3.0.0,>=2.7.4 in d:\\2. my workspace and notes\\1. demystify folders\\generativai_demystified\\venv\\lib\\site-packages (from langchain<0.4.0,>=0.3.14->langchain-community==0.3.14) (2.11.4)\n",
            "Requirement already satisfied: jsonpatch<2.0,>=1.33 in d:\\2. my workspace and notes\\1. demystify folders\\generativai_demystified\\venv\\lib\\site-packages (from langchain-core<0.4.0,>=0.3.29->langchain-community==0.3.14) (1.33)\n",
            "Requirement already satisfied: packaging<25,>=23.2 in d:\\2. my workspace and notes\\1. demystify folders\\generativai_demystified\\venv\\lib\\site-packages (from langchain-core<0.4.0,>=0.3.29->langchain-community==0.3.14) (24.2)\n",
            "Requirement already satisfied: typing-extensions>=4.7 in d:\\2. my workspace and notes\\1. demystify folders\\generativai_demystified\\venv\\lib\\site-packages (from langchain-core<0.4.0,>=0.3.29->langchain-community==0.3.14) (4.13.2)\n",
            "Requirement already satisfied: jsonpointer>=1.9 in d:\\2. my workspace and notes\\1. demystify folders\\generativai_demystified\\venv\\lib\\site-packages (from jsonpatch<2.0,>=1.33->langchain-core<0.4.0,>=0.3.29->langchain-community==0.3.14) (3.0.0)\n",
            "Requirement already satisfied: httpx<1,>=0.23.0 in d:\\2. my workspace and notes\\1. demystify folders\\generativai_demystified\\venv\\lib\\site-packages (from langsmith<0.3,>=0.1.125->langchain-community==0.3.14) (0.28.1)\n",
            "Requirement already satisfied: orjson<4.0.0,>=3.9.14 in d:\\2. my workspace and notes\\1. demystify folders\\generativai_demystified\\venv\\lib\\site-packages (from langsmith<0.3,>=0.1.125->langchain-community==0.3.14) (3.10.18)\n",
            "Requirement already satisfied: requests-toolbelt<2.0.0,>=1.0.0 in d:\\2. my workspace and notes\\1. demystify folders\\generativai_demystified\\venv\\lib\\site-packages (from langsmith<0.3,>=0.1.125->langchain-community==0.3.14) (1.0.0)\n",
            "Requirement already satisfied: anyio in d:\\2. my workspace and notes\\1. demystify folders\\generativai_demystified\\venv\\lib\\site-packages (from httpx<1,>=0.23.0->langsmith<0.3,>=0.1.125->langchain-community==0.3.14) (4.9.0)\n",
            "Requirement already satisfied: certifi in d:\\2. my workspace and notes\\1. demystify folders\\generativai_demystified\\venv\\lib\\site-packages (from httpx<1,>=0.23.0->langsmith<0.3,>=0.1.125->langchain-community==0.3.14) (2025.4.26)\n",
            "Requirement already satisfied: httpcore==1.* in d:\\2. my workspace and notes\\1. demystify folders\\generativai_demystified\\venv\\lib\\site-packages (from httpx<1,>=0.23.0->langsmith<0.3,>=0.1.125->langchain-community==0.3.14) (1.0.9)\n",
            "Requirement already satisfied: idna in d:\\2. my workspace and notes\\1. demystify folders\\generativai_demystified\\venv\\lib\\site-packages (from httpx<1,>=0.23.0->langsmith<0.3,>=0.1.125->langchain-community==0.3.14) (3.10)\n",
            "Requirement already satisfied: h11>=0.16 in d:\\2. my workspace and notes\\1. demystify folders\\generativai_demystified\\venv\\lib\\site-packages (from httpcore==1.*->httpx<1,>=0.23.0->langsmith<0.3,>=0.1.125->langchain-community==0.3.14) (0.16.0)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in d:\\2. my workspace and notes\\1. demystify folders\\generativai_demystified\\venv\\lib\\site-packages (from pydantic<3.0.0,>=2.7.4->langchain<0.4.0,>=0.3.14->langchain-community==0.3.14) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.33.2 in d:\\2. my workspace and notes\\1. demystify folders\\generativai_demystified\\venv\\lib\\site-packages (from pydantic<3.0.0,>=2.7.4->langchain<0.4.0,>=0.3.14->langchain-community==0.3.14) (2.33.2)\n",
            "Requirement already satisfied: typing-inspection>=0.4.0 in d:\\2. my workspace and notes\\1. demystify folders\\generativai_demystified\\venv\\lib\\site-packages (from pydantic<3.0.0,>=2.7.4->langchain<0.4.0,>=0.3.14->langchain-community==0.3.14) (0.4.0)\n",
            "Requirement already satisfied: python-dotenv>=0.21.0 in d:\\2. my workspace and notes\\1. demystify folders\\generativai_demystified\\venv\\lib\\site-packages (from pydantic-settings<3.0.0,>=2.4.0->langchain-community==0.3.14) (1.1.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in d:\\2. my workspace and notes\\1. demystify folders\\generativai_demystified\\venv\\lib\\site-packages (from requests<3,>=2->langchain-community==0.3.14) (3.4.2)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in d:\\2. my workspace and notes\\1. demystify folders\\generativai_demystified\\venv\\lib\\site-packages (from requests<3,>=2->langchain-community==0.3.14) (2.4.0)\n",
            "Requirement already satisfied: greenlet>=1 in d:\\2. my workspace and notes\\1. demystify folders\\generativai_demystified\\venv\\lib\\site-packages (from SQLAlchemy<3,>=1.4->langchain-community==0.3.14) (3.2.1)\n",
            "Requirement already satisfied: mypy-extensions>=0.3.0 in d:\\2. my workspace and notes\\1. demystify folders\\generativai_demystified\\venv\\lib\\site-packages (from typing-inspect<1,>=0.4.0->dataclasses-json<0.7,>=0.5.7->langchain-community==0.3.14) (1.1.0)\n",
            "Requirement already satisfied: sniffio>=1.1 in d:\\2. my workspace and notes\\1. demystify folders\\generativai_demystified\\venv\\lib\\site-packages (from anyio->httpx<1,>=0.23.0->langsmith<0.3,>=0.1.125->langchain-community==0.3.14) (1.3.1)\n"
          ]
        }
      ],
      "source": [
        "!pip install langchain==0.3.14\n",
        "!pip install langchain-openai==0.3.0\n",
        "!pip install langchain-community==0.3.14"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AakmY6B_zYte",
        "outputId": "f206e910-8ac4-4423-c1af-c000a92f3429"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: markitdown in d:\\2. my workspace and notes\\1. demystify folders\\generativai_demystified\\venv\\lib\\site-packages (0.1.1)\n",
            "Requirement already satisfied: beautifulsoup4 in d:\\2. my workspace and notes\\1. demystify folders\\generativai_demystified\\venv\\lib\\site-packages (from markitdown) (4.13.4)\n",
            "Requirement already satisfied: charset-normalizer in d:\\2. my workspace and notes\\1. demystify folders\\generativai_demystified\\venv\\lib\\site-packages (from markitdown) (3.4.2)\n",
            "Requirement already satisfied: magika~=0.6.1 in d:\\2. my workspace and notes\\1. demystify folders\\generativai_demystified\\venv\\lib\\site-packages (from markitdown) (0.6.2)\n",
            "Requirement already satisfied: markdownify in d:\\2. my workspace and notes\\1. demystify folders\\generativai_demystified\\venv\\lib\\site-packages (from markitdown) (1.1.0)\n",
            "Requirement already satisfied: requests in d:\\2. my workspace and notes\\1. demystify folders\\generativai_demystified\\venv\\lib\\site-packages (from markitdown) (2.32.3)\n",
            "Requirement already satisfied: click>=8.1.7 in d:\\2. my workspace and notes\\1. demystify folders\\generativai_demystified\\venv\\lib\\site-packages (from magika~=0.6.1->markitdown) (8.1.8)\n",
            "Requirement already satisfied: onnxruntime>=1.17.0 in d:\\2. my workspace and notes\\1. demystify folders\\generativai_demystified\\venv\\lib\\site-packages (from magika~=0.6.1->markitdown) (1.21.1)\n",
            "Requirement already satisfied: numpy>=1.26 in d:\\2. my workspace and notes\\1. demystify folders\\generativai_demystified\\venv\\lib\\site-packages (from magika~=0.6.1->markitdown) (1.26.4)\n",
            "Requirement already satisfied: python-dotenv>=1.0.1 in d:\\2. my workspace and notes\\1. demystify folders\\generativai_demystified\\venv\\lib\\site-packages (from magika~=0.6.1->markitdown) (1.1.0)\n",
            "Requirement already satisfied: colorama in d:\\2. my workspace and notes\\1. demystify folders\\generativai_demystified\\venv\\lib\\site-packages (from click>=8.1.7->magika~=0.6.1->markitdown) (0.4.6)\n",
            "Requirement already satisfied: coloredlogs in d:\\2. my workspace and notes\\1. demystify folders\\generativai_demystified\\venv\\lib\\site-packages (from onnxruntime>=1.17.0->magika~=0.6.1->markitdown) (15.0.1)\n",
            "Requirement already satisfied: flatbuffers in d:\\2. my workspace and notes\\1. demystify folders\\generativai_demystified\\venv\\lib\\site-packages (from onnxruntime>=1.17.0->magika~=0.6.1->markitdown) (25.2.10)\n",
            "Requirement already satisfied: packaging in d:\\2. my workspace and notes\\1. demystify folders\\generativai_demystified\\venv\\lib\\site-packages (from onnxruntime>=1.17.0->magika~=0.6.1->markitdown) (24.2)\n",
            "Requirement already satisfied: protobuf in d:\\2. my workspace and notes\\1. demystify folders\\generativai_demystified\\venv\\lib\\site-packages (from onnxruntime>=1.17.0->magika~=0.6.1->markitdown) (5.29.4)\n",
            "Requirement already satisfied: sympy in d:\\2. my workspace and notes\\1. demystify folders\\generativai_demystified\\venv\\lib\\site-packages (from onnxruntime>=1.17.0->magika~=0.6.1->markitdown) (1.14.0)\n",
            "Requirement already satisfied: soupsieve>1.2 in d:\\2. my workspace and notes\\1. demystify folders\\generativai_demystified\\venv\\lib\\site-packages (from beautifulsoup4->markitdown) (2.7)\n",
            "Requirement already satisfied: typing-extensions>=4.0.0 in d:\\2. my workspace and notes\\1. demystify folders\\generativai_demystified\\venv\\lib\\site-packages (from beautifulsoup4->markitdown) (4.13.2)\n",
            "Requirement already satisfied: humanfriendly>=9.1 in d:\\2. my workspace and notes\\1. demystify folders\\generativai_demystified\\venv\\lib\\site-packages (from coloredlogs->onnxruntime>=1.17.0->magika~=0.6.1->markitdown) (10.0)\n",
            "Requirement already satisfied: pyreadline3 in d:\\2. my workspace and notes\\1. demystify folders\\generativai_demystified\\venv\\lib\\site-packages (from humanfriendly>=9.1->coloredlogs->onnxruntime>=1.17.0->magika~=0.6.1->markitdown) (3.5.4)\n",
            "Requirement already satisfied: six<2,>=1.15 in d:\\2. my workspace and notes\\1. demystify folders\\generativai_demystified\\venv\\lib\\site-packages (from markdownify->markitdown) (1.17.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in d:\\2. my workspace and notes\\1. demystify folders\\generativai_demystified\\venv\\lib\\site-packages (from requests->markitdown) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in d:\\2. my workspace and notes\\1. demystify folders\\generativai_demystified\\venv\\lib\\site-packages (from requests->markitdown) (2.4.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in d:\\2. my workspace and notes\\1. demystify folders\\generativai_demystified\\venv\\lib\\site-packages (from requests->markitdown) (2025.4.26)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in d:\\2. my workspace and notes\\1. demystify folders\\generativai_demystified\\venv\\lib\\site-packages (from sympy->onnxruntime>=1.17.0->magika~=0.6.1->markitdown) (1.3.0)\n"
          ]
        }
      ],
      "source": [
        "!pip install markitdown"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "H9c37cLnSrbg"
      },
      "source": [
        "## Enter Open AI API Key"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cv3JzCEx_PAd",
        "outputId": "3e7a5d36-2bd9-49d8-88bc-5753c36d235c"
      },
      "outputs": [],
      "source": [
        "from getpass import getpass\n",
        "\n",
        "OPENAI_KEY = getpass('Enter Open AI API Key: ')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ucWRRI3QztL2"
      },
      "source": [
        "## Enter Tavily Search API Key\n",
        "\n",
        "Get a free API key from [here](https://tavily.com/#api)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mK-1WLzOrJdb",
        "outputId": "143b9b1d-9ae9-4ab1-e830-27bab3836ee2"
      },
      "outputs": [],
      "source": [
        "TAVILY_API_KEY = getpass('Enter Tavily Search API Key: ')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ce5arICZEEov"
      },
      "source": [
        "## Enter WeatherAPI API Key\n",
        "\n",
        "Get a free API key from [here](https://www.weatherapi.com/signup.aspx)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XpAMz1XgEEov",
        "outputId": "da1143c0-4243-4799-d76e-79e41dd8ea5f"
      },
      "outputs": [],
      "source": [
        "WEATHER_API_KEY = getpass('Enter WeatherAPI API Key: ')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1T0s0um5Svfa"
      },
      "source": [
        "## Setup Environment Variables"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "x1YSuHNF_lbh"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "\n",
        "os.environ['OPENAI_API_KEY'] = OPENAI_KEY\n",
        "os.environ['TAVILY_API_KEY'] = TAVILY_API_KEY"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "howf-v0ARWbv"
      },
      "source": [
        "## Create Tools\n",
        "\n",
        "Here we create two custom tools which are wrappers on top of the [Tavily API](https://tavily.com/#api) and [WeatherAPI](https://www.weatherapi.com/)\n",
        "\n",
        "- Web Search tool with information extraction\n",
        "- Weather tool\n",
        "\n",
        "![](https://i.imgur.com/TyPAYXE.png)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ue8xgu9WpuPi",
        "outputId": "5f312771-4696-4ee6-9d37-6a890b73086d"
      },
      "outputs": [],
      "source": [
        "from langchain_core.tools import tool\n",
        "from markitdown import MarkItDown\n",
        "from langchain_community.tools.tavily_search import TavilySearchResults\n",
        "from tqdm import tqdm\n",
        "from concurrent.futures import ThreadPoolExecutor, TimeoutError\n",
        "import requests\n",
        "import json\n",
        "from warnings import filterwarnings\n",
        "filterwarnings('ignore')\n",
        "\n",
        "tavily_tool = TavilySearchResults(max_results=5,\n",
        "                                  search_depth='advanced',\n",
        "                                  include_answer=False,\n",
        "                                  include_raw_content=True)\n",
        "# certain websites won't let you crawl them unless you specify a user-agent\n",
        "session = requests.Session()\n",
        "session.headers.update({\n",
        "    \"User-Agent\": \"Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/112.0.0.0 Safari/537.36\",\n",
        "    \"Accept-Language\": \"en-US,en;q=0.9\",\n",
        "    \"Accept-Encoding\": \"gzip, deflate, br\"\n",
        "})\n",
        "md = MarkItDown(requests_session=session)\n",
        "\n",
        "@tool\n",
        "def search_web_extract_info(query: str) -> list:\n",
        "    \"\"\"Search the web for a query and extracts useful information from the search links.\"\"\"\n",
        "    print('Calling web search tool')\n",
        "    results = tavily_tool.invoke(query)\n",
        "    docs = []\n",
        "\n",
        "    def extract_content(url):\n",
        "        \"\"\"Helper function to extract content from a URL.\"\"\"\n",
        "        extracted_info = md.convert(url)\n",
        "        text_title = extracted_info.title.strip()\n",
        "        text_content = extracted_info.text_content.strip()\n",
        "        return text_title + '\\n' + text_content\n",
        "    # parallelize execution of different urls\n",
        "    with ThreadPoolExecutor() as executor:\n",
        "        for result in tqdm(results):\n",
        "            try:\n",
        "                future = executor.submit(extract_content, result['url'])\n",
        "                # Wait for up to 15 seconds for the task to complete\n",
        "                content = future.result(timeout=15)\n",
        "                docs.append(content)\n",
        "            except TimeoutError:\n",
        "                print(f\"Extraction timed out for url: {result['url']}\")\n",
        "            except Exception as e:\n",
        "                print(f\"Error extracting from url: {result['url']} - {e}\")\n",
        "\n",
        "    return docs\n",
        "\n",
        "\n",
        "@tool\n",
        "def get_weather(query: str) -> list:\n",
        "    \"\"\"Search weatherapi to get the current weather of the queried location.\"\"\"\n",
        "    print('Calling weather tool')\n",
        "    base_url = \"http://api.weatherapi.com/v1/current.json\"\n",
        "    complete_url = f\"{base_url}?key={WEATHER_API_KEY}&q={query}\"\n",
        "\n",
        "    response = requests.get(complete_url)\n",
        "    data = response.json()\n",
        "    if data.get(\"location\"):\n",
        "        return data\n",
        "    else:\n",
        "        return \"Weather Data Not Found\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "D2N5192vikJR"
      },
      "source": [
        "## Test Tool Calling with LLM"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "_B2EFrwTpuXB"
      },
      "outputs": [],
      "source": [
        "from langchain_openai import ChatOpenAI\n",
        "\n",
        "chatgpt = ChatOpenAI(model=\"gpt-4o\", temperature=0)\n",
        "tools = [search_web_extract_info, get_weather]\n",
        "\n",
        "chatgpt_with_tools = chatgpt.bind_tools(tools)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "W0rVVBGDpuYw",
        "outputId": "95231440-d9de-4c58-a536-e05d67e0f279"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "[{'name': 'search_web_extract_info',\n",
              "  'args': {'query': 'Microsoft earnings call Q4 2024 details'},\n",
              "  'id': 'call_5zhAcU2t2VdxzdMXslBNAqA2',\n",
              "  'type': 'tool_call'}]"
            ]
          },
          "execution_count": 7,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "prompt = \"Get details of Microsoft's earnings call Q4 2024\"\n",
        "response = chatgpt_with_tools.invoke(prompt)\n",
        "response.tool_calls"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9qfchhGEpuaj",
        "outputId": "d4674863-91c3-44ea-8a7e-67121e208f3b"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "[{'name': 'get_weather',\n",
              "  'args': {'query': 'Bangalore'},\n",
              "  'id': 'call_obFy86zq2VyLbxxZMuMbzGT4',\n",
              "  'type': 'tool_call'}]"
            ]
          },
          "execution_count": 8,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "prompt = \"how is the weather in Bangalore today\"\n",
        "response = chatgpt_with_tools.invoke(prompt)\n",
        "response.tool_calls"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "c7kvwG3SmREW"
      },
      "source": [
        "## Build and Test AI Agent\n",
        "\n",
        "Now that we have defined the tools and the LLM, we can create the agent. We will be using a tool calling agent to bind the tools to the agent with a prompt. We will also add in the capability to store historical conversations as memory"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "grNq1I6_5dxC",
        "outputId": "7353b0b3-cb8d-4324-efc1-601180a6bc7d"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "[SystemMessagePromptTemplate(prompt=PromptTemplate(input_variables=[], input_types={}, partial_variables={}, template=\"Act as a helpful assistant.\\n                You run in a loop of Thought, Action, PAUSE, Observation.\\n                At the end of the loop, you output an Answer.\\n                Use Thought to describe your thoughts about the question you have been asked.\\n                Use Action to run one of the actions available to you - then return PAUSE.\\n                Observation will be the result of running those actions.\\n                Repeat till you get to the answer for the given user query.\\n\\n                Use the following workflow format:\\n                  Question: the input task you must solve\\n                  Thought: you should always think about what to do\\n                  Action: the action to take which can be any of the following:\\n                            - break it into smaller steps if needed\\n                            - see if you can answer the given task with your trained knowledge\\n                            - call the most relevant tools at your disposal mentioned below in case you need more information\\n                  Action Input: the input to the action\\n                  Observation: the result of the action\\n                  ... (this Thought/Action/Action Input/Observation can repeat N times)\\n                  Thought: I now know the final answer\\n                  Final Answer: the final answer to the original input question\\n\\n                Tools at your disposal to perform tasks as needed:\\n                  - get_weather: whenever user asks get the weather of a place.\\n                  - search_web_extract_info: whenever user asks for specific information or if you don't know the answer.\\n             \"), additional_kwargs={}),\n",
              " MessagesPlaceholder(variable_name='history', optional=True),\n",
              " HumanMessagePromptTemplate(prompt=PromptTemplate(input_variables=['query'], input_types={}, partial_variables={}, template='{query}'), additional_kwargs={}),\n",
              " MessagesPlaceholder(variable_name='agent_scratchpad')]"
            ]
          },
          "execution_count": 9,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "from langchain_core.prompts import ChatPromptTemplate, MessagesPlaceholder\n",
        "\n",
        "SYS_PROMPT = \"\"\"Act as a helpful assistant.\n",
        "                You run in a loop of Thought, Action, PAUSE, Observation.\n",
        "                At the end of the loop, you output an Answer.\n",
        "                Use Thought to describe your thoughts about the question you have been asked.\n",
        "                Use Action to run one of the actions available to you - then return PAUSE.\n",
        "                Observation will be the result of running those actions.\n",
        "                Repeat till you get to the answer for the given user query.\n",
        "\n",
        "                Use the following workflow format:\n",
        "                  Question: the input task you must solve\n",
        "                  Thought: you should always think about what to do\n",
        "                  Action: the action to take which can be any of the following:\n",
        "                            - break it into smaller steps if needed\n",
        "                            - see if you can answer the given task with your trained knowledge\n",
        "                            - call the most relevant tools at your disposal mentioned below in case you need more information\n",
        "                  Action Input: the input to the action\n",
        "                  Observation: the result of the action\n",
        "                  ... (this Thought/Action/Action Input/Observation can repeat N times)\n",
        "                  Thought: I now know the final answer\n",
        "                  Final Answer: the final answer to the original input question\n",
        "\n",
        "                Tools at your disposal to perform tasks as needed:\n",
        "                  - get_weather: whenever user asks get the weather of a place.\n",
        "                  - search_web_extract_info: whenever user asks for specific information or if you don't know the answer.\n",
        "             \"\"\"\n",
        "\n",
        "prompt_template = ChatPromptTemplate.from_messages(\n",
        "    [\n",
        "        (\"system\", SYS_PROMPT),\n",
        "        MessagesPlaceholder(variable_name=\"history\", optional=True),\n",
        "        (\"human\", \"{query}\"),\n",
        "        MessagesPlaceholder(variable_name=\"agent_scratchpad\"),\n",
        "    ]\n",
        ")\n",
        "\n",
        "prompt_template.messages"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jlJwVepDmsZw"
      },
      "source": [
        "Now, we can initalize the agent with the LLM, the prompt, and the tools.\n",
        "\n",
        "The agent is responsible for taking in input and deciding what actions to take.\n",
        "\n",
        "REMEMBER the Agent does not execute those actions - that is done by the AgentExecutor\n",
        "\n",
        "Note that we are passing in the model `chatgpt`, not `chatgpt_with_tools`.\n",
        "\n",
        "That is because `create_tool_calling_agent` will call `.bind_tools` for us under the hood.\n",
        "\n",
        "This should ideally be used with an LLM which supports tool \\ function calling"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "u4NMA82HpueH"
      },
      "outputs": [],
      "source": [
        "from langchain.agents import create_tool_calling_agent\n",
        "\n",
        "chatgpt = ChatOpenAI(model=\"gpt-4o\", temperature=0)\n",
        "tools = [search_web_extract_info, get_weather]\n",
        "agent = create_tool_calling_agent(chatgpt, tools, prompt_template)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TiL70NCrmkkW"
      },
      "source": [
        "Finally, we combine the `agent` (the brains) with the `tools` inside the `AgentExecutor` (which will repeatedly call the agent and execute tools)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "vAuGe5G5pugJ"
      },
      "outputs": [],
      "source": [
        "from langchain.agents import AgentExecutor\n",
        "\n",
        "agent_executor = AgentExecutor(agent=agent,\n",
        "                               tools=tools,\n",
        "                               early_stopping_method='force',\n",
        "                               max_iterations=10)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OXqgT0Yth892",
        "outputId": "6c03e40b-832c-44b2-9318-77cbdb3f42ae"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "As of my last update, Nvidia's Q4 2024 earnings call has not occurred, as my data only goes up to October 2023. Therefore, I cannot provide specific details about the call. However, I can guide you on what to typically expect from such earnings calls:\n",
            "\n",
            "1. **Financial Performance**: Discussion of revenue, net income, and earnings per share compared to previous quarters and analyst expectations.\n",
            "\n",
            "2. **Segment Performance**: Insights into how different business segments, such as gaming, data center, professional visualization, and automotive, have performed.\n",
            "\n",
            "3. **Market Trends**: Commentary on market conditions affecting Nvidia's business, such as demand for GPUs, AI advancements, and competition.\n",
            "\n",
            "4. **Product Updates**: Announcements or updates on new products, technologies, or partnerships.\n",
            "\n",
            "5. **Guidance**: Forward-looking statements regarding expected financial performance and strategic priorities for the upcoming quarters.\n",
            "\n",
            "6. **Q&A Session**: Responses to analysts' questions, which can provide additional insights into the company's strategy and outlook.\n",
            "\n",
            "For the most accurate and up-to-date information, I recommend checking Nvidia's official investor relations website or financial news sources after the earnings call takes place.\n"
          ]
        }
      ],
      "source": [
        "query = \"\"\"Summarize the key points discussed in Nvidia's Q4 2024 earnings call\"\"\"\n",
        "response = chatgpt.invoke(query)\n",
        "print(response.content)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {},
      "outputs": [],
      "source": [
        "from IPython.display import display, Markdown"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "07nRAXEwY7Ea",
        "outputId": "00785ea5-fcad-45bb-a491-0e287c184f55"
      },
      "outputs": [],
      "source": [
        "# query = \"\"\"Summarize the key points discussed in Nvidia's Q4 2024 earnings call\"\"\"\n",
        "# response = agent_executor.invoke({\"query\": query})\n",
        "\n",
        "\n",
        "# display(Markdown(response['output']))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 334
        },
        "id": "H2_MM2jrPRya",
        "outputId": "71457141-9bae-4ece-efb3-eb2c1d245488"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 260
        },
        "id": "riHUt00KE_3q",
        "outputId": "a45dcd11-12bf-43c7-da55-33b01c0fa057"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Calling web search tool\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "  0%|          | 0/5 [00:00<?, ?it/s]Some characters could not be decoded, and were replaced with REPLACEMENT CHARACTER.\n",
            " 20%|██        | 1/5 [00:02<00:08,  2.18s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Error extracting from url: https://www.gurufocus.com/news/2675853/intel-corp-intc-q4-2024-earnings-call-highlights-surpassing-guidance-amidst-market-challenges - 'NoneType' object has no attribute 'strip'\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Some characters could not be decoded, and were replaced with REPLACEMENT CHARACTER.\n",
            " 40%|████      | 2/5 [00:04<00:06,  2.13s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Error extracting from url: https://www.fool.com/earnings/call-transcripts/2025/01/30/intel-intc-q4-2024-earnings-call-transcript/ - 'NoneType' object has no attribute 'strip'\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 60%|██████    | 3/5 [00:08<00:05,  2.94s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Error extracting from url: https://download.intel.com/newsroom/2025/c8e6h3a2/intel-q4-2024y-earnings.pdf - File conversion failed after 1 attempts:\n",
            " - PdfConverter threw MissingDependencyException with message: PdfConverter recognized the input as a potential .pdf file, but the dependencies needed to read .pdf files have not been installed. To resolve this error, include the optional dependency [pdf] or [all] when installing MarkItDown. For example:\n",
            "\n",
            "* pip install markitdown[pdf]\n",
            "* pip install markitdown[all]\n",
            "* pip install markitdown[pdf, ...]\n",
            "* etc.\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 5/5 [00:10<00:00,  2.11s/it]\n"
          ]
        },
        {
          "data": {
            "text/markdown": [
              "Intel's Q4 2024 earnings call highlighted several key points:\n",
              "\n",
              "1. **Financial Performance**:\n",
              "   - Q4 revenue was $14.3 billion, up 7% sequentially.\n",
              "   - Non-GAAP gross margin was 42.1%, exceeding guidance by 260 basis points.\n",
              "   - Earnings per share (EPS) for Q4 was $0.13, slightly above the guidance of $0.12.\n",
              "   - Operating cash flow for Q4 was $3.2 billion, but adjusted free cash flow was negative $1.5 billion.\n",
              "   - Full-year 2024 revenue was $53.1 billion, a 2.1% decrease year-over-year.\n",
              "   - Full-year gross margin was 36%, down 760 basis points.\n",
              "   - Full-year EPS was negative $0.13, with cash from operations at $8.3 billion and adjusted free cash flow at negative $2.2 billion.\n",
              "\n",
              "2. **Guidance and Outlook**:\n",
              "   - Q1 2025 revenue guidance is between $11.7 billion and $12.7 billion.\n",
              "   - Gross margin for Q1 2025 is expected to be around 36%, with EPS guidance at breakeven on a non-GAAP basis.\n",
              "\n",
              "3. **Business Segments**:\n",
              "   - Intel Foundry's Q4 revenue was $4.5 billion, with a significant operating loss of $2.3 billion.\n",
              "   - Mobileye and Altera reported slight revenue increases sequentially.\n",
              "\n",
              "4. **Strategic Initiatives**:\n",
              "   - Intel remains a leader in AI PC CPUs, with plans to ship over 100 million systems by the end of 2025.\n",
              "   - The launch of Panther Lake on Intel 18A is on track for the second half of 2025.\n",
              "   - Intel Foundry is progressing with Intel 18A, showing competitive offerings and a healthy RFQ pipeline.\n",
              "\n",
              "5. **Challenges**:\n",
              "   - Increased competition in the AI PC category and lack of significant participation in the cloud-based AI data center market.\n",
              "   - Intel Foundry reported a significant operating loss in 2024.\n",
              "   - Q1 2025 guidance indicates a sequential revenue decline due to macro uncertainty and seasonality.\n",
              "   - Gross margins are expected to be under pressure throughout 2025.\n",
              "\n",
              "6. **Q&A Highlights**:\n",
              "   - Discussions on closing the gap with competitors through Granite Rapids and the niche market potential of Clearwater Forest.\n",
              "   - Gross margin pressures due to revenue decline and higher costs, with improvements expected later in the year.\n",
              "   - A more conservative approach for Intel Foundry Services under new leadership, focusing on cautious capital deployment.\n",
              "\n",
              "Overall, Intel surpassed its guidance amidst market challenges but faces ongoing competition and financial pressures."
            ],
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "query = \"\"\"Summarize the key points discussed in Intel's Q4 2024 earnings call\"\"\"\n",
        "response = agent_executor.invoke({\"query\": query})\n",
        "display(Markdown(response['output']))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 64
        },
        "id": "GfBHtCzJFKdb",
        "outputId": "8bc3f413-9adf-48a7-88c5-6ea25be31108"
      },
      "outputs": [
        {
          "data": {
            "text/markdown": [
              "To provide an accurate assessment of a company's future outlook, I would need to know which specific companies you are interested in comparing. Please provide the names of the companies you would like to evaluate."
            ],
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "query = \"\"\"which company's future outlook looks to be better?\n",
        "        \"\"\"\n",
        "response = agent_executor.invoke({\"query\": query})\n",
        "display(Markdown(response['output']))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 301
        },
        "id": "O1-HaMLoZAwO",
        "outputId": "88218ffb-eb4e-45f3-c530-68cbeb0e2f03"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Calling weather tool\n"
          ]
        },
        {
          "data": {
            "text/markdown": [
              "The weather in Bangalore today is as follows:\n",
              "\n",
              "- **Temperature**: 16.7°C (62.1°F)\n",
              "- **Condition**: Partly Cloudy\n",
              "- **Wind**: 10.8 kph (6.7 mph) from the East\n",
              "- **Pressure**: 1013.0 mb (29.91 in)\n",
              "- **Precipitation**: 0.0 mm\n",
              "- **Humidity**: 92%\n",
              "- **Cloud Cover**: 28%\n",
              "- **Feels Like**: 16.7°C (62.1°F)\n",
              "- **Dew Point**: 15.4°C (59.7°F)\n",
              "- **Visibility**: 10.0 km (6.0 miles)\n",
              "- **UV Index**: 0.0\n",
              "- **Wind Gusts**: 19.0 kph (11.8 mph)\n",
              "\n",
              "The data was last updated at 6:30 AM local time."
            ],
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "query = \"\"\"how is the weather in Bangalore today?\n",
        "           show detailed statistics\n",
        "        \"\"\"\n",
        "response = agent_executor.invoke({\"query\": query})\n",
        "display(Markdown(response['output']))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 301
        },
        "id": "2GosuSIoZrZm",
        "outputId": "a5212dd7-68f9-4820-934c-48a47a823c42"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Calling weather tool\n"
          ]
        },
        {
          "data": {
            "text/markdown": [
              "The weather in Dubai today is clear. Here are the detailed statistics:\n",
              "\n",
              "- **Temperature**: 17.6°C (63.7°F)\n",
              "- **Condition**: Clear\n",
              "- **Wind**: 12.3 mph (19.8 kph) from the East (93°)\n",
              "- **Pressure**: 1021.0 mb (30.16 in)\n",
              "- **Precipitation**: 0.0 mm (0.0 in)\n",
              "- **Humidity**: 43%\n",
              "- **Cloud Cover**: 0%\n",
              "- **Feels Like**: 17.6°C (63.7°F)\n",
              "- **Dew Point**: 5.0°C (41.1°F)\n",
              "- **Visibility**: 10.0 km (6.0 miles)\n",
              "- **UV Index**: 0.0\n",
              "- **Wind Gusts**: 21.9 mph (35.2 kph)\n",
              "\n",
              "The current time in Dubai is 5:04 AM."
            ],
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "query = \"\"\"how is the weather in Dubai today?\n",
        "           show detailed statistics\n",
        "        \"\"\"\n",
        "response = agent_executor.invoke({\"query\": query})\n",
        "display(Markdown(response['output']))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 93
        },
        "id": "ElF1npM4ZvAo",
        "outputId": "0414a0b5-51dc-4183-813b-a6a37701fc6a"
      },
      "outputs": [
        {
          "data": {
            "text/markdown": [
              "Question: The user is asking which city is hotter, but they haven't specified the cities they are interested in. I need more information to proceed.\n",
              "\n",
              "Thought: I need to ask the user for the names of the cities they want to compare in terms of temperature.\n",
              "\n",
              "Final Answer: Could you please specify the names of the cities you would like to compare to determine which one is hotter?"
            ],
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "query = \"\"\"which city is hotter?\n",
        "        \"\"\"\n",
        "response = agent_executor.invoke({\"query\": query})\n",
        "display(Markdown(response['output']))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DQQAx3B7xrl-"
      },
      "source": [
        "The agent is doing pretty well but unfortunately it doesn't remember conversations. We will use some user-session based memory to store this and dive deeper into this in the next video."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "C:\\Users\\Acer\\AppData\\Local\\Temp\\ipykernel_36092\\527297010.py:68: LangChainDeprecationWarning: The class `LLMChain` was deprecated in LangChain 0.1.17 and will be removed in 1.0. Use :meth:`~RunnableSequence, e.g., `prompt | llm`` instead.\n",
            "  tool_selection_chain = LLMChain(\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "from typing import Dict, Any\n",
        "from langchain_core.prompts import ChatPromptTemplate\n",
        "from langchain_openai import ChatOpenAI\n",
        "from langchain_core.tools import Tool\n",
        "from langchain_core.output_parsers import StrOutputParser\n",
        "from langchain.chains import LLMChain\n",
        "from langchain.agents import AgentExecutor, create_structured_chat_agent\n",
        "\n",
        "# Define some simple tool functions\n",
        "def calculator(expression: str) -> float:\n",
        "    \"\"\"Evaluate a mathematical expression.\"\"\"\n",
        "    try:\n",
        "        return eval(expression)\n",
        "    except Exception as e:\n",
        "        return f\"Error: {str(e)}\"\n",
        "\n",
        "def get_weather(location: str) -> str:\n",
        "    \"\"\"Get the current weather for a location.\"\"\"\n",
        "    # Mock implementation\n",
        "    return f\"The weather in {location} is sunny with a temperature of 72°F.\"\n",
        "\n",
        "def search_database(query: str) -> str:\n",
        "    \"\"\"Search a database for information.\"\"\"\n",
        "    # Mock database\n",
        "    database = {\n",
        "        \"python\": \"Python is a high-level programming language.\",\n",
        "        \"langchain\": \"LangChain is a framework for LLM applications.\",\n",
        "        \"llm\": \"LLM stands for Large Language Model.\"\n",
        "    }\n",
        "    query = query.lower()\n",
        "    return database.get(query, f\"No information found for '{query}'.\")\n",
        "\n",
        "# Create the tools\n",
        "tools = [\n",
        "    Tool(\n",
        "        name=\"Calculator\",\n",
        "        func=calculator,\n",
        "        description=\"Useful for performing mathematical calculations\"\n",
        "    ),\n",
        "    Tool(\n",
        "        name=\"WeatherService\",\n",
        "        func=get_weather,\n",
        "        description=\"Get current weather for a location\"\n",
        "    ),\n",
        "    Tool(\n",
        "        name=\"Database\",\n",
        "        func=search_database,\n",
        "        description=\"Search the database for information\"\n",
        "    )\n",
        "]\n",
        "\n",
        "# Create the LLM\n",
        "llm = ChatOpenAI(\n",
        "    temperature=0,\n",
        "    model=\"gpt-3.5-turbo\"\n",
        ")\n",
        "\n",
        "# Create an LLM chain for deciding which tool to use\n",
        "tool_selection_prompt = ChatPromptTemplate.from_messages([\n",
        "    (\"system\", \"\"\"You are a tool selection assistant. \n",
        "    Based on the user's question, determine which tool would be most appropriate.\n",
        "    Respond with only the tool name: \"Calculator\", \"WeatherService\", or \"Database\".\n",
        "    If none of these tools can help, respond with \"None\".\"\"\"),\n",
        "    (\"human\", \"{query}\")\n",
        "])\n",
        "\n",
        "tool_selection_chain = LLMChain(\n",
        "    llm=llm,\n",
        "    prompt=tool_selection_prompt,\n",
        "    output_key=\"selected_tool\"\n",
        ")\n",
        "\n",
        "# Create an LLM chain for formatting tool inputs\n",
        "tool_input_prompt = ChatPromptTemplate.from_messages([\n",
        "    (\"system\", \"\"\"Extract the specific input needed for the tool from the user's query.\n",
        "    For Calculator: Extract the mathematical expression.\n",
        "    For WeatherService: Extract the location name.\n",
        "    For Database: Extract the search query.\n",
        "    Provide only the extracted information, nothing else.\"\"\"),\n",
        "    (\"human\", \"Tool to use: {selected_tool}\\nUser query: {query}\")\n",
        "])\n",
        "\n",
        "tool_input_chain = LLMChain(\n",
        "    llm=llm,\n",
        "    prompt=tool_input_prompt,\n",
        "    output_key=\"tool_input\"\n",
        ")\n",
        "\n",
        "# Create an LLM chain for formatting the final response\n",
        "response_prompt = ChatPromptTemplate.from_messages([\n",
        "    (\"system\", \"Create a helpful response to the user's query using the tool's output.\"),\n",
        "    (\"human\", \"User query: {query}\\nTool used: {selected_tool}\\nTool output: {tool_output}\")\n",
        "])\n",
        "\n",
        "response_chain = LLMChain(\n",
        "    llm=llm,\n",
        "    prompt=response_prompt,\n",
        "    output_key=\"response\"\n",
        ")\n",
        "\n",
        "# Function to run the full chain\n",
        "def process_query(query: str) -> str:\n",
        "    # First, select which tool to use\n",
        "    tool_selection_result = tool_selection_chain.invoke({\"query\": query})\n",
        "    selected_tool = tool_selection_result[\"selected_tool\"].strip()\n",
        "    print(f\"Selected tool: {selected_tool}\")\n",
        "    \n",
        "    if selected_tool == \"None\":\n",
        "        return \"I don't have a tool that can help with this query.\"\n",
        "    \n",
        "    # Next, format the input for the selected tool\n",
        "    tool_input_result = tool_input_chain.invoke({\n",
        "        \"selected_tool\": selected_tool,\n",
        "        \"query\": query\n",
        "    })\n",
        "    tool_input = tool_input_result[\"tool_input\"].strip()\n",
        "    print(f\"Tool input: {tool_input}\")\n",
        "    \n",
        "    # Find and run the appropriate tool\n",
        "    tool_output = \"Tool not found\"\n",
        "    for tool in tools:\n",
        "        if tool.name == selected_tool:\n",
        "            tool_output = tool.func(tool_input)\n",
        "            break\n",
        "    print(f\"Tool output: {tool_output}\")\n",
        "    \n",
        "    # Format the final response\n",
        "    response_result = response_chain.invoke({\n",
        "        \"query\": query,\n",
        "        \"selected_tool\": selected_tool,\n",
        "        \"tool_output\": tool_output\n",
        "    })\n",
        "    return response_result[\"response\"]\n",
        "\n",
        "# Example usage\n",
        "def run_examples():\n",
        "    examples = [\n",
        "        \"What is 234 * 78.5?\",\n",
        "        \"What's the weather like in San Francisco?\",\n",
        "        \"Tell me about LangChain.\",\n",
        "        \"What's the capital of France?\"\n",
        "    ]\n",
        "    \n",
        "    for example in examples:\n",
        "        print(f\"\\n\\nQUERY: {example}\")\n",
        "        print(\"-\" * 50)\n",
        "        response = process_query(example)\n",
        "        print(\"FINAL RESPONSE:\")\n",
        "        print(response)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "\n",
            "QUERY: What is 234 * 78.5?\n",
            "--------------------------------------------------\n",
            "Selected tool: Calculator\n",
            "Tool input: 234 * 78.5\n",
            "Tool output: 18369.0\n",
            "FINAL RESPONSE:\n",
            "The result of multiplying 234 by 78.5 is 18,369.0.\n",
            "\n",
            "\n",
            "QUERY: What's the weather like in San Francisco?\n",
            "--------------------------------------------------\n",
            "Selected tool: WeatherService\n",
            "Tool input: San Francisco\n",
            "Tool output: The weather in San Francisco is sunny with a temperature of 72°F.\n",
            "FINAL RESPONSE:\n",
            "The current weather in San Francisco is sunny with a temperature of 72°F. It seems like a beautiful day to enjoy outdoor activities or explore the city. Remember to stay hydrated and wear sunscreen if you plan to be outside for an extended period of time.\n",
            "\n",
            "\n",
            "QUERY: Tell me about LangChain.\n",
            "--------------------------------------------------\n",
            "Selected tool: None\n",
            "FINAL RESPONSE:\n",
            "I don't have a tool that can help with this query.\n",
            "\n",
            "\n",
            "QUERY: What's the capital of France?\n",
            "--------------------------------------------------\n",
            "Selected tool: None\n",
            "FINAL RESPONSE:\n",
            "I don't have a tool that can help with this query.\n"
          ]
        }
      ],
      "source": [
        "run_examples()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "venv",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.10"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
