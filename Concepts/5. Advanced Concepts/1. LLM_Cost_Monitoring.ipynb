{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e9a6d102",
   "metadata": {},
   "source": [
    "# Advanced Operations for LLM Input / Output with LangChain\n",
    "\n",
    "This notebook covers the following operations:\n",
    "\n",
    "- LLM Cost Monitoring"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c08b42e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install -qq langchain==0.3.11\n",
    "!pip install -qq langchain-openai==0.2.12\n",
    "!pip install -qq langchain-community==0.3.11"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b22b34a",
   "metadata": {},
   "source": [
    "## Enter API Tokens"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb69ab66",
   "metadata": {},
   "source": [
    "#### Enter your Open AI Key here\n",
    "\n",
    "You can get the key from [here](https://platform.openai.com/api-keys) after creating an account or signing in"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "724b318c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from getpass import getpass\n",
    "\n",
    "# OPENAI_KEY = getpass('Please enter your Open AI API Key here: ')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db8fcf1a",
   "metadata": {},
   "source": [
    "## Setup necessary system environment variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e80f574",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import os\n",
    "\n",
    "# os.environ['OPENAI_API_KEY'] = OPENAI_KEY"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "af51d22c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9450525",
   "metadata": {},
   "source": [
    "## Chat Models and LLMs\n",
    "\n",
    "Large Language Models (LLMs) are a core component of LangChain. LangChain does not implement or build its own LLMs. It provides a standard API for interacting with almost every LLM out there.\n",
    "\n",
    "There are lots of LLM providers (OpenAI, Hugging Face, etc) - the LLM class is designed to provide a standard interface for all of them."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b233c6d",
   "metadata": {},
   "source": [
    "## Accessing Commercial LLMs like ChatGPT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b223bb25",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_openai import ChatOpenAI\n",
    "\n",
    "chatgpt = ChatOpenAI(model_name=\"gpt-4o-mini\", temperature=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3a20ff6",
   "metadata": {},
   "source": [
    "## Tracking LLM Costs\n",
    "\n",
    "Typically LLMs like ChatGPT charge you based on the number of tokens per request and response. You can track your token usage for specific calls. It is currently only implemented for the OpenAI API."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "3f2f64af",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generative AI refers to algorithms that can create new content, such as text, images, or music, by learning patterns from existing data.\n",
      "Tokens Used: 42\n",
      "\tPrompt Tokens: 14\n",
      "\tCompletion Tokens: 28\n",
      "Successful Requests: 1\n",
      "Total Cost (USD): $1.89e-05\n"
     ]
    }
   ],
   "source": [
    "# Import the callback function to track OpenAI API usage and costs\n",
    "from langchain_community.callbacks import get_openai_callback\n",
    "\n",
    "# Define a simple prompt to test the LLM\n",
    "prompt = \"\"\"Explain Generative AI in one line\"\"\"\n",
    "\n",
    "# Use the callback context manager to track token usage and costs\n",
    "with get_openai_callback() as cb:\n",
    "    # Invoke the ChatGPT model with our prompt\n",
    "    response = chatgpt.invoke(prompt)\n",
    "    # Print the model's response\n",
    "    print(response.content)\n",
    "    # Print the callback object which contains usage statistics (tokens, costs, etc.)\n",
    "    print(cb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "3fa85c1c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'content': 'Generative AI refers to algorithms that can create new content, such as text, images, or music, by learning patterns from existing data.',\n",
       " 'additional_kwargs': {'refusal': None},\n",
       " 'response_metadata': {'token_usage': {'completion_tokens': 28,\n",
       "   'prompt_tokens': 14,\n",
       "   'total_tokens': 42,\n",
       "   'completion_tokens_details': {'accepted_prediction_tokens': 0,\n",
       "    'audio_tokens': 0,\n",
       "    'reasoning_tokens': 0,\n",
       "    'rejected_prediction_tokens': 0},\n",
       "   'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}},\n",
       "  'model_name': 'gpt-4o-mini-2024-07-18',\n",
       "  'system_fingerprint': 'fp_34a54ae93c',\n",
       "  'finish_reason': 'stop',\n",
       "  'logprobs': None},\n",
       " 'type': 'ai',\n",
       " 'name': None,\n",
       " 'id': 'run--ac2d336a-8ed9-4401-8558-a042f9921005-0',\n",
       " 'example': False,\n",
       " 'tool_calls': [],\n",
       " 'invalid_tool_calls': [],\n",
       " 'usage_metadata': {'input_tokens': 14,\n",
       "  'output_tokens': 28,\n",
       "  'total_tokens': 42,\n",
       "  'input_token_details': {'audio': 0, 'cache_read': 0},\n",
       "  'output_token_details': {'audio': 0, 'reasoning': 0}}}"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response.model_dump()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "b34d5738",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "42"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cb.total_tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "55740f2b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(14, 28)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cb.prompt_tokens, cb.completion_tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "1d3ff57a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.89e-05"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cb.total_cost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48092cc3",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
